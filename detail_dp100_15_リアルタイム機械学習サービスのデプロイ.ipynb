{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbbcc0f",
   "metadata": {},
   "source": [
    "# dp100_15 リアルタイム機械学習サービスのデプロイ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3c30c",
   "metadata": {},
   "source": [
    "\"推論\"とは、トレーニング済みのモデルを使用して、モデルがトレーニングされていない新しいデータのラベルを予測することを意味する。  \n",
    "こうしたモデルは多くの場合、アプリケーションで個別または少数のデータ観測のための予測を即時に要求できるようにするサービスの一部としてデプロイされる。\n",
    "\n",
    "AzureMLでは、Azure Kubernetes Service(AKS)などのコンテナー化されたプラットフォームでホストされるサービスとして.   \n",
    "モデルをデプロイすることで、リアルタイムの推論ソリューションを作成できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ecb793",
   "metadata": {},
   "source": [
    "## モデルをリアルタイムサービスとしてデプロイする\n",
    "\n",
    "モデルはリアルタイムのWebサービスとして、いくつかの種類のコンピューティングターゲットにデプロイすることができる。  \n",
    "これには、ローカルコンピューティング、AzureMLコンピューティングインスタンス、Azure Container Instance(ACI)、  \n",
    "Azure Kubenernetes Service(AKS)クラスター、Azure関数、IoTモジュールが含まれる。\n",
    "\n",
    "AzureMLでは、\"コンテナ\"をデプロイメカニズムとして使用し、モデルとコードをパッケージ化して、  \n",
    "選択したコンピューティングターゲットのコンテナーにデプロイできるイメージとして使う。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fa9174",
   "metadata": {},
   "source": [
    "> 注:テストと開発には、ローカルサービス、コンピューティングインスタンス、またはACIへデプロイが適している。  \n",
    "運用環境では、アプリケーションアーキテクチャの特定のパフォーマンス、スケーラビリティ、  \n",
    "およびセキュリティのニーズを満たすターゲットにデプロイする必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed04ea4",
   "metadata": {},
   "source": [
    "リアルタイムの推論サービスとしてモデルをデプロイするには、次のタスクを実行する必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5f928",
   "metadata": {},
   "source": [
    "### 1.トレーニング済みモデルを登録する\n",
    "\n",
    "モデルのトレーニングが正常に行われたあとで、AzureMLワークスペースで登録する必要がある。  \n",
    "そのあと、リアルタイムサービスでは必要に応じてモデルを読み込むことができる。\n",
    "\n",
    "ローカルファイルからモデルを登録する場合は、ここに示すように**Model**オブジェクトの**register**メソッドを使用できる。\n",
    "\n",
    "```\n",
    "from azureml.core import Model\n",
    "\n",
    "classification_model = Model.register(workspace=ws,\n",
    "                       model_name='classification_model',\n",
    "                       model_path='model.pkl', # local path\n",
    "                       description='A classification model')\n",
    "```\n",
    "\n",
    "また、モデルのトレーニングに使用された**Run**への参照がある場合は、以下に示すように**register_model**メソッドを使用できる。\n",
    "\n",
    "```\n",
    "run.register_model( model_name='classification_model',\n",
    "                    model_path='outputs/model.pkl', # run outputs path\n",
    "                    description='A classification model')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f473a",
   "metadata": {},
   "source": [
    "### 2. 推論の構成を定義する\n",
    "\n",
    "モデルは、以下のもので構成されるサービスとしてデプロイされる。\n",
    "\n",
    "- モデルを読み込み、送信されたデータの予測を返すスクリプト\n",
    "- スクリプトが実行される環境\n",
    "\n",
    "そのため、サービスのスクリプトと環境を定義する必要がある。\n",
    "\n",
    "#### エントリスクリプトを作成する\n",
    "\n",
    "サービスの\"エントリスクリプト\"(スコアリングスクリプトと呼ばれることも)をpyファイルとして作成する。  \n",
    "次の2つの関数が含まれている必要がある。\n",
    "\n",
    "- **init()** : サービスの初期化時に呼び出し\n",
    "- **run(raw_data)** : 新しいデータがサービスに送信されるときに呼び出される\n",
    "\n",
    "通常は、**init**関数を使ってモデルレジストリからモデルを読み込み、**run**関数を使用して入力データから予測を生成する。  \n",
    "次のスクリプト例は、このパターンを示している。\n",
    "\n",
    "```\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the registered model file and load it\n",
    "    model_path = Model.get_model_path('classification_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Return the predictions as any JSON serializable format\n",
    "    return predictions.tolist()\n",
    "```\n",
    "\n",
    "#### 環境の作成\n",
    "\n",
    "サービスには、エントリスクリプトを実行するPython環境が必要で、Conda構成ファイルを使用して構成できる。  \n",
    "このファイルを作成する簡単な方法は、**CondaDependencies**クラスを使用し、  \n",
    "(**azureml-defaults**パッケージと、**numpy**、**pandas**などの一般的に使用されるパッケージが含まれる)規定の環境を作成し、  \n",
    "その他の必要なパッケージを追加してから、環境を文字列にシリアル化して保存する。\n",
    "\n",
    "```\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "# Add the dependencies for your model\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package(\"scikit-learn\")\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = 'service_files/env.yml'\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "```\n",
    "\n",
    "#### InferenceConfigでスクリプトと環境を組み合わせる\n",
    "\n",
    "エントリスクリプトと環境構成ファイルを作成した後、このようにサービスの**InferenceConfig**でそれらを組み合わせることができる。\n",
    "\n",
    "```\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "classifier_inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                              source_directory = 'service_files',\n",
    "                                              entry_script=\"score.py\",\n",
    "                                              conda_file=\"env.yml\")\n",
    "```\n",
    "\n",
    "### 3.デプロイ構成を定義する\n",
    "\n",
    "これでエントリスクリプトと環境が用意できたので、サービスがデプロイされるコンピューティングを構成する必要がある。  \n",
    "AKSクラスターにデプロイする場合は、デプロイする前にクラスターとコンピューティングターゲットを作成する必要がある。\n",
    "\n",
    "```\n",
    "from azureml.core.compute import ComputeTarget, AksCompute\n",
    "\n",
    "cluster_name = 'aks-cluster'\n",
    "compute_config = AksCompute.provisioning_configuration(location='eastus')\n",
    "production_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "production_cluster.wait_for_completion(show_output=True)\n",
    "```\n",
    "\n",
    "コンピューティングターゲットが作成され、デプロイ構成が定義できるようになった。  \n",
    "これにより、コンテナ化されたデプロイのターゲット固有のコンピューティング使用が設定される。\n",
    "\n",
    "```\n",
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "classifier_deploy_config = AksWebservice.deploy_configuration(cpu_cores = 1,\n",
    "                                                              memory_gb = 1)\n",
    "```\n",
    "\n",
    "ACIのデプロイを構成するコードは似ているが、ACIのコンピューティングターゲットを明示的に作成する必要がない点が異なる。  \n",
    "また、**azureml.core.webservice.AciWebservice**名前空間から**deploy_configuration**クラスを使用する必要がある。  \n",
    "同様に、**azureml.core.LocalWebservice**名前空間を使用して、ローカルのDockerベースのサービスを構成できる。\n",
    "\n",
    "> 注:Azure関数にモデルをデプロイする場合は、デプロイ構成を作成する必要はない。  \n",
    "その代わりに、使用する関数トリガーの種類に基づいて、モデルをパッケージ化する必要がある。  \n",
    "詳細URL : https://aka.ms/AA70rrn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc673a",
   "metadata": {},
   "source": [
    "### 4.モデルをデプロイする\n",
    "\n",
    "すべての構成を準備したあとでモデルをデプロイできる。  \n",
    "これを行う最も簡単な方法は、以下のように**Model**クラスの**deploy**メソッドを呼び出すこと。\n",
    "\n",
    "```\n",
    "from azureml.core.model import Model\n",
    "\n",
    "model = ws.models['classification_model']\n",
    "service = Model.deploy(workspace=ws,\n",
    "                       name = 'classifier-service',\n",
    "                       models = [model],\n",
    "                       inference_config = classifier_inference_config,\n",
    "                       deployment_config = classifier_deploy_config,\n",
    "                       deployment_target = production_cluster)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "```\n",
    "\n",
    "ACIまたはローカルサービスの場合は、**deployment_target**パラメータを省略(または**None**)できる。\n",
    "\n",
    "AzureMLを使用したモデルのデプロイの詳細 : https://aka.ms/AA70zfv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd16a96d",
   "metadata": {},
   "source": [
    "## リアルタイムの推論サービスを使用する\n",
    "\n",
    "リアルタイムサービスをデプロイした後、それをクライアントアプリケーションから使用して、新しいデータケースのラベルを予測することができる。\n",
    "\n",
    "### AzureML SDKを使用する\n",
    "\n",
    "テストでは、AzureML SDKを使用して、デプロイされたサービスを参照する**WebService**オブジェクトの**run**メソッドを介して、  \n",
    "Webサービスを呼び出すことができる。通常は、次の構造でJSON形式の**run**メソッドにデータを送信する。\n",
    "\n",
    "```\n",
    "{\n",
    "  \"data\":[\n",
    "      [0.1,2.3,4.1,2.0], // 1st case\n",
    "      [0.2,1.8,3.9,2.1],  // 2nd case,\n",
    "      ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "**run**メソッドからの応答は、データで送信された各ケースの予測を含むJSONコレクション。  \n",
    "次のコードサンプルでは、サービスを呼び出して応答を表示する。\n",
    "\n",
    "```\n",
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[0.1,2.3,4.1,2.0],\n",
    "         [0.2,1.8,3.9,2.1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "response = service.run(input_data = json_data)\n",
    "\n",
    "# Get the predictions\n",
    "predictions = json.loads(response)\n",
    "\n",
    "# Print the predicted class for each case.\n",
    "for i in range(len(x_new)):\n",
    "    print (x_new[i], predictions[i])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c74af",
   "metadata": {},
   "source": [
    "### RESTエンドポイントを使用する\n",
    "\n",
    "運用環境では、ほとんどのクライアントアプリケーションにAzureML SDKは含まれず、RESTインターフェイスを介してサービスが使用される。  \n",
    "デプロイされたサービスのエンドポイントは、AzureMLスタジオで、または次のようにSDKで**Webservice**オブジェクトの**scoring_uri**プロパティを取得することで確認できる。\n",
    "\n",
    "```\n",
    "endpoint = service.scoring_uri\n",
    "print(endpoint)\n",
    "```\n",
    "\n",
    "エンドポイントがわかっている場合は、JSONデータと共にHTTP POST要求を使用してサービスを呼び出すことができる。  \n",
    "次の例は、Pythonを使用してこれを行う方法を示している。\n",
    "\n",
    "```\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[0.1,2.3,4.1,2.0],\n",
    "         [0.2,1.8,3.9,2.1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type in the request headers\n",
    "request_headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "# Call the service\n",
    "response = requests.post(url = endpoint,\n",
    "                         data = json_data,\n",
    "                         headers = request_headers)\n",
    "\n",
    "# Get the predictions from the JSON response\n",
    "predictions = json.loads(response.json())\n",
    "\n",
    "# Print the predicted class for each case.\n",
    "for i in range(len(x_new)):\n",
    "    print (x_new[i]), predictions[i] )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e44fa95",
   "metadata": {},
   "source": [
    "### 認証\n",
    "\n",
    "運用環境では、認証の適用によるサービスへのアクセスの制限が必要になる場合がある。  \n",
    "使用できる認証には、次の2種類がある。\n",
    "\n",
    "- **Key** : 要求は、サービスに関連付けられているキーを指定することによって認証される\n",
    "- **Token** : 要求は、JSON Web Token(JWT)を提供することによって認証される\n",
    "\n",
    "規定では、認証はACIサービスに対して無効になっており、AKSサービスのキーベース設定されている(プライマリおよびセカンダリキーは自動的に生成)。  \n",
    "必要に応じて、トークンベース認証を使用するようにAKSサービスを構成することができる(ACIサービスはサポートされていない)。\n",
    "\n",
    "ワークスペースで認証されたセッションが確立されていると仮定した場合、  \n",
    "サービスに関連付けられている**WebService**オブジェクトの**get_keys**メソッドを使用して、サービスのキーを取得できる。\n",
    "\n",
    "```\n",
    "primary_key, secondary_key = service.get_keys()\n",
    "```\n",
    "\n",
    "トークンベース認証の場合、クライアントアプリケーションでサービスプリンシパル認証を使用して、  \n",
    "Azure Active Directory(Azure AD)を介してそのIDを検証し、サービスの**get_token**メソッドを呼び出して、期間限定のトークンを取得する必要がある。\n",
    "\n",
    "サービスのRESTエンドポイントへの認証された呼び出しを行うには、次のように要求ヘッダーにキーまたはトークンを含める必要がある。\n",
    "\n",
    "```\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# An array of new data cases\n",
    "x_new = [[0.1,2.3,4.1,2.0],\n",
    "         [0.2,1.8,3.9,2.1]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "json_data = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type in the request headers\n",
    "request_headers = { \"Content-Type\":\"application/json\",\n",
    "                    \"Authorization\":\"Bearer \" + key_or_token }\n",
    "\n",
    "# Call the service\n",
    "response = requests.post(url = endpoint,\n",
    "                         data = json_data,\n",
    "                         headers = request_headers)\n",
    "\n",
    "# Get the predictions from the JSON response\n",
    "predictions = json.loads(response.json())\n",
    "\n",
    "# Print the predicted class for each case.\n",
    "for i in range(len(x_new)):\n",
    "    print (x_new[i]), predictions[i] )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2c211",
   "metadata": {},
   "source": [
    "## サービスデプロイのトラブルシューティングを行う\n",
    "\n",
    "リアルタイムサービスのデプロイには、トレーニング済みモデル、ランタイム環境の構成、スコアリングスクリプト、コンテナイメージ、  \n",
    "コンテナホストなど、多数の要素がある。\n",
    "\n",
    "失敗したデプロイや、デプロイされたサービスの使用時のエラーのトラブルシューティングは複雑な場合がある。\n",
    "\n",
    "### サービスの状態を確認する\n",
    "\n",
    "最初のトラブルシューティング手順として、サービス状態を確認することができる。  \n",
    "そのためには、以下のようにして**状態**を調べる。\n",
    "\n",
    "```\n",
    "from azureml.core.webservice import AksWebservice\n",
    "\n",
    "# デプロイされたサービスを取得\n",
    "service = AksWebservice(name='classifier-service', workspace=ws)\n",
    "\n",
    "# ステータス確認\n",
    "print(service.state)\n",
    "```\n",
    "\n",
    "> 注:サービスの**状態**を表示するには、汎用の**WebService**オブジェクトではなく、  \n",
    "コンピューティング固有のサービスの種類(たとえば**AksWebservice)を使用する必要あり"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2394461",
   "metadata": {},
   "source": [
    "### サービスログを確認する\n",
    "\n",
    "サービスに異常やエラーが発生した場合は、そのログを確認できる。\n",
    "\n",
    "```\n",
    "print(service.get_logs())\n",
    "```\n",
    "\n",
    "ログには、サービスのプロビジョニングと、処理された要求に関する詳細情報が含まれている。  \n",
    "多くの場合、これらにより予期しないエラーの原因について洞察を得ることができる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415eecf3",
   "metadata": {},
   "source": [
    "### ローカルコンテナにデプロイ\n",
    "\n",
    "デプロイおよびランタイムエラーは、以下のようにローカルのDockerインスタンスにコンテナとしてサービスをデプロイすることで診断しやすくなる。\n",
    "\n",
    "```\n",
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deployment_config = LocalWebservice.deploy_configuration(port=8890)\n",
    "service = Model.deploy(ws, 'test-svc', [model], inference_config, deployment_config)\n",
    "```\n",
    "\n",
    "その後、SDKを使用してローカルにデプロイされたサービスをテストできる。\n",
    "\n",
    "```\n",
    "print(service.run(input_data = json_data))\n",
    "```\n",
    "\n",
    "その後、推論構成で参照されるスコアリングファイルに変更を加え、サービスを再デプロイせずに再読込することで、  \n",
    "ランタイムの問題をトラブルシューティングできる(ローカルサービスでのみ行うことができる)。\n",
    "\n",
    "```\n",
    "service.reload()\n",
    "print(service.run(input_data = json_data))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527ba546",
   "metadata": {},
   "source": [
    "## 演習 リアルタイムサービスとしてモデルをデプロイする\n",
    "\n",
    "### ワークスペースの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8265fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.28.0 to work with 20210613\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353dd180",
   "metadata": {},
   "source": [
    "### モデルの訓練および登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da54075f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: mslearn-train-diabetes\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8906666666666667\n",
      "AUC: 0.8778496442609085\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name=\"mslearn-train-diabetes\")\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634d05b7",
   "metadata": {},
   "source": [
    "### モデルをWebサービスとしてデプロイする\n",
    "\n",
    "まず、ワークスペースにどのようなモデルが登録されているかを確認する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4e66081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 10\n",
      "\t Training context : Inline Training\n",
      "\t AUC : 0.8778496442609085\n",
      "\t Accuracy : 0.8906666666666667\n",
      "\n",
      "\n",
      "diabetes_model version: 9\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.8854221505732166\n",
      "\t Accuracy : 0.9004444444444445\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Compute cluster\n",
      "\t AUC : 0.8840918562273435\n",
      "\t Accuracy : 0.8991111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568743524381947\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483198169063138\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3313905",
   "metadata": {},
   "source": [
    "デプロイしたいモデルを取得する。デフォルトではモデル名を指定すると最新バージョンが指定される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5bff34d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version 10\n"
     ]
    }
   ],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eee1524",
   "metadata": {},
   "source": [
    "このモデルをホストするためのWebサービスを作成するが、そのためにはいくつかコードと設定ファイルが必要になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb189c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_service folder created.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'diabetes_service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = os.path.join(experiment_folder,\"score_diabetes.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fd507",
   "metadata": {},
   "source": [
    "モデルをデプロイするウェブサービスは、入力データを読み込み、ワークスペースからモデルを取得し、  \n",
    "予測値を生成して返すためのPythonコードが必要になる。  \n",
    "このコードをエントリースクリプト(またはスコアリングスクリプト)に保存し、Webサービスにデプロイする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1dab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./diabetes_service/score_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9623aa05",
   "metadata": {},
   "source": [
    "Webサービスはコンテナでホストされ、コンテナは初期化時に必要なPythonの依存関係をインストールする必要がある。  \n",
    "この場合、スコアリングコードにはscikit-learnがひつようなので、ymlファイルを作成して、  \n",
    "コンテナのホストにscikit-learnを環境にインストールするようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b9bb6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dependency info in ./diabetes_service/diabetes_env.yml\n",
      "# Conda environment specification. The dependencies defined in this file will\n",
      "# be automatically provisioned for runs with userManagedDependencies=False.\n",
      "\n",
      "# Details about the Conda environment file format:\n",
      "# https://conda.io/docs/user-guide/tasks/manage-environments.html#create-env-file-manually\n",
      "\n",
      "name: project_environment\n",
      "dependencies:\n",
      "  # The python interpreter version.\n",
      "  # Currently Azure ML only supports 3.5.2 and later.\n",
      "- python=3.6.2\n",
      "\n",
      "- pip:\n",
      "    # Required packages for AzureML execution, history, and data preparation.\n",
      "  - azureml-defaults\n",
      "\n",
      "- scikit-learn\n",
      "channels:\n",
      "- anaconda\n",
      "- conda-forge\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package('scikit-learn')\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    " = os.path.join(experiment_folder,\"diabetes_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1b361b",
   "metadata": {},
   "source": [
    "デプロイの手順は以下の通り。\n",
    "\n",
    "1. モデルの読み込みと使用に必要なスコアリングと環境ファイルを含む推論構成を定義\n",
    "2. サービスがホストされる実行環境を定義するデプロイメント構成を定義  \n",
    "ここではAzure Container Instanceを使用\n",
    "3. モデルをWebサービスとしてデプロイ\n",
    "4. デプロイされたサービスの状態を確認\n",
    "\n",
    "※詳細URL : https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where\n",
    "\n",
    "デプロイでは、まずコンテナイメージを作成するプロセスが実行され、次にそのイメージに基づいてWebサービスを作成するプロセスが実行されるため時間がかかる。  \n",
    "デプロイが正常に完了すると、ステータスが**Healthy**と表示される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a261976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-06-15 06:32:07+00:00 Creating Container Registry if not exists.\n",
      "2021-06-15 06:32:07+00:00 Registering the environment.\n",
      "2021-06-15 06:32:09+00:00 Building image..\n",
      "2021-06-15 06:39:10+00:00 Generating deployment configuration.\n",
      "2021-06-15 06:39:11+00:00 Submitting deployment to compute..\n",
      "2021-06-15 06:39:50+00:00 Checking the status of deployment diabetes-service..\n",
      "2021-06-15 06:41:37+00:00 Checking the status of inference endpoint diabetes-service.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"diabetes-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4b1ec",
   "metadata": {},
   "source": [
    "うまくいけばデプロイは成功して**Healthy**が表示される。  \n",
    "そうでない場合は、以下のコードを使用してサービスログを取得し、トラブルシューティングに役立てることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9bc28ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-15T06:41:20,209334800+00:00 - rsyslog/run \n",
      "2021-06-15T06:41:20,209813000+00:00 - gunicorn/run \n",
      "2021-06-15T06:41:20,213386100+00:00 - iot-server/run \n",
      "2021-06-15T06:41:20,283973600+00:00 - nginx/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-06-15T06:41:20,770021300+00:00 - iot-server/finish 1 0\n",
      "2021-06-15T06:41:20,775887000+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (72)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 100\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-06-15 06:41:23,265 | root | INFO | Starting up app insights client\n",
      "2021-06-15 06:41:23,266 | root | INFO | Starting up request id generator\n",
      "2021-06-15 06:41:23,266 | root | INFO | Starting up app insight hooks\n",
      "2021-06-15 06:41:23,267 | root | INFO | Invoking user's init function\n",
      "2021-06-15 06:41:24,008 | root | INFO | Users's init has completed successfully\n",
      "/azureml-envs/azureml_4b824bcb98517d791c41923f24d65461/lib/python3.6/site-packages/sklearn/base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "2021-06-15 06:41:24,012 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-06-15 06:41:24,012 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-06-15 06:41:24,013 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-06-15 06:42:11,863 | root | INFO | Swagger file not present\n",
      "2021-06-15 06:42:11,863 | root | INFO | 404\n",
      "127.0.0.1 - - [15/Jun/2021:06:42:11 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-06-15 06:42:17,333 | root | INFO | Swagger file not present\n",
      "2021-06-15 06:42:17,333 | root | INFO | 404\n",
      "127.0.0.1 - - [15/Jun/2021:06:42:17 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())\n",
    "\n",
    "# うまく行かずに再デプロイする必要があれば、以下のコードでサービスを削除する必要がある\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6580356d",
   "metadata": {},
   "source": [
    "以下のコードを実行することで、ワークスペース内のWebサービスの名前を取得することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0fc4fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes-service\n"
     ]
    }
   ],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5489c8",
   "metadata": {},
   "source": [
    "### Webサービスを使う\n",
    "\n",
    "サービスがデプロイされると、今度はクライアントアプリケーションからサービスを使用できるようになる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a66aba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22]\n",
      "diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# リストをjsonファイルのシリアライズ可能なリストへ変換\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# 入力データを渡してWebサービスを呼び出す(Webサービスはバイナリ形式のデータも受け付ける)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# 予測されるクラスを取得する　※これが最初の(かつ唯一の)クラスになる\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455ca8bf",
   "metadata": {},
   "source": [
    "また、複数のデータを送信すると、それぞれの予測値を得ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0b302ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a714a380",
   "metadata": {},
   "source": [
    "上記のコードではAzureML　SDKを使用してコンテナ化されたWebサービスに接続し、それを使用して予測値を生成している。  \n",
    "本番環境では、AzureML SDKを使用せず、単にWebサービスへのHTTPリクエストを行うビジネスアプリケーションによってモデルが消費される可能性がある。\n",
    "\n",
    "これらのアプリケーションがリクエストを送信しなければならないURLを決めよう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3f6ae575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://37bbfafd-1a05-437d-9cdf-3ece0ba3e5c1.westus2.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4a12b8",
   "metadata": {},
   "source": [
    "これでエンドポイントのURLがわかったので、アプリケーションは単純にHTTPリクエストを行い、jsonフォーマットのデータを送信し、  \n",
    "予測されたクラスを受信することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "79c7cf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient [2, 180, 74, 24, 21, 23.9091702, 1.488172308, 22] diabetic\n",
      "Patient [0, 148, 58, 11, 179, 39.19207553, 0.160829008, 45] not-diabetic\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba0ae17",
   "metadata": {},
   "source": [
    "Webサービスを、認証を必要としないAzure Containter Instance(ACI)サービスとして展開した。  \n",
    "これは開発やテストには良いが、本番環境ではAzure Kubernetes Service(AKS)クラスタにデプロイし、  \n",
    "トークンベースの認証を有効にすることを検討する必要がある。\n",
    "この場合、RESTリクエストに**Authorization**ヘッダを含める必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f752f0",
   "metadata": {},
   "source": [
    "### サービスの削除\n",
    "\n",
    "サービスが不要になったら、不要な料金が発生しないように削除しておく。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e7c1dab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service deleted.\n"
     ]
    }
   ],
   "source": [
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1566cbfd",
   "metadata": {},
   "source": [
    "モデルをサービスとして公開することについての詳細情報 : https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0120ecc1",
   "metadata": {},
   "source": [
    "## 知識チェック\n",
    "\n",
    "1. Azure Machine Learning 用の Python SDK を使用して、モデルをトレーニングしました。  \n",
    "高いスケーラビリティとセキュリティを備え、コンテナー化されたリアルタイム サービスとしてモデルをデプロイする必要があります。  \n",
    "このサービスをホストするには、どのような種類のコンピューティングを作成する必要がありますか?\n",
    "    - Azure Kubernetes Service (AKS) 推論クラスター\n",
    "    - GPU を使用するコンピューティング インスタンス\n",
    "    - 複数のノードがあるトレーニング クラスター。\n",
    "\n",
    "\n",
    "2. モデルをリアルタイムの推論サービスとしてデプロイしています。  \n",
    "サービスのエントリ スクリプトには、どのような関数が含まれている必要がありますか?\n",
    "    - main() と score()\n",
    "    - base() と train()\n",
    "    - init() と run()\n",
    "\n",
    "↓解答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3733aa3c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "1. Azure Kubernetes Service (AKS) 推論クラスター\n",
    "    - モデルをスケーラブルで、セキュリティで保護され、コンテナー化されたサービスとしてデプロイするには、  \n",
    "    AKS クラスターを使用する必要があります。\n",
    "\n",
    "\n",
    "2. init() と run()\n",
    "    - エントリ (スコアリング) スクリプトでは、init 関数と run 関数を実装する必要があります。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
