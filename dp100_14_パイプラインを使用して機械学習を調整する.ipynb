{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aaee75b",
   "metadata": {},
   "source": [
    "# dp100_14 パイプライン"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390d7fc7",
   "metadata": {},
   "source": [
    "## パイプラインのステップ\n",
    "\n",
    "- パイプラインは、タスクを実行する1つ以上の\"ステップ\"で構成される\n",
    "- AzureMLパイプラインでの一般的なステップは次の通り。\n",
    "    - PythonScriptStep:\n",
    "        - 指定されたPythonスクリプトを実行する\n",
    "    - DataTransferStep:\n",
    "        - Azure Data Factoryを使用してデータストア間でデータコピー\n",
    "    - DatabriksStep:\n",
    "        - Databricksクラスターでノートブック、スクリプト、またはコンパイル済みJARを実行\n",
    "    - AdlaStep:\n",
    "        - Azure Data Lake AnalyticsでU-SQLジョブを実行する\n",
    "    - ParallelRunStep:\n",
    "        - 複数のコンピューティングノードで分散タスクとしてPythonスクリプトを実行\n",
    "- 作成するには、各ステップを定義してからパイプラインを作成する必要がある\n",
    "    - ステップの作成は`step = PythonScriptStep(name,source_directory,script_name,compute_target)`\n",
    "    - パイプラインの割り当ては`train_pipeline = Pipeline(workspace, steps = [step, ...])`\n",
    "        - エクスペリメントとして実行 `experiment.submit(train_pipeline)`\n",
    "    \n",
    "## パイプラインのステップ間のデータやり取り\n",
    "\n",
    "- `PipelineData`でステップ間のデータのやり取りを行う\n",
    "    - パイプラインデータを`prepped_data = PipelineData('prepped',  datastore=data_store)`\n",
    "    - `arguments`にパイプラインデータを紐付け\n",
    "    - スクリプト自体はローカルフォルダ-のように使用できる\n",
    "- パイプラインはステップを基本的に再利用する\n",
    "    - パイプラインの再利用を無効にしたい場合、`PythonScriptStep(allow_reuse = False)`\n",
    "    - すべてのステップを強制的に実行したい場合、`experiment.submit(regenerate_outputs=True)`を設定\n",
    "\n",
    "## パイプラインの発行\n",
    "\n",
    "- RESTエンドポイントの作成ができる\n",
    "- 発行するには、`published_pipeline = pipeline.publish(name, description, version)`\n",
    "- エクスペリメントが正常に実行されたら、`run.publish_pipeline(name, description, version)`でも発行できる\n",
    "- エンドポイントのURIを`published_pipeline.endpoint`で取得できる\n",
    "\n",
    "## パイプラインパラメータの使用\n",
    "\n",
    "- パイプラインのパラメータを定義したい場合、`reg_param = PipelineParameter(name='reg_rate', default_value=0.01)`をしてから、  \n",
    "`arguments`にてパラメータを追加すればできる\n",
    "\n",
    "## パイプラインのスケジュール設定\n",
    "\n",
    "- `ScheduleRecurrence`で頻度を定義し、`Schedule.create`で作成する必要がある\n",
    "- データの変更をパイプライン実行トリガーにしたい場合、`ath_on_datastore='data/training'`で指定パスを監視する`Schedule`を作成する\n",
    "\n",
    "## よくわからんやつ\n",
    "\n",
    "```\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
