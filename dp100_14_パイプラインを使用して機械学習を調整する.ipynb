{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55777d3",
   "metadata": {},
   "source": [
    "# dp100_14 パイプラインを使用して機械学習を調整する\n",
    "\n",
    "パイプラインという用語は機械学習で広く使用されており、多くの場合意味はさまざま。  \n",
    "たとえば、scikit-learnでは、パイプラインを定義して、データ前処理変換とトレーニングアルゴリズムを組み合わせることができる。  \n",
    "また、Azure DevOpsでは、ビルドまたはリリースのパイプラインを定義して、ソフトウェアの配布に必要なビルドと厚生のタスクを実行できる。  \n",
    "この子ジュールで焦点を当てるのは**AzureMLパイプラインで、これは実験として実行できるステップをカプセル化するため**のもの。  \n",
    "ただし、念頭に置くべき点として、Azure DevOpsパイプラインのなkのタスクによってAzureMLパイプラインを開始させ、  \n",
    "次いでその中にscikit-learnパイプラインを基にモデルをトレーニングするステップを含めても一向に差し支えがない。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b486e8",
   "metadata": {},
   "source": [
    "## パイプラインの概要\n",
    "\n",
    "パイプラインは、各タスクが1つの\"ステップ\"として実装される機械学習タスクのワークフロー。\n",
    "\n",
    "ステップを順番にまたは並列で配置することで、機械学習操作を調整する高度なフローロジックを作成できる。  \n",
    "各ステップは特定のコンピューティング先で実行できるため、必要に応じてさまざまな種類のプロセスを組み合わせて、全体的な目標を達成することができる。\n",
    "\n",
    "パイプラインは1つのプロセスとして実行できる。そのためには、パイプラインを実験として実行する。  \n",
    "パイプライン実行の各ステップは、実験実行全体の一部として、それぞれに割り当てられたコンピューティング先で実行される。\n",
    "\n",
    "パイプラインをRESTエンドポイントとして発行し、クライアントアプリケーションでパイプライン実行を開始できるようにすることができる。  \n",
    "また、パイプラインのスケジュールを定義し、定期的に自動で実行するように設定することもできる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1263efbf",
   "metadata": {},
   "source": [
    "### パイプラインのステップ\n",
    "\n",
    "パイプラインは、タスクを実行する1つ以上の\"ステップ\"で構成される。  \n",
    "AzureMLパイプラインではさまざまな種類のステップがサポートされており、それぞれに固有の目的と構成のオプションがある。\n",
    "\n",
    "AzureMLパイプラインでの一般的なステップは次の通り。\n",
    "\n",
    "- PythonScriptStep:\n",
    "    - 指定されたPythonスクリプトを実行する\n",
    "- DataTransferStep:\n",
    "    - Azure Data Factoryを使用してデータストア間でデータコピー\n",
    "- DatabriksStep:\n",
    "    - Databricksクラスt-あでノートブック、スクリプト、またはコンパイル済みJARを実行\n",
    "- AdlaStep:\n",
    "    - Azure Data Lake AnalyticsでU-SQLジョブを実行する\n",
    "- ParallelRunStep:\n",
    "    - 複数のコンピューティングノードで分散タスクとしてPythonスクリプトを実行\n",
    "    \n",
    "パイプラインを作成するには、まず各ステップを定義してから、それらのステップを含むパイプラインを作成する必要がある。  \n",
    "各ステップの特定の構成は、ステップの種類によって異なる。  \n",
    "たとえば、以下のコードでは、データを準備してモデルをトレーニングするための2つの**PythonScriptStep**ステップが定義される。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Step to run a Python script\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster')\n",
    "\n",
    "# Step to train a model\n",
    "step2 = PythonScriptStep(name = 'train model',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'train_model.py',\n",
    "                         compute_target = 'aml-cluster')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328f79dc",
   "metadata": {},
   "source": [
    "ステップを定義したら、それらをパイプラインに割り当てて、実験として実行できる。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# パイプライン構築\n",
    "train_pipeline = Pipeline(workspace = ws, steps = [step1,step2])\n",
    "\n",
    "# 実験を行い、パイプラインを実行する\n",
    "experiment = Experiment(workspace = ws, name = 'training-pipeline')\n",
    "pipeline_run = experiment.submit(train_pipeline)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f38c2dc8",
   "metadata": {},
   "source": [
    "## パイプラインのステップ間でデータを渡す\n",
    "\n",
    "多くの場合、パイプラインの線には、前のステップの出力に依存するステップが少なくとも1つ含まれている。  \n",
    "例えば、Pythonスクリプトを実行してデータを事前に処理するステップを使用し、これを後続のステップでモデルをトレーニングするために使用する必要がある、という場合が考えられる。\n",
    "\n",
    "### PipelineDataオブジェクト\n",
    "\n",
    "**PipelineData**オブジェクトは、特殊な種類の**DataReference**であり、用途は次の通り。\n",
    "\n",
    "- データストア内の場所を参照する\n",
    "- パイプラインステップ間のデータ依存関係を作成する\n",
    "\n",
    "**PipelineData**オブジェクトは、あるステップから後続のステップに渡す必要があるデータの中間ストアとみなせる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0932b9ec",
   "metadata": {},
   "source": [
    "### PipelineDataステップの入力と出力\n",
    "\n",
    "**PipelineData**オブジェクトを使用してステップ間でデータを渡すには、次の操作を行う必要がある。\n",
    "\n",
    "1. データストア内の場所を参照する、名前付き**PipelineData**オブジェクトを定義する\n",
    "2. スクリプトを実行するステップで、**PipelineData**オブジェクトをスクリプト引数として渡す\n",
    "    - また、データの読み取りまたは書き込みを行うためのコードをスクリプトに含める\n",
    "3. 必要に応じて、ステップの\"入力\"または\"出力\"として**PipelineData**オブジェクトを指定する\n",
    "\n",
    "たとえば、次のコードではステップ間で渡される必要がある前処理されたデータを表す**PipelineData**オブジェクトが定義される。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep, EstimatorStep\n",
    "\n",
    "# Get a dataset for the initial data\n",
    "raw_ds = Dataset.get_by_name(ws, 'raw_dataset')\n",
    "\n",
    "# Define a PipelineData object to pass data between steps\n",
    "data_store = ws.get_default_datastore()\n",
    "prepped_data = PipelineData('prepped',  datastore=data_store)\n",
    "\n",
    "# Step to run a Python script\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         # Script arguments include PipelineData\n",
    "                         arguments = ['--raw-ds', raw_ds.as_named_input('raw_data'),\n",
    "                                      '--out_folder', prepped_data],\n",
    "                         # Specify PipelineData as output\n",
    "                         outputs=[prepped_data])\n",
    "\n",
    "# Step to run an estimator\n",
    "step2 = PythonScriptStep(name = 'train model',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         # Pass as script argument\n",
    "                         arguments=['--in_folder', prepped_data],\n",
    "                         # Specify PipelineData as input\n",
    "                         inputs=[prepped_data])\n",
    "```\n",
    "\n",
    "スクリプト自体の中では、スクリプト引数から**PipelineData**オブジェクトへの参照を取得し、ローカルフォルダのように使用することができる。\n",
    "\n",
    "```\n",
    "# code in data_prep.py\n",
    "from azureml.core import Run\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--raw-ds', type=str, dest='raw_dataset_id')\n",
    "parser.add_argument('--out_folder', type=str, dest='folder')\n",
    "args = parser.parse_args()\n",
    "output_folder = args.folder\n",
    "\n",
    "# Get input dataset as dataframe\n",
    "raw_df = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# code to prep data (in this case, just select specific columns)\n",
    "prepped_df = raw_df[['col1', 'col2', 'col3']]\n",
    "\n",
    "# Save prepped data to the PipelineData location\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "output_path = os.path.join(output_folder, 'prepped_data.csv')\n",
    "prepped_df.to_csv(output_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd18fec5",
   "metadata": {},
   "source": [
    "## パイプラインのステップの再利用\n",
    "\n",
    "実行時間の長いステップが複数あるパイプラインは、完了までにかなりの時間をかかることがある。  \n",
    "AzureMLには、この時間を短縮するためのキャッシュと再利用の機能が含まれている。\n",
    "\n",
    "### ステップの出力の再利用を管理する\n",
    "\n",
    "規定では、前のパイプライン実行のステップ出力は、そのステップのスクリプト、ソースディレクトリ、  \n",
    "その他のパラメータが変更されていない場合に、ステップを再実行せずに再利用される。  \n",
    "ステップを再利用すると、パイプラインの実行にかかる時間を短縮できるが、  \n",
    "ダウンストリームのデータソースへの変更が反映されていない場合は、古い結果になる恐れがある。\n",
    "\n",
    "個々のステップの再利用を制御するには、次のようにステップの構成で**allow_reuse**パラメータを設定する。\n",
    "\n",
    "```\n",
    "step1 = PythonScriptStep(name = 'prepare data',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         runconfig = run_config,\n",
    "                         inputs=[raw_ds.as_named_input('raw_data')],\n",
    "                         outputs=[prepped_data],\n",
    "                         arguments = ['--folder', prepped_data]),\n",
    "                         # Disable step reuse\n",
    "                         allow_reuse = False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa7edc0",
   "metadata": {},
   "source": [
    "### すべてのステップを強制的に実行する\n",
    "\n",
    "複数のステップがある場合、パイプライン実験を送信するときに**regenerate_outputs**パラメータを設定することによって、  \n",
    "個々の再利用の構成に関係なく、すべてのステップを強制的に実行できる。\n",
    "\n",
    "```\n",
    "pipeline_run = experiment.submit(train_pipeline, regenerate_outputs=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fdc219",
   "metadata": {},
   "source": [
    "## パイプラインを発行する\n",
    "\n",
    "パイプラインを作成したらそれを発行し、必要に応じてパイプラインを実行できるようにRESTエンドポイントを作成できる。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d8a610",
   "metadata": {},
   "source": [
    "### パイプラインを発行する\n",
    "\n",
    "パイプラインを発行するには、**publish**メソッドを呼び出すことができる。\n",
    "\n",
    "```\n",
    "published_pipeline = pipeline.publish(name='training_pipeline',\n",
    "                                          description='Model training pipeline',\n",
    "                                          version='1.0')\n",
    "```\n",
    "\n",
    "または、パイプラインが正常に実行されたときに**publish**メソッドを呼び出すこともできる。\n",
    "\n",
    "```\n",
    "# パイプラインの最新の実行結果を取得\n",
    "pipeline_experiment = ws.experiments.get('training-pipeline')\n",
    "run = list(pipeline_experiment.get_runs())[0]\n",
    "\n",
    "# Runからのパイプラインの公開\n",
    "published_pipeline = run.publish_pipeline(name='training_pipeline',\n",
    "                                          description='Model training pipeline',\n",
    "                                          version='1.0')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb52037",
   "metadata": {},
   "source": [
    "パイプラインが発行されると、AzureMLスタジオで確認できる。  \n",
    "以下のようにエンドポイントのURIを決定することもできる。\n",
    "\n",
    "```\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7af5e6",
   "metadata": {},
   "source": [
    "### 発行されたパイプラインを使用する\n",
    "\n",
    "発行されたエンドポイントを開始するには、RESTエンドポイントに対してHTTP要求を行い、  \n",
    "パイプラインを実行するアクセス許可を持つサービスプリンシパルのトークンを指定したAuthorizationヘッダーと、  \n",
    "実験名を指定したJSONペイロードを渡す。  \n",
    "パイプラインは非同期に実行されるため、正常なREST呼び出しからの応答には実行IDが含まれる。これを使用してAzureML下地おでの実行を追跡できる。\n",
    "\n",
    "例えば、次のPythonコードでは、パイプラインを実行するためのREST要求が行われ、返された実行IDが表示される。\n",
    "\n",
    "```\n",
    "import requests\n",
    "\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={\"ExperimentName\": \"run_training_pipeline\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "print(run_id)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba2168",
   "metadata": {},
   "source": [
    "## パイプラインパラメータを使用する\n",
    "\n",
    "パラメータを定義することで、パイプラインの柔軟性を高めることができる。\n",
    "\n",
    "### パイプラインのパラメータを定義する\n",
    "\n",
    "パイプラインのパラメータを定義するには、パラメータごとに**PipelineParameter**オブジェクトを作成し、  \n",
    "各パラメータを少なくとも1つのステップで指定する。\n",
    "\n",
    "たとえば、次のコードを使用して、推定機によって使用されるスクリプトに正規化率を表すパラメータを含めることができる。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core.graph import PipelineParameter\n",
    "\n",
    "reg_param = PipelineParameter(name='reg_rate', default_value=0.01)\n",
    "\n",
    "...\n",
    "\n",
    "step2 = PythonScriptStep(name = 'train model',\n",
    "                         source_directory = 'scripts',\n",
    "                         script_name = 'data_prep.py',\n",
    "                         compute_target = 'aml-cluster',\n",
    "                         # Pass parameter as script argument\n",
    "                         arguments=['--in_folder', prepped_data,\n",
    "                                    '--reg', reg_param],\n",
    "                         inputs=[prepped_data])\n",
    "```\n",
    "\n",
    "> 注:パイプラインを発行する前に、そのパラメータを定義する必要がある\n",
    "\n",
    "### パイプラインを使用してパイプラインを実行する\n",
    "\n",
    "パラメータ化されたパイプラインを発行した後、RESTインターフェイスのJSONペイロードに入れてパラメータ値を渡すことができる。\n",
    "\n",
    "```\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={\"ExperimentName\": \"run_training_pipeline\",\n",
    "                               \"ParameterAssignments\": {\"reg_rate\": 0.1}})\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b04803b",
   "metadata": {},
   "source": [
    "## パイプラインのスケジュール設定\n",
    "\n",
    "パイプラインを発行した後は、RESTエンドポイントを使用して必要に応じてこれを開始できる。  \n",
    "また、定期的なスケジュールに基づいて、またはデータ更新に応じてパイプラインを自動的に実行することもできる。\n",
    "\n",
    "### 定期的な間隔でパイプラインのスケジュールを設定する\n",
    "\n",
    "パイプラインが定期的に実行されるようにスケジュールを設定するには、実行頻度を決定する**ScheduleRecurrence**を定義し、  \n",
    "それを使用して**Schedule**を作成する必要がある。\n",
    "\n",
    "例えば、次のコードを使用すると、発行されたパイプラインが毎日実行されるようスケジュールが設定される。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "daily = ScheduleRecurrence(frequency='Day', interval=1)\n",
    "pipeline_schedule = Schedule.create(ws, name='Daily Training',\n",
    "                                        description='trains model every day',\n",
    "                                        pipeline_id=published_pipeline.id,\n",
    "                                        experiment_name='Training_Pipeline',\n",
    "                                        recurrence=daily)\n",
    "```\n",
    "\n",
    "### データ変更時にパイプライン実行をトリガーする\n",
    "\n",
    "データが変更されるたびにパイプラインが実行されるようにスケジュールを設定するには、  \n",
    "次のようにデータストアの指定されたパスを監視する**Schedule**を作成する必要がある。\n",
    "\n",
    "```\n",
    "from azureml.core import Datastore\n",
    "from azureml.pipeline.core import Schedule\n",
    "\n",
    "training_datastore = Datastore(workspace=ws, name='blob_data')\n",
    "pipeline_schedule = Schedule.create(ws, name='Reactive Training',\n",
    "                                    description='trains model on data change',\n",
    "                                    pipeline_id=published_pipeline_id,\n",
    "                                    experiment_name='Training_Pipeline',\n",
    "                                    datastore=training_datastore,\n",
    "                                    path_on_datastore='data/training')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2d374",
   "metadata": {},
   "source": [
    "## 演習 パイプラインを作成する\n",
    "\n",
    "このノートブックでは、機械学習ソリューションの構築に必要な一連の個別のステップをまとめ、データの前処理、  \n",
    "モデルのトレーニングと登録を行うシンプルなパイプラインを作成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1283747",
   "metadata": {},
   "source": [
    "### ワークスペースの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f7a763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.28.0 to work with 20210613\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafca0ce",
   "metadata": {},
   "source": [
    "### データの準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd168374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6222397b",
   "metadata": {},
   "source": [
    "### パイプラインステップのスクリプト作成\n",
    "\n",
    "パイプラインは1つまたは複数のステップで構成されており、Pythonスクリプトや、データを有る場所から別の場所にコピーするデータ転送ステップなどの特殊なステップがある。  \n",
    "各ステップは、独自のコンピュートコンテキストで実行できる。  \n",
    "この演習では、2つのPythonスクリプトステップを含むシンプルなパイプラインを構築する。  \n",
    "1つはトレーニングデータを前処理するステップで、もう1つは前処理したデータを使ってモデルをトレーニングして登録するステップ。\n",
    "\n",
    "まず、パイプラインのステップで使用するスクリプトファイルのためのフォルダを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "566010e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the pipeline step files\n",
    "experiment_folder = 'diabetes_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d068f0e",
   "metadata": {},
   "source": [
    "最初のスクリプトを作成する。このスクリプトは、糖尿病データセットからデータを読み込み、簡単な前処理を適用して、  \n",
    "データが欠落している行を削除し、数値特徴が同じようなスケールになるように正規化する。\n",
    "\n",
    "このスクリプトには、**--prepped-data**という引数があり、これは結果のデータを保存するフォルダを参照する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f5833f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/prep_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/prep_diabetes.py\n",
    "# Import libraries\n",
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from azureml.core import Run\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
    "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
    "args = parser.parse_args()\n",
    "save_folder = args.prepped_data\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the data (passed as an input dataset)\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
    "\n",
    "# Log raw row count\n",
    "row_count = (len(diabetes))\n",
    "run.log('raw_rows', row_count)\n",
    "\n",
    "# remove nulls\n",
    "diabetes = diabetes.dropna()\n",
    "\n",
    "# Normalize the numeric columns\n",
    "scaler = MinMaxScaler()\n",
    "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
    "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
    "\n",
    "# Log processed rows\n",
    "row_count = (len(diabetes))\n",
    "run.log('processed_rows', row_count)\n",
    "\n",
    "# Save the prepped data\n",
    "print(\"Saving Data...\")\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "save_path = os.path.join(save_folder,'data.csv')\n",
    "diabetes.to_csv(save_path, index=False, header=True)\n",
    "\n",
    "# End the run\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121e790",
   "metadata": {},
   "source": [
    "次に、2つ目のスクリプトを作成する。  \n",
    "スクリプトには、**--training-folder**という引数があり、前のステップで準備したデータが保存されているフォルダを参照する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e57def7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing diabetes_pipeline/train_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/train_diabetes.py\n",
    "# Import libraries\n",
    "from azureml.core import Run, Model\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get parameters\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
    "args = parser.parse_args()\n",
    "training_folder = args.training_folder\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# load the prepared data file in the training folder\n",
    "print(\"Loading Data...\")\n",
    "file_path = os.path.join(training_folder,'data.csv')\n",
    "diabetes = pd.read_csv(file_path)\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train adecision tree model\n",
    "print('Training a decision tree model...')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# plot ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "# Plot the diagonal 50% line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "# Plot the FPR and TPR achieved by our model\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "run.log_image(name = \"ROC\", plot = fig)\n",
    "plt.show()\n",
    "\n",
    "# Save the trained model in the outputs folder\n",
    "print(\"Saving model...\")\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "\n",
    "# Register the model\n",
    "print('Registering model...')\n",
    "Model.register(workspace=run.experiment.workspace,\n",
    "               model_path = model_file,\n",
    "               model_name = 'diabetes_model',\n",
    "               tags={'Training context':'Pipeline'},\n",
    "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
    "\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd0e4de",
   "metadata": {},
   "source": [
    "### パイプラインステップのためのコンピューティング環境の準備\n",
    "\n",
    "必要に応じて各ステップに異なるコンピューティングコンテキストを指定することができる。  \n",
    "まず、前回作成したコンピューティングターゲットを取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ef14ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"msl-20210613b\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        pipeline_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576e11d8",
   "metadata": {},
   "source": [
    "このコンピューティングには、必要なパッケージの依存関係がインストールされたPython環境が必要となるため、  \n",
    "実行設定を作成する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77895ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run configuration created.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.core.runconfig import RunConfiguration\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
    "\n",
    "# Create a set of package dependencies\n",
    "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
    "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n",
    "\n",
    "# Add the dependencies to the environment\n",
    "diabetes_env.python.conda_dependencies = diabetes_packages\n",
    "\n",
    "# Register the environment \n",
    "diabetes_env.register(workspace=ws)\n",
    "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
    "\n",
    "# Create a new runconfig object for the pipeline\n",
    "pipeline_run_config = RunConfiguration()\n",
    "\n",
    "# Use the compute you created above. \n",
    "pipeline_run_config.target = pipeline_cluster\n",
    "\n",
    "# Assign the environment to the run configuration\n",
    "pipeline_run_config.environment = registered_env\n",
    "\n",
    "print (\"Run configuration created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0501b0c",
   "metadata": {},
   "source": [
    "### パイプラインの作成と実行\n",
    "\n",
    "まずパイプラインのステップを定義し、それらの間で渡す必要のあるデータ参照を定義する必要がある。  \n",
    "今回の例では、最初のステップが準備したデータをフォルダに書き込み、2番目のステップがそれを読み込めるようにする。  \n",
    "各ステップはリモートコンピュートで実行されるため(実際にはそれぞれ別のコンピュートで実行される可能性もある)、  \n",
    "フォルダのパスはワークスペース内のデータストアの場所へのデータ参照として渡される必要がある。  \n",
    "PipelineDataオブジェクトは、パイプラインステップ間で渡すことができる中間ストレージの場所に使用される特別な種類のデータ参照なので、  \n",
    "これを作成して最初のステップの出力と2番目のステップの入力として使用する。  \n",
    "また、データ参照によって参照されるデータストアの場所にコードがアクセスできるように、スクリプト引数として渡す必要があることに注意する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2855beaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.steps import PythonScriptStep\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07e52fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PipelineData (temporary Data Reference) for the model folder\n",
    "prepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f4cd8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1, Run the data prep script\n",
    "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"prep_diabetes.py\",\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
    "                                             '--prepped-data', prepped_data_folder],\n",
    "                                outputs=[prepped_data_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1818f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2, run the training script\n",
    "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
    "                                source_directory = experiment_folder,\n",
    "                                script_name = \"train_diabetes.py\",\n",
    "                                arguments = ['--training-folder', prepped_data_folder],\n",
    "                                inputs=[prepped_data_folder],\n",
    "                                compute_target = pipeline_cluster,\n",
    "                                runconfig = pipeline_run_config,\n",
    "                                allow_reuse = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b090837",
   "metadata": {},
   "source": [
    "これで、定義したステップからパイプラインを構築し、実験として実行する準備が整った。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27a745df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline is built.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Construct the pipeline\n",
    "pipeline_steps = [prep_step, train_step]\n",
    "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
    "print(\"Pipeline is built.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723b7b2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step Prepare Data [d29111bb][33517913-ded8-4a97-a34d-83f76102c1bd], (This step will run and generate new outputs)\n",
      "Created step Train and Register Model [b742241d][c2f0785e-c28f-4464-9c23-381bebb1c2f6], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 0268e2e0-be38-4866-82da-aa4a93d1a249\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/0268e2e0-be38-4866-82da-aa4a93d1a249?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "Pipeline submitted for execution.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "888aa45f284d4aba9ff6ac11b82fec71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/0268e2e0-be38-4866-82da-aa4a93d1a249?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\", \"run_id\": \"0268e2e0-be38-4866-82da-aa4a93d1a249\", \"run_properties\": {\"run_id\": \"0268e2e0-be38-4866-82da-aa4a93d1a249\", \"created_utc\": \"2021-06-14T17:43:22.606192Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-06-14T17:59:39.205635Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.0268e2e0-be38-4866-82da-aa4a93d1a249/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=9HOJeyWS00Y29TTuXEN1MEjlo8SDX8Be4xpAffN2LMs%3D&st=2021-06-14T17%3A33%3A45Z&se=2021-06-15T01%3A43%3A45Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.0268e2e0-be38-4866-82da-aa4a93d1a249/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=1ITsf%2BZHOdCWJU%2BZ0wQ7DuERkeNh5LT3vjpSWeqsEp4%3D&st=2021-06-14T17%3A33%3A45Z&se=2021-06-15T01%3A43%3A45Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.0268e2e0-be38-4866-82da-aa4a93d1a249/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=T2L%2F0vIb%2B7gvfD77xnpQlCUgE%2FP5Wt5wg%2BFR0yaCGyI%3D&st=2021-06-14T17%3A33%3A45Z&se=2021-06-15T01%3A43%3A45Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:16:16\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"cc53dec4-6cb1-42c7-bd35-8f3213d63bc2\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-06-14T17:56:27.29606Z\", \"created_time\": \"2021-06-14T17:43:26.324077Z\", \"end_time\": \"2021-06-14T17:58:35.30575Z\", \"duration\": \"0:15:08\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-14T17:43:26.324077Z\", \"is_reused\": \"\"}, {\"run_id\": \"e774011e-35ac-41be-a84c-ce20bdc56a52\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-06-14T17:58:49.953484Z\", \"created_time\": \"2021-06-14T17:58:37.512925Z\", \"end_time\": \"2021-06-14T17:59:37.099595Z\", \"duration\": \"0:00:59\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-14T17:58:37.512925Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-06-14 17:43:26Z] Submitting 1 runs, first five are: d29111bb:cc53dec4-6cb1-42c7-bd35-8f3213d63bc2\\n[2021-06-14 17:58:37Z] Completing processing run id cc53dec4-6cb1-42c7-bd35-8f3213d63bc2.\\n[2021-06-14 17:58:37Z] Submitting 1 runs, first five are: b742241d:e774011e-35ac-41be-a84c-ce20bdc56a52\\n[2021-06-14 17:59:38Z] Completing processing run id e774011e-35ac-41be-a84c-ce20bdc56a52.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"128580f0\": {\"node_id\": \"128580f0\", \"name\": \"diabetes dataset\"}}, \"module_nodes\": {\"d29111bb\": {\"node_id\": \"d29111bb\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"cc53dec4-6cb1-42c7-bd35-8f3213d63bc2\"}, \"b742241d\": {\"node_id\": \"b742241d\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"e774011e-35ac-41be-a84c-ce20bdc56a52\"}}, \"edges\": [{\"source_node_id\": \"128580f0\", \"source_node_name\": \"diabetes dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"d29111bb\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"d29111bb\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data_folder\", \"target_name\": \"prepped_data_folder\", \"dst_node_id\": \"b742241d\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"cc53dec4-6cb1-42c7-bd35-8f3213d63bc2\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-06-14T17:56:27.29606Z\", \"created_time\": \"2021-06-14T17:43:26.324077Z\", \"end_time\": \"2021-06-14T17:58:35.30575Z\", \"duration\": \"0:15:08\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-14T17:43:26.324077Z\", \"is_reused\": \"\"}, {\"run_id\": \"e774011e-35ac-41be-a84c-ce20bdc56a52\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-06-14T17:58:49.953484Z\", \"created_time\": \"2021-06-14T17:58:37.512925Z\", \"end_time\": \"2021-06-14T17:59:37.099595Z\", \"duration\": \"0:00:59\", \"run_number\": 3, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-06-14T17:58:37.512925Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.28.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 0268e2e0-be38-4866-82da-aa4a93d1a249\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/0268e2e0-be38-4866-82da-aa4a93d1a249?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: cc53dec4-6cb1-42c7-bd35-8f3213d63bc2\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/cc53dec4-6cb1-42c7-bd35-8f3213d63bc2?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "StepRun( Prepare Data ) Status: NotStarted\n",
      "StepRun( Prepare Data ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/06/14 17:43:37 Downloading source code...\n",
      "2021/06/14 17:43:38 Finished downloading source code\n",
      "2021/06/14 17:43:38 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/06/14 17:43:39 Successfully set up Docker network: acb_default_network\n",
      "2021/06/14 17:43:39 Setting up Docker configuration...\n",
      "2021/06/14 17:43:39 Successfully set up Docker configuration\n",
      "2021/06/14 17:43:39 Logging in to registry: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "2021/06/14 17:43:40 Successfully logged into 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "2021/06/14 17:43:40 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/06/14 17:43:40 Scanning for dependencies...\n",
      "2021/06/14 17:43:41 Successfully scanned dependencies\n",
      "2021/06/14 17:43:41 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1@sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1@sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "d519e2592276: Pulling fs layer\n",
      "d22d2dfcfa9c: Pulling fs layer\n",
      "b3afe92c540b: Pulling fs layer\n",
      "b45c209a4d67: Pulling fs layer\n",
      "3f5a608df989: Pulling fs layer\n",
      "11df60c3c446: Pulling fs layer\n",
      "3306300f7441: Pulling fs layer\n",
      "d5f61fd90197: Pulling fs layer\n",
      "3c91cee49561: Pulling fs layer\n",
      "3166a3588baf: Pulling fs layer\n",
      "386667a0fc79: Pulling fs layer\n",
      "b45c209a4d67: Waiting\n",
      "3f5a608df989: Waiting\n",
      "3c91cee49561: Waiting\n",
      "3166a3588baf: Waiting\n",
      "386667a0fc79: Waiting\n",
      "11df60c3c446: Waiting\n",
      "3306300f7441: Waiting\n",
      "d5f61fd90197: Waiting\n",
      "d22d2dfcfa9c: Verifying Checksum\n",
      "d22d2dfcfa9c: Download complete\n",
      "b3afe92c540b: Verifying Checksum\n",
      "b3afe92c540b: Download complete\n",
      "d519e2592276: Verifying Checksum\n",
      "d519e2592276: Download complete\n",
      "3f5a608df989: Verifying Checksum\n",
      "3f5a608df989: Download complete\n",
      "11df60c3c446: Verifying Checksum\n",
      "11df60c3c446: Download complete\n",
      "d5f61fd90197: Verifying Checksum\n",
      "d5f61fd90197: Download complete\n",
      "b45c209a4d67: Verifying Checksum\n",
      "b45c209a4d67: Download complete\n",
      "3166a3588baf: Verifying Checksum\n",
      "3166a3588baf: Download complete\n",
      "386667a0fc79: Verifying Checksum\n",
      "386667a0fc79: Download complete\n",
      "d519e2592276: Pull complete\n",
      "d22d2dfcfa9c: Pull complete\n",
      "b3afe92c540b: Pull complete\n",
      "3c91cee49561: Verifying Checksum\n",
      "3c91cee49561: Download complete\n",
      "3306300f7441: Verifying Checksum\n",
      "3306300f7441: Download complete\n",
      "b45c209a4d67: Pull complete\n",
      "3f5a608df989: Pull complete\n",
      "11df60c3c446: Pull complete\n",
      "3306300f7441: Pull complete\n",
      "d5f61fd90197: Pull complete\n",
      "3c91cee49561: Pull complete\n",
      "3166a3588baf: Pull complete\n",
      "386667a0fc79: Pull complete\n",
      "Digest: sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1@sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      " ---> 821000375236\n",
      "Step 2/18 : USER root\n",
      " ---> Running in cf6c7ea633c3\n",
      "Removing intermediate container cf6c7ea633c3\n",
      " ---> 9f7c356cb62b\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in 93fca860ddff\n",
      "Removing intermediate container 93fca860ddff\n",
      " ---> aad8dceb05f5\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in 9a05c8e8417a\n",
      "Removing intermediate container 9a05c8e8417a\n",
      " ---> 3deec3cb2184\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> dcaa5ff171ae\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in bd96d416eb86\n",
      "Removing intermediate container bd96d416eb86\n",
      " ---> 0f19872ea9db\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> 45b58c550d15\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 0ea45375871d\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "libxml2-2.9.10       | 1.3 MB    |            |   0% \n",
      "libxml2-2.9.10       | 1.3 MB    | #4         |  14% \n",
      "libxml2-2.9.10       | 1.3 MB    | ########## | 100% \n",
      "libxml2-2.9.10       | 1.3 MB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "dbus-1.13.18         | 586 KB    |            |   0% \n",
      "dbus-1.13.18         | 586 KB    | ########## | 100% \n",
      "dbus-1.13.18         | 586 KB    | ########## | 100% \n",
      "\n",
      "pyzmq-19.0.2         | 479 KB    |            |   0% \n",
      "pyzmq-19.0.2         | 479 KB    | ########## | 100% \n",
      "pyzmq-19.0.2         | 479 KB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
      "scipy-1.5.2          | 18.5 MB   | 7          |   7% \n",
      "scipy-1.5.2          | 18.5 MB   | ##6        |  26% \n",
      "scipy-1.5.2          | 18.5 MB   | ######     |  60% \n",
      "scipy-1.5.2          | 18.5 MB   | ########2  |  83% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "\n",
      "pillow-8.0.0         | 675 KB    |            |   0% \n",
      "pillow-8.0.0         | 675 KB    | ########## | 100% \n",
      "pillow-8.0.0         | 675 KB    | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "pexpect-4.8.0        | 84 KB     |            |   0% \n",
      "pexpect-4.8.0        | 84 KB     | ########## | 100% \n",
      "\n",
      "qt-5.9.6             | 86.7 MB   |            |   0% \n",
      "qt-5.9.6             | 86.7 MB   | 6          |   7% \n",
      "qt-5.9.6             | 86.7 MB   | #9         |  20% \n",
      "qt-5.9.6             | 86.7 MB   | ###2       |  33% \n",
      "qt-5.9.6             | 86.7 MB   | ####3      |  43% \n",
      "qt-5.9.6             | 86.7 MB   | #####4     |  54% \n",
      "qt-5.9.6             | 86.7 MB   | ######6    |  66% \n",
      "qt-5.9.6             | 86.7 MB   | #######9   |  79% \n",
      "qt-5.9.6             | 86.7 MB   | #########1 |  92% \n",
      "\n",
      "qt-5.9.6             | 86.7 MB   | ########## | 100% \n",
      "\n",
      "ipython-7.16.1       | 1.1 MB    |            |   0% \n",
      "ipython-7.16.1       | 1.1 MB    | #####      |  50% \n",
      "ipython-7.16.1       | 1.1 MB    | ########## | 100% \n",
      "ipython-7.16.1       | 1.1 MB    | ########## | 100% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  |            |   1% \n",
      "mkl-2019.4           | 204.1 MB  | 2          |   2% \n",
      "mkl-2019.4           | 204.1 MB  | 4          |   4% \n",
      "mkl-2019.4           | 204.1 MB  | 7          |   8% \n",
      "mkl-2019.4           | 204.1 MB  | #2         |  12% \n",
      "mkl-2019.4           | 204.1 MB  | #6         |  17% \n",
      "mkl-2019.4           | 204.1 MB  | ##1        |  22% \n",
      "mkl-2019.4           | 204.1 MB  | ##6        |  26% \n",
      "mkl-2019.4           | 204.1 MB  | ###        |  31% \n",
      "mkl-2019.4           | 204.1 MB  | ###4       |  35% \n",
      "mkl-2019.4           | 204.1 MB  | ###8       |  39% \n",
      "mkl-2019.4           | 204.1 MB  | ####2      |  42% \n",
      "mkl-2019.4           | 204.1 MB  | ####6      |  47% \n",
      "mkl-2019.4           | 204.1 MB  | #####      |  51% \n",
      "mkl-2019.4           | 204.1 MB  | #####5     |  55% \n",
      "mkl-2019.4           | 204.1 MB  | ######     |  60% \n",
      "mkl-2019.4           | 204.1 MB  | ######4    |  64% \n",
      "mkl-2019.4           | 204.1 MB  | ######9    |  69% \n",
      "mkl-2019.4           | 204.1 MB  | #######4   |  74% \n",
      "mkl-2019.4           | 204.1 MB  | #######8   |  79% \n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  84% \n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  93% \n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  98% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "\n",
      "libuuid-1.0.3        | 16 KB     |            |   0% \n",
      "libuuid-1.0.3        | 16 KB     | ########## | 100% \n",
      "\n",
      "gst-plugins-base-1.1 | 6.3 MB    |            |   0% \n",
      "gst-plugins-base-1.1 | 6.3 MB    | ########8  |  89% \n",
      "gst-plugins-base-1.1 | 6.3 MB    | ########## | 100% \n",
      "\n",
      "glib-2.56.2          | 5.0 MB    |            |   0% \n",
      "glib-2.56.2          | 5.0 MB    | ########## | 100% \n",
      "glib-2.56.2          | 5.0 MB    | ########## | 100% \n",
      "\n",
      "ipython_genutils-0.2 | 39 KB     |            |   0% \n",
      "ipython_genutils-0.2 | 39 KB     | ########## | 100% \n",
      "\n",
      "pickleshare-0.7.5    | 13 KB     |            |   0% \n",
      "pickleshare-0.7.5    | 13 KB     | ########## | 100% \n",
      "\n",
      "jupyter_client-6.1.7 | 76 KB     |            |   0% \n",
      "jupyter_client-6.1.7 | 76 KB     | ########## | 100% \n",
      "\n",
      "decorator-4.4.2      | 14 KB     |            |   0% \n",
      "decorator-4.4.2      | 14 KB     | ########## | 100% \n",
      "\n",
      "zstd-1.4.4           | 1006 KB   |            |   0% \n",
      "zstd-1.4.4           | 1006 KB   | ########## | 100% \n",
      "zstd-1.4.4           | 1006 KB   | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "\n",
      "gstreamer-1.14.0     | 3.8 MB    |            |   0% \n",
      "gstreamer-1.14.0     | 3.8 MB    | ########## | 100% \n",
      "gstreamer-1.14.0     | 3.8 MB    | ########## | 100% \n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "lcms2-2.11           | 419 KB    |            |   0% \n",
      "lcms2-2.11           | 419 KB    | ########## | 100% \n",
      "lcms2-2.11           | 419 KB    | ########## | 100% \n",
      "\n",
      "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "\n",
      "pyqt-5.9.2           | 5.6 MB    |            |   0% \n",
      "pyqt-5.9.2           | 5.6 MB    | ####1      |  41% \n",
      "pyqt-5.9.2           | 5.6 MB    | ########## | 100% \n",
      "pyqt-5.9.2           | 5.6 MB    | ########## | 100% \n",
      "\n",
      "lz4-c-1.9.2          | 203 KB    |            |   0% \n",
      "lz4-c-1.9.2          | 203 KB    | ########## | 100% \n",
      "lz4-c-1.9.2          | 203 KB    | ########## | 100% \n",
      "\n",
      "libpng-1.6.37        | 364 KB    |            |   0% \n",
      "libpng-1.6.37        | 364 KB    | ########## | 100% \n",
      "libpng-1.6.37        | 364 KB    | ########## | 100% \n",
      "\n",
      "freetype-2.10.4      | 901 KB    |            |   0% \n",
      "freetype-2.10.4      | 901 KB    | ########## | 100% \n",
      "freetype-2.10.4      | 901 KB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "six-1.15.0           | 13 KB     |            |   0% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "\n",
      "wcwidth-0.2.5        | 37 KB     |            |   0% \n",
      "wcwidth-0.2.5        | 37 KB     | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "\n",
      "jpeg-9b              | 247 KB    |            |   0% \n",
      "jpeg-9b              | 247 KB    | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "numpy-1.19.1         | 20 KB     |            |   0% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "zeromq-4.3.3         | 678 KB    |            |   0% \n",
      "zeromq-4.3.3         | 678 KB    | ########## | 100% \n",
      "zeromq-4.3.3         | 678 KB    | ########## | 100% \n",
      "\n",
      "pyparsing-2.4.7      | 64 KB     |            |   0% \n",
      "pyparsing-2.4.7      | 64 KB     | ########## | 100% \n",
      "\n",
      "pcre-8.44            | 269 KB    |            |   0% \n",
      "pcre-8.44            | 269 KB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "\n",
      "jedi-0.17.2          | 952 KB    |            |   0% \n",
      "jedi-0.17.2          | 952 KB    | ########## | 100% \n",
      "jedi-0.17.2          | 952 KB    | ########## | 100% \n",
      "\n",
      "sip-4.19.24          | 297 KB    |            |   0% \n",
      "sip-4.19.24          | 297 KB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "kiwisolver-1.2.0     | 91 KB     |            |   0% \n",
      "kiwisolver-1.2.0     | 91 KB     | ########## | 100% \n",
      "\n",
      "prompt-toolkit-3.0.8 | 244 KB    |            |   0% \n",
      "prompt-toolkit-3.0.8 | 244 KB    | ########## | 100% \n",
      "prompt-toolkit-3.0.8 | 244 KB    | ########## | 100% \n",
      "\n",
      "cycler-0.10.0        | 13 KB     |            |   0% \n",
      "cycler-0.10.0        | 13 KB     | ########## | 100% \n",
      "\n",
      "libsodium-1.0.18     | 387 KB    |            |   0% \n",
      "libsodium-1.0.18     | 387 KB    | ########## | 100% \n",
      "libsodium-1.0.18     | 387 KB    | ########## | 100% \n",
      "\n",
      "pandas-1.1.3         | 10.5 MB   |            |   0% \n",
      "pandas-1.1.3         | 10.5 MB   | ####6      |  46% \n",
      "pandas-1.1.3         | 10.5 MB   | ########## | 100% \n",
      "pandas-1.1.3         | 10.5 MB   | ########## | 100% \n",
      "\n",
      "ipykernel-5.3.4      | 176 KB    |            |   0% \n",
      "ipykernel-5.3.4      | 176 KB    | ########## | 100% \n",
      "\n",
      "parso-0.7.0          | 71 KB     |            |   0% \n",
      "parso-0.7.0          | 71 KB     | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "traitlets-4.3.3      | 137 KB    |            |   0% \n",
      "traitlets-4.3.3      | 137 KB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "\n",
      "tornado-6.0.4        | 650 KB    |            |   0% \n",
      "tornado-6.0.4        | 650 KB    | ########## | 100% \n",
      "tornado-6.0.4        | 650 KB    | ########## | 100% \n",
      "\n",
      "matplotlib-base-3.3. | 6.7 MB    |            |   0% \n",
      "matplotlib-base-3.3. | 6.7 MB    | #########6 |  96% \n",
      "matplotlib-base-3.3. | 6.7 MB    | ########## | 100% \n",
      "\n",
      "matplotlib-3.3.1     | 24 KB     |            |   0% \n",
      "matplotlib-3.3.1     | 24 KB     | ########## | 100% \n",
      "\n",
      "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "\n",
      "pygments-2.7.1       | 704 KB    |            |   0% \n",
      "pygments-2.7.1       | 704 KB    | ########## | 100% \n",
      "pygments-2.7.1       | 704 KB    | ########## | 100% \n",
      "\n",
      "libxcb-1.14          | 610 KB    |            |   0% \n",
      "libxcb-1.14          | 610 KB    | ########## | 100% \n",
      "libxcb-1.14          | 610 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########   |  80% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "jupyter_core-4.6.3   | 75 KB     |            |   0% \n",
      "jupyter_core-4.6.3   | 75 KB     | ########## | 100% \n",
      "\n",
      "backcall-0.2.0       | 14 KB     |            |   0% \n",
      "backcall-0.2.0       | 14 KB     | ########## | 100% \n",
      "\n",
      "fontconfig-2.13.0    | 291 KB    |            |   0% \n",
      "fontconfig-2.13.0    | 291 KB    | ########## | 100% \n",
      "\n",
      "expat-2.2.10         | 192 KB    |            |   0% \n",
      "expat-2.2.10         | 192 KB    | ########## | 100% \n",
      "\n",
      "ptyprocess-0.6.0     | 23 KB     |            |   0% \n",
      "ptyprocess-0.6.0     | 23 KB     | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "joblib-0.17.0        | 205 KB    |            |   0% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "\n",
      "icu-58.2             | 22.7 MB   |            |   0% \n",
      "icu-58.2             | 22.7 MB   | ##4        |  24% \n",
      "icu-58.2             | 22.7 MB   | #######1   |  72% \n",
      "icu-58.2             | 22.7 MB   | ########## | 100% \n",
      "icu-58.2             | 22.7 MB   | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "pytz-2020.1          | 239 KB    |            |   0% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "pytz-2020.1          | 239 KB    | ########## | 100% \n",
      "\n",
      "olefile-0.46         | 48 KB     |            |   0% \n",
      "olefile-0.46         | 48 KB     | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "\n",
      "libtiff-4.1.0        | 607 KB    |            |   0% \n",
      "libtiff-4.1.0        | 607 KB    | ########## | 100% \n",
      "libtiff-4.1.0        | 607 KB    | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "python-dateutil-2.8. | 224 KB    |            |   0% \n",
      "python-dateutil-2.8. | 224 KB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | ##3        |  24% \n",
      "python-3.6.2         | 27.0 MB   | ####7      |  48% \n",
      "python-3.6.2         | 27.0 MB   | #######3   |  73% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.88v0ow69.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults~=1.28.0\n",
      "  Downloading azureml_defaults-1.28.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting azureml-dataprep[pandas]\n",
      "  Downloading azureml_dataprep-2.18.0-py3-none-any.whl (39.4 MB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-4.0.1-cp36-cp36m-manylinux2014_x86_64.whl (21.9 MB)\n",
      "Collecting azureml-core~=1.28.0\n",
      "  Downloading azureml_core-1.28.0.post1-py3-none-any.whl (2.2 MB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.28.0\n",
      "  Downloading azureml_dataset_runtime-1.28.0-py3-none-any.whl (3.5 kB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-native<37.0.0,>=36.0.0\n",
      "  Downloading azureml_dataprep_native-36.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.21-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting azureml-dataprep-rslex<1.17.0a,>=1.16.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (83.9 MB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied, skipping upgrade: pandas<2.0.0,>=0.23.4; extra == \"pandas\" in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 2)) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>=1.14.0; extra == \"pandas\" in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from azureml-dataprep[pandas]->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 2)) (1.19.1)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.7.3 in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from azureml-core~=1.28.0->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 1)) (2.8.1)\n",
      "Collecting requests<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting docker<5.0.0\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied, skipping upgrade: pytz in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from azureml-core~=1.28.0->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 1)) (2020.1)\n",
      "Collecting ruamel.yaml<0.17.5,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting contextlib2<1.0.0\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-8.0.0-py2.py3-none-any.whl (663 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=3.0 in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 1)) (50.3.0.post20201006)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 1)) (1.15.0)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.12.0-py2.py3-none-any.whl (66 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.15.0-py2.py3-none-any.whl (138 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib/python3.6/site-packages (from requests<3.0.0,>=2.19.1->azureml-core~=1.28.0->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.88v0ow69.requirements.txt (line 1)) (2020.6.20)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.5.0-py3-none-any.whl (17 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=dc2249be9c62bb7d2fa85010efe86d746f07a25b36c98ebb1f0599cc2ad5c2ef\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=c54b04836aa764f83f135726120529e1a82d7d493357461bab55f0386da86ca8\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=9164e5567181eec1b32fd82c370946313cb387ae9c6e926f3221498f22fc2299\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built json-logging-py fusepy liac-arff\n",
      "Installing collected packages: PyJWT, urllib3, chardet, idna, requests, websocket-client, docker, azure-common, oauthlib, requests-oauthlib, isodate, msrest, pycparser, cffi, cryptography, adal, msrestazure, azure-graphrbac, typing-extensions, zipp, importlib-metadata, jsonpickle, ruamel.yaml.clib, ruamel.yaml, azure-mgmt-resource, backports.weakref, backports.tempfile, pathspec, jmespath, jeepney, SecretStorage, azure-mgmt-storage, azure-mgmt-authorization, contextlib2, azure-mgmt-keyvault, pyopenssl, pyasn1, ndg-httpsclient, azure-core, azure-mgmt-core, azure-mgmt-containerregistry, azureml-core, gunicorn, werkzeug, applicationinsights, msal, portalocker, msal-extensions, azure-identity, azureml-dataprep-native, distro, dotnetcore2, azureml-dataprep-rslex, cloudpickle, pyarrow, azureml-dataprep, fusepy, azureml-dataset-runtime, dill, liac-arff, azureml-model-management-sdk, json-logging-py, itsdangerous, MarkupSafe, Jinja2, click, flask, configparser, azureml-defaults\n",
      "Successfully installed Jinja2-3.0.1 MarkupSafe-2.0.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.15.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.0.0 azure-mgmt-core-1.2.2 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.28.0.post1 azureml-dataprep-2.18.0 azureml-dataprep-native-36.0.0 azureml-dataprep-rslex-1.16.0 azureml-dataset-runtime-1.28.0 azureml-defaults-1.28.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-8.0.1 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.4.7 dill-0.3.4 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.21 flask-1.0.3 fusepy-3.0.1 gunicorn-20.1.0 idna-2.10 importlib-metadata-4.5.0 isodate-0.6.0 itsdangerous-2.0.1 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.12.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.1 pathspec-0.8.1 portalocker-1.7.1 pyarrow-4.0.1 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 typing-extensions-3.10.0.0 urllib3-1.26.5 websocket-client-1.1.0 werkzeug-1.0.1 zipp-3.4.1\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.10.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 0ea45375871d\n",
      " ---> f74f3ee2a0be\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/bin:$PATH\n",
      " ---> Running in 5e2a6b32557d\n",
      "Removing intermediate container 5e2a6b32557d\n",
      " ---> 5cb28536b493\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 0dfc1c85c5a3\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 6ae0f4b2da26\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e\n",
      " ---> Running in 9deaab954f87\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 9deaab954f87\n",
      " ---> b20160d7e347\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e\n",
      " ---> Running in 61ab82cf1b0c\n",
      "Removing intermediate container 61ab82cf1b0c\n",
      " ---> f999078ed5a4\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in e1c1772fad92\n",
      "Removing intermediate container e1c1772fad92\n",
      " ---> a7e776e1c100\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 5301db6d5094\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 5a8409b072fc\n",
      "Removing intermediate container 5a8409b072fc\n",
      " ---> 28c1b1e40b36\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 502ab4a51fc8\n",
      "Removing intermediate container 502ab4a51fc8\n",
      " ---> bdeb879e22e4\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in b17dc400f41d\n",
      "Removing intermediate container b17dc400f41d\n",
      " ---> dc43680aa4a3\n",
      "Successfully built dc43680aa4a3\n",
      "Successfully tagged 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:latest\n",
      "Successfully tagged 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:1\n",
      "2021/06/14 17:49:47 Successfully executed container: acb_step_0\n",
      "2021/06/14 17:49:47 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/06/14 17:49:47 Pushing image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:1, attempt 1\n",
      "The push refers to repository [322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb]\n",
      "88fa3e5af1d9: Preparing\n",
      "485a91d10ff5: Preparing\n",
      "566db4c50612: Preparing\n",
      "cf6d7040b3ed: Preparing\n",
      "9027bc0608c7: Preparing\n",
      "c582247a9ab2: Preparing\n",
      "c145aa22509d: Preparing\n",
      "e770a6511c57: Preparing\n",
      "92ffca78f92b: Preparing\n",
      "5a817c02ccf1: Preparing\n",
      "08d6fac9c4d0: Preparing\n",
      "de5226ffdd67: Preparing\n",
      "8d9f57db5cd6: Preparing\n",
      "09de504e442b: Preparing\n",
      "f86a0c2bc4c2: Preparing\n",
      "cb3dceea19cb: Preparing\n",
      "f5257ad8a814: Preparing\n",
      "9f10818f1f96: Preparing\n",
      "27502392e386: Preparing\n",
      "c95d2191d777: Preparing\n",
      "c582247a9ab2: Waiting\n",
      "c145aa22509d: Waiting\n",
      "e770a6511c57: Waiting\n",
      "92ffca78f92b: Waiting\n",
      "5a817c02ccf1: Waiting\n",
      "08d6fac9c4d0: Waiting\n",
      "de5226ffdd67: Waiting\n",
      "09de504e442b: Waiting\n",
      "f86a0c2bc4c2: Waiting\n",
      "cb3dceea19cb: Waiting\n",
      "f5257ad8a814: Waiting\n",
      "9f10818f1f96: Waiting\n",
      "27502392e386: Waiting\n",
      "c95d2191d777: Waiting\n",
      "8d9f57db5cd6: Waiting\n",
      "88fa3e5af1d9: Pushed\n",
      "cf6d7040b3ed: Pushed\n",
      "566db4c50612: Pushed\n",
      "485a91d10ff5: Pushed\n",
      "c145aa22509d: Pushed\n",
      "c582247a9ab2: Pushed\n",
      "e770a6511c57: Pushed\n",
      "92ffca78f92b: Pushed\n",
      "08d6fac9c4d0: Pushed\n",
      "5a817c02ccf1: Pushed\n",
      "de5226ffdd67: Pushed\n",
      "8d9f57db5cd6: Pushed\n",
      "\n",
      "cb3dceea19cb: Pushed\n",
      "9f10818f1f96: Pushed\n",
      "27502392e386: Pushed\n",
      "f86a0c2bc4c2: Pushed\n",
      "c95d2191d777: Pushed\n",
      "09de504e442b: Pushed\n",
      "f5257ad8a814: Pushed\n",
      "9027bc0608c7: Pushed\n",
      "1: digest: sha256:a0b98364676f03cc296bb39ef84ba0799aff54d968c34d16cc4c3b8fedf1c36a size: 4513\n",
      "2021/06/14 17:52:46 Successfully pushed image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:1\n",
      "2021/06/14 17:52:46 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/06/14 17:52:46 Pushing image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:latest, attempt 1\n",
      "The push refers to repository [322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb]\n",
      "88fa3e5af1d9: Preparing\n",
      "485a91d10ff5: Preparing\n",
      "566db4c50612: Preparing\n",
      "cf6d7040b3ed: Preparing\n",
      "9027bc0608c7: Preparing\n",
      "c582247a9ab2: Preparing\n",
      "c145aa22509d: Preparing\n",
      "e770a6511c57: Preparing\n",
      "92ffca78f92b: Preparing\n",
      "5a817c02ccf1: Preparing\n",
      "08d6fac9c4d0: Preparing\n",
      "de5226ffdd67: Preparing\n",
      "8d9f57db5cd6: Preparing\n",
      "09de504e442b: Preparing\n",
      "f86a0c2bc4c2: Preparing\n",
      "cb3dceea19cb: Preparing\n",
      "f5257ad8a814: Preparing\n",
      "9f10818f1f96: Preparing\n",
      "27502392e386: Preparing\n",
      "c95d2191d777: Preparing\n",
      "c145aa22509d: Waiting\n",
      "e770a6511c57: Waiting\n",
      "92ffca78f92b: Waiting\n",
      "5a817c02ccf1: Waiting\n",
      "08d6fac9c4d0: Waiting\n",
      "de5226ffdd67: Waiting\n",
      "8d9f57db5cd6: Waiting\n",
      "09de504e442b: Waiting\n",
      "f86a0c2bc4c2: Waiting\n",
      "cb3dceea19cb: Waiting\n",
      "f5257ad8a814: Waiting\n",
      "9f10818f1f96: Waiting\n",
      "27502392e386: Waiting\n",
      "c95d2191d777: Waiting\n",
      "c582247a9ab2: Waiting\n",
      "cf6d7040b3ed: Layer already exists\n",
      "88fa3e5af1d9: Layer already exists\n",
      "9027bc0608c7: Layer already exists\n",
      "485a91d10ff5: Layer already exists\n",
      "566db4c50612: Layer already exists\n",
      "c145aa22509d: Layer already exists\n",
      "c582247a9ab2: Layer already exists\n",
      "5a817c02ccf1: Layer already exists\n",
      "92ffca78f92b: Layer already exists\n",
      "e770a6511c57: Layer already exists\n",
      "08d6fac9c4d0: Layer already exists\n",
      "de5226ffdd67: Layer already exists\n",
      "09de504e442b: Layer already exists\n",
      "f86a0c2bc4c2: Layer already exists\n",
      "cb3dceea19cb: Layer already exists\n",
      "8d9f57db5cd6: Layer already exists\n",
      "f5257ad8a814: Layer already exists\n",
      "9f10818f1f96: Layer already exists\n",
      "c95d2191d777: Layer already exists\n",
      "27502392e386: Layer already exists\n",
      "latest: digest: sha256:a0b98364676f03cc296bb39ef84ba0799aff54d968c34d16cc4c3b8fedf1c36a size: 4513\n",
      "2021/06/14 17:52:53 Successfully pushed image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:latest\n",
      "2021/06/14 17:52:53 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 366.162396)\n",
      "2021/06/14 17:52:53 Populating digests for step ID: acb_step_0...\n",
      "2021/06/14 17:52:58 Successfully populated digests for step ID: acb_step_0\n",
      "2021/06/14 17:52:58 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 179.054064)\n",
      "2021/06/14 17:52:58 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 7.034620)\n",
      "2021/06/14 17:52:58 The following dependencies were found:\n",
      "2021/06/14 17:52:58 \n",
      "- image:\n",
      "    registry: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "    repository: azureml/azureml_e96989a292f63f7b1f52525986a204bb\n",
      "    tag: latest\n",
      "    digest: sha256:a0b98364676f03cc296bb39ef84ba0799aff54d968c34d16cc4c3b8fedf1c36a\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210301.v1\n",
      "    digest: sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "    repository: azureml/azureml_e96989a292f63f7b1f52525986a204bb\n",
      "    tag: \"1\"\n",
      "    digest: sha256:a0b98364676f03cc296bb39ef84ba0799aff54d968c34d16cc4c3b8fedf1c36a\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210301.v1\n",
      "    digest: sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cc2 was successful after 9m22s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-14T17:56:25Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/mounts/workspaceblobstore\n",
      "2021-06-14T17:56:25Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-14T17:56:26Z Starting output-watcher...\n",
      "2021-06-14T17:56:26Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-14T17:56:26Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-06-14T17:56:26Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_e96989a292f63f7b1f52525986a204bb\n",
      "d519e2592276: Pulling fs layer\n",
      "d22d2dfcfa9c: Pulling fs layer\n",
      "b3afe92c540b: Pulling fs layer\n",
      "b45c209a4d67: Pulling fs layer\n",
      "3f5a608df989: Pulling fs layer\n",
      "11df60c3c446: Pulling fs layer\n",
      "3306300f7441: Pulling fs layer\n",
      "d5f61fd90197: Pulling fs layer\n",
      "3c91cee49561: Pulling fs layer\n",
      "3166a3588baf: Pulling fs layer\n",
      "386667a0fc79: Pulling fs layer\n",
      "76fe5a83c3ed: Pulling fs layer\n",
      "853eff62ee9f: Pulling fs layer\n",
      "a20beb294a56: Pulling fs layer\n",
      "24a55fbde08c: Pulling fs layer\n",
      "ecdcce3d13d7: Pulling fs layer\n",
      "2a10110a4bf7: Pulling fs layer\n",
      "c88cff83f776: Pulling fs layer\n",
      "f4c251b6c056: Pulling fs layer\n",
      "590d465ecff4: Pulling fs layer\n",
      "b45c209a4d67: Waiting\n",
      "3f5a608df989: Waiting\n",
      "11df60c3c446: Waiting\n",
      "3306300f7441: Waiting\n",
      "d5f61fd90197: Waiting\n",
      "3c91cee49561: Waiting\n",
      "3166a3588baf: Waiting\n",
      "386667a0fc79: Waiting\n",
      "76fe5a83c3ed: Waiting\n",
      "f4c251b6c056: Waiting\n",
      "853eff62ee9f: Waiting\n",
      "a20beb294a56: Waiting\n",
      "24a55fbde08c: Waiting\n",
      "590d465ecff4: Waiting\n",
      "ecdcce3d13d7: Waiting\n",
      "2a10110a4bf7: Waiting\n",
      "c88cff83f776: Waiting\n",
      "d22d2dfcfa9c: Verifying Checksum\n",
      "d22d2dfcfa9c: Download complete\n",
      "b3afe92c540b: Verifying Checksum\n",
      "b3afe92c540b: Download complete\n",
      "d519e2592276: Verifying Checksum\n",
      "d519e2592276: Download complete\n",
      "3f5a608df989: Verifying Checksum\n",
      "3f5a608df989: Download complete\n",
      "11df60c3c446: Verifying Checksum\n",
      "11df60c3c446: Download complete\n",
      "d5f61fd90197: Verifying Checksum\n",
      "d5f61fd90197: Download complete\n",
      "b45c209a4d67: Verifying Checksum\n",
      "b45c209a4d67: Download complete\n",
      "3306300f7441: Verifying Checksum\n",
      "3306300f7441: Download complete\n",
      "386667a0fc79: Verifying Checksum\n",
      "386667a0fc79: Download complete\n",
      "3c91cee49561: Verifying Checksum\n",
      "3c91cee49561: Download complete\n",
      "3166a3588baf: Verifying Checksum\n",
      "3166a3588baf: Download complete\n",
      "853eff62ee9f: Verifying Checksum\n",
      "853eff62ee9f: Download complete\n",
      "76fe5a83c3ed: Verifying Checksum\n",
      "76fe5a83c3ed: Download complete\n",
      "24a55fbde08c: Verifying Checksum\n",
      "24a55fbde08c: Download complete\n",
      "a20beb294a56: Verifying Checksum\n",
      "a20beb294a56: Download complete\n",
      "2a10110a4bf7: Verifying Checksum\n",
      "2a10110a4bf7: Download complete\n",
      "c88cff83f776: Verifying Checksum\n",
      "c88cff83f776: Download complete\n",
      "590d465ecff4: Verifying Checksum\n",
      "590d465ecff4: Download complete\n",
      "f4c251b6c056: Verifying Checksum\n",
      "f4c251b6c056: Download complete\n",
      "d519e2592276: Pull complete\n",
      "d22d2dfcfa9c: Pull complete\n",
      "b3afe92c540b: Pull complete\n",
      "b45c209a4d67: Pull complete\n",
      "3f5a608df989: Pull complete\n",
      "ecdcce3d13d7: Verifying Checksum\n",
      "ecdcce3d13d7: Download complete\n",
      "11df60c3c446: Pull complete\n",
      "3306300f7441: Pull complete\n",
      "d5f61fd90197: Pull complete\n",
      "3c91cee49561: Pull complete\n",
      "3166a3588baf: Pull complete\n",
      "386667a0fc79: Pull complete\n",
      "76fe5a83c3ed: Pull complete\n",
      "853eff62ee9f: Pull complete\n",
      "a20beb294a56: Pull complete\n",
      "24a55fbde08c: Pull complete\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-14T17:57:53.898363] Entering job preparation.\n",
      "[2021-06-14T17:57:55.556298] Starting job preparation.\n",
      "[2021-06-14T17:57:55.556332] Extracting the control code.\n",
      "[2021-06-14T17:57:55.631350] fetching and extracting the control code on master node.\n",
      "[2021-06-14T17:57:55.631399] Starting extract_project.\n",
      "[2021-06-14T17:57:55.631452] Starting to extract zip file.\n",
      "[2021-06-14T17:57:56.065910] Finished extracting zip file.\n",
      "[2021-06-14T17:57:56.203725] Using urllib.request Python 3.0 or later\n",
      "[2021-06-14T17:57:56.203842] Start fetching snapshots.\n",
      "[2021-06-14T17:57:56.203877] Start fetching snapshot.\n",
      "[2021-06-14T17:57:56.203888] Retrieving project from snapshot: 475cce19-448c-4f5b-8f25-136b2d415329\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 44\n",
      "[2021-06-14T17:57:56.826699] Finished fetching snapshot.\n",
      "[2021-06-14T17:57:56.826728] Finished fetching snapshots.\n",
      "[2021-06-14T17:57:56.826849] Finished extract_project.\n",
      "[2021-06-14T17:57:56.838186] Finished fetching and extracting the control code.\n",
      "[2021-06-14T17:57:56.843676] downloadDataStore - Download from datastores if requested.\n",
      "[2021-06-14T17:57:56.844305] Start run_history_prep.\n",
      "[2021-06-14T17:57:57.024950] Entering context manager injector.\n",
      "Acquired lockfile /tmp/cc53dec4-6cb1-42c7-bd35-8f3213d63bc2-datastore.lock to downloading input data references\n",
      "[2021-06-14T17:57:57.542258] downloadDataStore completed\n",
      "[2021-06-14T17:57:57.546036] Job preparation is complete.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-14T17:58:23.809593] Entering job release\n",
      "[2021-06-14T17:58:24.857283] Starting job release\n",
      "[2021-06-14T17:58:24.858042] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 321\n",
      "[2021-06-14T17:58:24.858976] job release stage : upload_datastore starting...\n",
      "[2021-06-14T17:58:24.867898] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-06-14T17:58:24.868222] job release stage : execute_job_release starting...\n",
      "[2021-06-14T17:58:24.868680] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-06-14T17:58:24.868966] Entering context manager injector.\n",
      "[2021-06-14T17:58:24.869743] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-06-14T17:58:24.902558] job release stage : upload_datastore completed...\n",
      "[2021-06-14T17:58:25.450575] job release stage : send_run_telemetry starting...\n",
      "[2021-06-14T17:58:25.561744] job release stage : execute_job_release completed...\n",
      "[2021-06-14T17:58:26.225992] get vm size and vm region successfully.\n",
      "[2021-06-14T17:58:26.500121] get compute meta data successfully.\n",
      "[2021-06-14T17:58:26.658049] post artifact meta request successfully.\n",
      "[2021-06-14T17:58:26.683340] upload compute record artifact successfully.\n",
      "[2021-06-14T17:58:26.683427] job release stage : send_run_telemetry completed...\n",
      "[2021-06-14T17:58:26.683808] Job release is complete\n",
      "\n",
      "StepRun(Prepare Data) Execution Summary\n",
      "========================================\n",
      "StepRun( Prepare Data ) Status: Finished\n",
      "{'runId': 'cc53dec4-6cb1-42c7-bd35-8f3213d63bc2', 'target': 'msl-20210613b', 'status': 'Completed', 'startTimeUtc': '2021-06-14T17:56:27.29606Z', 'endTimeUtc': '2021-06-14T17:58:35.30575Z', 'properties': {'ContentSnapshotId': '475cce19-448c-4f5b-8f25-136b2d415329', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': '33517913-ded8-4a97-a34d-83f76102c1bd', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'd29111bb', 'azureml.pipelinerunid': '0268e2e0-be38-4866-82da-aa4a93d1a249', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': '34c69dce-293a-4864-9539-305b47c0bf6e'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'msl-20210613b', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': '34c69dce-293a-4864-9539-305b47c0bf6e', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.28.0', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_d288952671d425e4e901cdcb45ed642e'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=gVX5ZNh1m%2FkffV7tdSIN098ONkkxOLQdRl9YWqMWSwg%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/55_azureml-execution-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt?sv=2019-02-02&sr=b&sig=i7KK2RyYnjxg9fbkMOLIIbLRfxNDjo%2Bysv5feM524pE%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'azureml-logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt?sv=2019-02-02&sr=b&sig=w8SQdh3ZeXd1OjjvF261zlNU1XqGg7%2Fx43UH8PGLmjg%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=c1dUKdoBwVb3wIjGwkCPG%2F%2FiutHIbWrDyHX38eaJ9%2FI%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'azureml-logs/75_job_post-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/75_job_post-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt?sv=2019-02-02&sr=b&sig=1D03c2wMvA0s9%2FsDFN3W88C55AhzXxZ249TwnRbyQEk%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'azureml-logs/process_info.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=035oWLw1kVBJ6PVdCqpiiaHj7iNCCefO7nLkurhlaeA%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'azureml-logs/process_status.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=q3I8MeTuzcJGWZxdQtO%2BcDUOFRzjLR0JPQMrBJGGmeE%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/95_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/95_azureml.log?sv=2019-02-02&sr=b&sig=OwAsLdIjuy1Ox%2FQbHZUbrFzMEMSxzTXpMjP0Z4hEJVs%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=37Ho%2FhPFJ1b8K3BxpBOIB5yBZO6K5HoGAoQSg%2BgUTts%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=nEbJipNUMKPUwZTWvSldHOH%2FFFKTgfBk8mWAUNJIqOc%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=G2WGt4Arzjg%2BVnQ2Q15oIb4AwmNQairCHm6hX4gvV0s%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=MR%2BGhfXkRq4jpttbNNhepzSp9384OnCsBCtxYz7QUzk%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=I8L9UMnscTJM4tJ8qWN1uLpFSh%2FvGO9DNdV4CaX%2FSHw%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=eT6Oq1vPicyAeaV9mJWExorYvNDnVF8oGtx7291U9G4%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=fAzI3XNy8csC2%2FN8Bfk10TRWfuVC1mqza%2F5TD3mj1WE%3D&st=2021-06-14T17%3A48%3A26Z&se=2021-06-15T01%3A58%3A26Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "StepRunId: e774011e-35ac-41be-a84c-ce20bdc56a52\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/e774011e-35ac-41be-a84c-ce20bdc56a52?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "StepRun( Train and Register Model ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-14T17:58:49Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore\n",
      "2021-06-14T17:58:49Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-14T17:58:49Z Starting output-watcher...\n",
      "2021-06-14T17:58:49Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-14T17:58:49Z Executing 'Copy ACR Details file' on 10.0.0.4\n",
      "2021-06-14T17:58:49Z Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_e96989a292f63f7b1f52525986a204bb\n",
      "Digest: sha256:a0b98364676f03cc296bb39ef84ba0799aff54d968c34d16cc4c3b8fedf1c36a\n",
      "Status: Image is up to date for 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:latest\n",
      "322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb:latest\n",
      "2021-06-14T17:58:50Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-14T17:58:50Z Check if container e774011e-35ac-41be-a84c-ce20bdc56a52 already exist exited with 0, \n",
      "\n",
      "9e588e8d0fa9355eb6a6bb0292480af1d771c28ca92495472f08bb2e4bc86d59\n",
      "2021-06-14T17:58:50Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-06-14T17:58:50Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-87368150d4415d1d3c9eabd647782895-cf1e1faf1ba8069c-01 -sshRequired=false] \n",
      "2021/06/14 17:58:50 Starting App Insight Logger for task:  containerSetup\n",
      "2021/06/14 17:58:50 Version: 3.0.01615.0003 Branch: .SourceBranch Commit: 41d0573\n",
      "2021/06/14 17:58:50 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/06/14 17:58:50 Starting infiniband setup\n",
      "2021/06/14 17:58:50 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/06/14 17:58:50 Returning Python Version as 3.6\n",
      "2021/06/14 17:58:50 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/06/14 17:58:50 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021-06-14T17:58:50Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-18.04\n",
      "2021/06/14 17:58:50 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/06/14 17:58:50 Not setting up Infiniband in Container\n",
      "2021/06/14 17:58:50 Not setting up Infiniband in Container\n",
      "2021-06-14T17:58:50Z Not setting up Infiniband in Container\n",
      "2021/06/14 17:58:50 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
      "\n",
      "2021/06/14 17:58:50 Returning Python Version as 3.6\n",
      "2021/06/14 17:58:50 sshd inside container not required for job, skipping setup.\n",
      "2021/06/14 17:58:51 All App Insights Logs was send successfully\n",
      "2021/06/14 17:58:51 App Insight Client has already been closed\n",
      "2021/06/14 17:58:51 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-06-14T17:58:51Z Starting docker container succeeded.\n",
      "2021-06-14T17:58:56Z Job environment preparation succeeded on 10.0.0.4. Output: \n",
      ">>>   2021/06/14 17:58:48 Starting App Insight Logger for task:  prepareJobEnvironment\n",
      ">>>   2021/06/14 17:58:48 Version: 3.0.01615.0003 Branch: .SourceBranch Commit: 41d0573\n",
      ">>>   2021/06/14 17:58:48 runtime.GOOS linux\n",
      ">>>   2021/06/14 17:58:48 Checking if '/tmp' exists\n",
      ">>>   2021/06/14 17:58:48 Reading dyanamic configs\n",
      ">>>   2021/06/14 17:58:48 Container sas url: https://baiscriptswestus2prod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=71Fsy25bPMdce8Lc7jVPFZbJokMhH4i%2F250OyAEdREA%3D\n",
      ">>>   2021/06/14 17:58:48 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
      ">>>   2021/06/14 17:58:48 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: false. Is Azsecpack enabled: false,\n",
      ">>>   2021/06/14 17:58:48 Starting Azsecpack installation on machine: 4374517f257945bb924ed08b1b0256f2000000#5456e8d8-0223-4619-ba5b-e313627da53d#153404fd-72ab-4092-b50e-de490c5509fc#20210613#20210613#msl-20210613b\n",
      ">>>   2021/06/14 17:58:48 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
      ">>>   2021/06/14 17:58:48 Turning off azsecpack, if it is already running\n",
      ">>>   2021/06/14 17:58:48 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\n",
      ">>>   ,err:exit status 1.\n",
      ">>>   2021/06/14 17:58:48 OS patching disabled by dynamic configs. Skipping.\n",
      ">>>   2021/06/14 17:58:48 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
      ">>>   2021/06/14 17:58:48 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/06/14 17:58:48 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/06/14 17:58:48 Get GPU count failed with err: The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command., \n",
      ">>>   2021/06/14 17:58:48 AMLComputeXDSEndpoint:  https://westus2-prodk8ds.batchai.core.windows.net\n",
      ">>>   2021/06/14 17:58:48 AMLComputeXDSApiVersion:  2018-02-01\n",
      ">>>   2021/06/14 17:58:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config\n",
      ">>>   2021/06/14 17:58:48 This is not a aml-workstation (compute instance), current offer type: amlcompute. Starting identity responder as part of prepareJobEnvironment.\n",
      ">>>   2021/06/14 17:58:48 Starting identity responder.\n",
      ">>>   2021/06/14 17:58:48 Starting identity responder.\n",
      ">>>   2021/06/14 17:58:48 Failed to open file /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.batchai.IdentityResponder.envlist: open /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
      ">>>   2021/06/14 17:58:48 Logfile used for identity responder: /mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/IdentityResponderLog-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      ">>>   2021/06/14 17:58:48 Logfile used for identity responder: /mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/IdentityResponderLog-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      ">>>   2021/06/14 17:58:48 Started Identity Responder for job.\n",
      ">>>   2021/06/14 17:58:48 Started Identity Responder for job.\n",
      ">>>   2021/06/14 17:58:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/wd\n",
      ">>>   2021/06/14 17:58:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/shared\n",
      ">>>   2021/06/14 17:58:48 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/06/14 17:58:48 Mounting job level file systems\n",
      ">>>   2021/06/14 17:58:48 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts\n",
      ">>>   2021/06/14 17:58:48 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.amlcompute.datastorecredentials\n",
      ">>>   2021/06/14 17:58:48 Datastore credentials file not found, skipping.\n",
      ">>>   2021/06/14 17:58:48 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.master.runtimesastokens\n",
      ">>>   2021/06/14 17:58:48 Runtime sas tokens file not found, skipping.\n",
      ">>>   2021/06/14 17:58:48 No NFS configured\n",
      ">>>   2021/06/14 17:58:48 No Azure File Shares configured\n",
      ">>>   2021/06/14 17:58:48 Mounting blob file systems\n",
      ">>>   2021/06/14 17:58:48 Blobfuse runtime version 1.3.6\n",
      ">>>   2021/06/14 17:58:48 Mounting azureml-blobstore-322f90dd-b503-46f1-8d45-68f1641a9197 container from 202106138491592323 account at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore\n",
      ">>>   2021/06/14 17:58:48 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/06/14 17:58:48 Using Compute Identity to authenticate Blobfuse: false.\n",
      ">>>   2021/06/14 17:58:48 Blobfuse cache size set to 21653 MB.\n",
      ">>>   2021/06/14 17:58:48 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=21653 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
      ">>>   2021/06/14 17:58:48 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore\n",
      ">>>   2021/06/14 17:58:49 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore\n",
      ">>>   2021/06/14 17:58:49 Successfully mounted azureml-blobstore-322f90dd-b503-46f1-8d45-68f1641a9197 container from 202106138491592323 account at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore\n",
      ">>>   2021/06/14 17:58:49 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52\n",
      ">>>   2021/06/14 17:58:49 No unmanaged file systems configured\n",
      ">>>   2021/06/14 17:58:49 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/06/14 17:58:49 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/06/14 17:58:49 From the policy service, the filtering patterns is: , data store is \n",
      ">>>   2021/06/14 17:58:49 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs\n",
      ">>>   2021/06/14 17:58:49 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/logs\n",
      ">>>   2021/06/14 17:58:49 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/outputs\n",
      ">>>   2021/06/14 17:58:49 Starting output-watcher...\n",
      ">>>   2021/06/14 17:58:49 Single file input dataset is enabled.\n",
      ">>>   2021/06/14 17:58:49 Start to pulling docker image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb\n",
      ">>>   2021/06/14 17:58:49 Start pull docker image: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      ">>>   2021/06/14 17:58:49 Getting credentials for image 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb with url 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      ">>>   2021/06/14 17:58:49 Container registry is ACR.\n",
      ">>>   2021/06/14 17:58:49 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
      ">>>   2021/06/14 17:58:49 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
      ">>>   2021/06/14 17:58:49 Requesting XDS for registry details.\n",
      ">>>   2021/06/14 17:58:49 Attempt 1 of http call to https://westus2-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/workspaces/20210613/clusters/msl-20210613b/nodes/tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d?api-version=2018-02-01\n",
      ">>>   2021/06/14 17:58:49 Got container registry details from credentials service for registry address: 322f90ddb50346f18d4568f1641a9197.azurecr.io.\n",
      ">>>   2021/06/14 17:58:49 Writing ACR Details to file...\n",
      ">>>   2021/06/14 17:58:49 Copying ACR Details file to worker nodes...\n",
      ">>>   2021/06/14 17:58:49 Executing 'Copy ACR Details file' on 10.0.0.4\n",
      ">>>   2021/06/14 17:58:49 Begin executing 'Copy ACR Details file' task on Node\n",
      ">>>   2021/06/14 17:58:49 'Copy ACR Details file' task Node result: succeeded\n",
      ">>>   2021/06/14 17:58:49 Copy ACR Details file succeeded on 10.0.0.4. Output: \n",
      ">>>   >>>   \n",
      ">>>   >>>   \n",
      ">>>   2021/06/14 17:58:50 Successfully retrieved ACR Credentials from EMS.\n",
      ">>>   2021/06/14 17:58:50 EMS returned 322f90ddb50346f18d4568f1641a9197.azurecr.io for environment diabetes-pipeline-env\n",
      ">>>   2021/06/14 17:58:50 Save docker credentials for image 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb in /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/wd/docker_login_24C134F5F76528F0\n",
      ">>>   2021/06/14 17:58:50 Start login to the docker registry\n",
      ">>>   2021/06/14 17:58:50 Successfully logged into the docker registry.\n",
      ">>>   2021/06/14 17:58:50 Start run pull docker image command\n",
      ">>>   2021/06/14 17:58:50 Pull docker image succeeded.\n",
      ">>>   2021/06/14 17:58:50 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/wd/docker_login_24C134F5F76528F0\n",
      ">>>   2021/06/14 17:58:50 Pull docker image time: 364.457417ms\n",
      ">>>   \n",
      ">>>   2021/06/14 17:58:50 Docker Version that this nodes use are: 19.03.14+azure\n",
      ">>>   \n",
      ">>>   2021/06/14 17:58:50 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/06/14 17:58:50 The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      ">>>   2021/06/14 17:58:50 Setting the memory limit for docker container to be 13674 MB\n",
      ">>>   2021/06/14 17:58:50 The env variable file size is 40092 bytes\n",
      ">>>   2021/06/14 17:58:50 Creating parent cgroup 'e774011e-35ac-41be-a84c-ce20bdc56a52' for Containers used in Job\n",
      ">>>   2021/06/14 17:58:50 Add parent cgroup 'e774011e-35ac-41be-a84c-ce20bdc56a52' to container 'e774011e-35ac-41be-a84c-ce20bdc56a52'\n",
      ">>>   2021/06/14 17:58:50 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      ">>>   2021/06/14 17:58:50 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,e774011e-35ac-41be-a84c-ce20bdc56a52,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/certs:/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13674m,-v,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd:/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52:/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.batchai.envlist,--cgroup-parent=/e774011e-35ac-41be-a84c-ce20bdc56a52/,--shm-size,2g\n",
      ">>>   2021/06/14 17:58:50 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
      ">>>   2021/06/14 17:58:50 the binding /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52:/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52 \n",
      ">>>   2021/06/14 17:58:50 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,e774011e-35ac-41be-a84c-ce20bdc56a52,-m,13674m,-w,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.batchai.envlist,--cgroup-parent=/e774011e-35ac-41be-a84c-ce20bdc56a52/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52:/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52,-v,/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd:/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd,-v,/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/certs:/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/certs\n",
      ">>>   2021/06/14 17:58:50 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name e774011e-35ac-41be-a84c-ce20bdc56a52 -m 13674m -w /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/config/.batchai.envlist --cgroup-parent=/e774011e-35ac-41be-a84c-ce20bdc56a52/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52:/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52 -v /mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd:/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd -v /mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/certs:/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/certs -d -it --privileged --net=host 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_e96989a292f63f7b1f52525986a204bb\n",
      ">>>   2021/06/14 17:58:50 Check if container e774011e-35ac-41be-a84c-ce20bdc56a52 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/06/14 17:58:50 Check if container e774011e-35ac-41be-a84c-ce20bdc56a52 already exist exited with 0, \n",
      ">>>   \n",
      ">>>   2021/06/14 17:58:50 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/06/14 17:58:50 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      ">>>   2021/06/14 17:58:50 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-87368150d4415d1d3c9eabd647782895-cf1e1faf1ba8069c-01 -sshRequired=false] \n",
      ">>>   2021/06/14 17:58:50 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-87368150d4415d1d3c9eabd647782895-cf1e1faf1ba8069c-01 -sshRequired=false] \n",
      ">>>   2021/06/14 17:58:51 Container ssh is not required for job type.\n",
      ">>>   2021/06/14 17:58:51 Starting docker container succeeded.\n",
      ">>>   2021/06/14 17:58:51 Starting docker container succeeded.\n",
      ">>>   2021/06/14 17:58:51 Disk space after starting docker container: 23107MB\n",
      ">>>   2021/06/14 17:58:51 Begin execution of runSpecialJobTask\n",
      ">>>   2021/06/14 17:58:51 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs\n",
      ">>>   2021/06/14 17:58:51 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/bin/python /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"475cce19-448c-4f5b-8f25-136b2d415329\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/06/14 17:58:51 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      ">>>   2021/06/14 17:58:51 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/azureml_compute_logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      ">>>   2021/06/14 17:58:51 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52;/azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/bin/python /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"475cce19-448c-4f5b-8f25-136b2d415329\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/06/14 17:58:51 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
      ">>>   2021/06/14 17:58:52 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-87368150d4415d1d3c9eabd647782895-f4ae01096542004f-01 -t e774011e-35ac-41be-a84c-ce20bdc56a52 bash -c if [ -f ~/.bashrc ]; then PS1_back=$PS1; PS1='$'; . ~/.bashrc; PS1=$PS1_back; fi;PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/5d5580b8-0490-49dc-bd92-afddfb9c9854/job-1/e774011e-35ac-41be-a_6237d85a-d07d-43f1-8b76-2aaa52d74fd9/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52;/azureml-envs/azureml_d288952671d425e4e901cdcb45ed642e/bin/python /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52/mounts/workspaceblobstore/azureml/e774011e-35ac-41be-a84c-ce20bdc56a52-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"475cce19-448c-4f5b-8f25-136b2d415329\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
      ">>>   2021/06/14 17:58:53 Attempt 1 of http call to https://westus2.api.azureml.ms/history/v1.0/private/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/runs/e774011e-35ac-41be-a84c-ce20bdc56a52/spans\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
      ">>>   \n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:52.400797] Entering job preparation.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:53.664287] Starting job preparation.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:53.664345] Extracting the control code.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:53.685889] fetching and extracting the control code on master node.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:53.685936] Starting extract_project.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:53.686021] Starting to extract zip file.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.173182] Finished extracting zip file.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.313947] Using urllib.request Python 3.0 or later\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.314005] Start fetching snapshots.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.314041] Start fetching snapshot.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.314060] Retrieving project from snapshot: 475cce19-448c-4f5b-8f25-136b2d415329\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 43\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.657255] Finished fetching snapshot.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.657305] Finished fetching snapshots.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.657315] Finished extract_project.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.667999] Finished fetching and extracting the control code.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.672162] downloadDataStore - Download from datastores if requested.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.673443] Start run_history_prep.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:54.763186] Entering context manager injector.\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: Acquired lockfile /tmp/e774011e-35ac-41be-a84c-ce20bdc56a52-datastore.lock to downloading input data references\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:55.274491] downloadDataStore completed\n",
      ">>>   2021/06/14 17:58:55 runSpecialJobTask: preparation: [2021-06-14T17:58:55.277612] Job preparation is complete.\n",
      ">>>   2021/06/14 17:58:55 Execution of runSpecialJobTask completed\n",
      ">>>   2021/06/14 17:58:55 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      ">>>   Stopped: false\n",
      ">>>   OriginalData: 3\n",
      ">>>   FilteredData: 0.\n",
      ">>>   2021/06/14 17:58:55 Process Exiting with Code:  0\n",
      ">>>   2021/06/14 17:58:55 All App Insights Logs was send successfully\n",
      ">>>   \n",
      "2021-06-14T17:58:56Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-14T17:58:56Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-14T17:58:56Z 127.0.0.1 slots=2 max-slots=2\n",
      "2021-06-14T17:58:56Z launching Custom job\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-14T17:59:10.860757] Entering job release\n",
      "[2021-06-14T17:59:11.898803] Starting job release\n",
      "[2021-06-14T17:59:11.905501] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 146\n",
      "[2021-06-14T17:59:11.905814] job release stage : upload_datastore starting...\n",
      "[2021-06-14T17:59:11.906214] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-06-14T17:59:11.914739] job release stage : execute_job_release starting...\n",
      "[2021-06-14T17:59:11.915971] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-06-14T17:59:11.916529] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-06-14T17:59:11.917268] Entering context manager injector.\n",
      "[2021-06-14T17:59:11.933890] job release stage : upload_datastore completed...\n",
      "[2021-06-14T17:59:12.333872] job release stage : send_run_telemetry starting...\n",
      "[2021-06-14T17:59:12.446127] job release stage : execute_job_release completed...\n",
      "[2021-06-14T17:59:12.518581] get vm size and vm region successfully.\n",
      "[2021-06-14T17:59:12.753751] get compute meta data successfully.\n",
      "[2021-06-14T17:59:12.947052] post artifact meta request successfully.\n",
      "[2021-06-14T17:59:12.974309] upload compute record artifact successfully.\n",
      "[2021-06-14T17:59:12.974435] job release stage : send_run_telemetry completed...\n",
      "[2021-06-14T17:59:12.974724] Job release is complete\n",
      "\n",
      "StepRun(Train and Register Model) Execution Summary\n",
      "====================================================\n",
      "StepRun( Train and Register Model ) Status: Finished\n",
      "{'runId': 'e774011e-35ac-41be-a84c-ce20bdc56a52', 'target': 'msl-20210613b', 'status': 'Completed', 'startTimeUtc': '2021-06-14T17:58:49.953484Z', 'endTimeUtc': '2021-06-14T17:59:37.099595Z', 'properties': {'ContentSnapshotId': '475cce19-448c-4f5b-8f25-136b2d415329', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'c2f0785e-c28f-4464-9c23-381bebb1c2f6', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'b742241d', 'azureml.pipelinerunid': '0268e2e0-be38-4866-82da-aa4a93d1a249', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-folder', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'msl-20210613b', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/cc53dec4-6cb1-42c7-bd35-8f3213d63bc2/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.28.0', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_d288952671d425e4e901cdcb45ed642e'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/azureml-logs/55_azureml-execution-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt?sv=2019-02-02&sr=b&sig=5E1z3IZKqU9iXQ6T0cu81ADnmEPIZIeXVJeXaARG%2FKA%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'azureml-logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/azureml-logs/65_job_prep-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt?sv=2019-02-02&sr=b&sig=vOOBBg0pOCsiw6Ki6HMFHvbrIiHr0APBRD7p5gN2JVQ%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=O55DiWK%2FhcZkJpRvJyIcRXmX%2FfAItk3RsDQ4HL7QH5E%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'azureml-logs/75_job_post-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/azureml-logs/75_job_post-tvmps_2100a389774982151797c06de8b2af602675007c87c530ab83864e29f5a7f9af_d.txt?sv=2019-02-02&sr=b&sig=p9tp4CnJDyybSW3ihct%2Fhxzo0UiBIpNvXglnxNre%2B78%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'azureml-logs/process_info.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=dteD7kX%2Fd0uEJ5EdvJps9y7WgZUfqO%2FkqlscAlvMDBE%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'azureml-logs/process_status.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=IZMhmMchAQRQuaHgEN6JzSyevALGMieev48WWEfrFb0%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'logs/azureml/94_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/94_azureml.log?sv=2019-02-02&sr=b&sig=OGRVf%2BHBHyRg7p%2FlLZnrOS8%2FuhXmJgzDUUuT%2BmM%2B3FY%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=bM0iZNESdvnDU9AOJT1o05jZ4rss1ja6N5HklA8%2B2vg%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=Z4ZX7HjSOENRqQJNY3NGC9gjKxHxmbfT2R1uacMmRE0%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=UBYY9J39bbNYOPLRvEYP%2B1kYectWcjK1xLhLEVE2Zh0%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=p114ux792d%2BUVXvVtk%2BIaQcukJ40D4XBvvX6473Ento%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=vdypsHmhz9D6bHbkMz0NBYd0IJ8jg3qvj0HnphrsThY%3D&st=2021-06-14T17%3A49%3A15Z&se=2021-06-15T01%3A59%3A15Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '0268e2e0-be38-4866-82da-aa4a93d1a249', 'status': 'Completed', 'startTimeUtc': '2021-06-14T17:43:23.894096Z', 'endTimeUtc': '2021-06-14T17:59:39.205635Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.0268e2e0-be38-4866-82da-aa4a93d1a249/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=9HOJeyWS00Y29TTuXEN1MEjlo8SDX8Be4xpAffN2LMs%3D&st=2021-06-14T17%3A33%3A45Z&se=2021-06-15T01%3A43%3A45Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.0268e2e0-be38-4866-82da-aa4a93d1a249/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=1ITsf%2BZHOdCWJU%2BZ0wQ7DuERkeNh5LT3vjpSWeqsEp4%3D&st=2021-06-14T17%3A33%3A45Z&se=2021-06-15T01%3A43%3A45Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.0268e2e0-be38-4866-82da-aa4a93d1a249/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=T2L%2F0vIb%2B7gvfD77xnpQlCUgE%2FP5Wt5wg%2BFR0yaCGyI%3D&st=2021-06-14T17%3A33%3A45Z&se=2021-06-15T01%3A43%3A45Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an experiment and run the pipeline\n",
    "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
    "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
    "print(\"Pipeline submitted for execution.\")\n",
    "RunDetails(pipeline_run).show()\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a8f846",
   "metadata": {},
   "source": [
    "パイプラインが終了すると、その子実行が記録したメトリックを調べることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eca9da98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Register Model :\n",
      "\t Accuracy : 0.9004444444444445\n",
      "\t AUC : 0.8854221505732166\n",
      "\t ROC : aml://artifactId/ExperimentRun/dcid.e774011e-35ac-41be-a84c-ce20bdc56a52/ROC_1623693541.png\n",
      "Prepare Data :\n",
      "\t raw_rows : 15000\n",
      "\t processed_rows : 15000\n"
     ]
    }
   ],
   "source": [
    "for run in pipeline_run.get_children():\n",
    "    print(run.name, ':')\n",
    "    metrics = run.get_metrics()\n",
    "    for metric_name in metrics:\n",
    "        print('\\t',metric_name, \":\", metrics[metric_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd413a",
   "metadata": {},
   "source": [
    "パイプラインが成功すると、新しいモデルが、パイプラインでトレーニングされたことを示すTraining contextタグとともに登録される。  \n",
    "以下のコードを実行して確認してみる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ee361a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes_model version: 9\n",
      "\t Training context : Pipeline\n",
      "\t AUC : 0.8854221505732166\n",
      "\t Accuracy : 0.9004444444444445\n",
      "\n",
      "\n",
      "diabetes_model version: 8\n",
      "\t Training context : Compute cluster\n",
      "\t AUC : 0.8840918562273435\n",
      "\t Accuracy : 0.8991111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 7\n",
      "\t Training context : File dataset\n",
      "\t AUC : 0.8568743524381947\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 6\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 5\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 4\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 3\n",
      "\t Training context : Tabular dataset\n",
      "\t AUC : 0.8568509052814499\n",
      "\t Accuracy : 0.7891111111111111\n",
      "\n",
      "\n",
      "diabetes_model version: 2\n",
      "\t Training context : Parameterized script\n",
      "\t AUC : 0.8483198169063138\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n",
      "diabetes_model version: 1\n",
      "\t Training context : Script\n",
      "\t AUC : 0.8484929598487486\n",
      "\t Accuracy : 0.774\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834bccf5",
   "metadata": {},
   "source": [
    "### パイプラインの登録\n",
    "\n",
    "パイプラインを作成してテストした後は、RESTサービスとして公開することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94a52552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-training-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/4c67cd90-bc1f-4e96-b252-04f3c5b3d88d?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613\" target=\"_blank\" rel=\"noopener\">4c67cd90-bc1f-4e96-b252-04f3c5b3d88d</a></td><td>Active</td><td><a href=\"https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/PipelineRuns/PipelineSubmit/4c67cd90-bc1f-4e96-b252-04f3c5b3d88d\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: diabetes-training-pipeline,\n",
       "Id: 4c67cd90-bc1f-4e96-b252-04f3c5b3d88d,\n",
       "Status: Active,\n",
       "Endpoint: https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/PipelineRuns/PipelineSubmit/4c67cd90-bc1f-4e96-b252-04f3c5b3d88d)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Publish the pipeline from the run\n",
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=\"diabetes-training-pipeline\", description=\"Trains diabetes model\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467c49a3",
   "metadata": {},
   "source": [
    "公開されたパイプラインにはエンドポイントがあり、オブジェクトのプロパティとして確認することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f43faf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/PipelineRuns/PipelineSubmit/4c67cd90-bc1f-4e96-b252-04f3c5b3d88d\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dbd7cb",
   "metadata": {},
   "source": [
    "### パイプラインのエンドポイントを呼び出す\n",
    "\n",
    "エンドポイントを利用するには、クライアントアプリケーションがHTTPでRESTコールを行う必要がある。  \n",
    "このリクエストは認証されなければならないので、authorizationヘッダーが必要。  \n",
    "実際のアプリケーションでは、認証されるためのサービス・プリンシパルが必要だが、これをテストするために、  \n",
    "Azureワークスペースへの源氏亜の接続からの認証ヘッダーを使用する。\n",
    "\n",
    "なお、以下のコードで取得できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254b0321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print(\"Authentication header ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c58223",
   "metadata": {},
   "source": [
    "パイプラインは非同期的に実行されるので、識別子が返ってくる。  \n",
    "この識別子を使って、パイプラインの実験が実行されているかどうかを追跡することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1b67bcc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'374b26ab-73e4-4b8c-a9b2-ad5c103ea138'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "experiment_name = 'mslearn-diabetes-pipeline'\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71758b",
   "metadata": {},
   "source": [
    "RunIDをもっているため、それを用いてRunが完了するのを待つことができる。\n",
    "\n",
    "> 注:各ステップの出力は再利用できるように設定されているため、パイプラインはすぐ完了するはずで、  \n",
    "これはこのコースの利便性と時間短縮のために行ったもの。  \n",
    "実際には、データが変更された場合に備えて、最初のステップを毎回実行し、ステップ1からの出力が変更された場合にのみ、  \n",
    "後続のステップをトリガーするようにすると良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "078dad38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 374b26ab-73e4-4b8c-a9b2-ad5c103ea138\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/374b26ab-73e4-4b8c-a9b2-ad5c103ea138?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '374b26ab-73e4-4b8c-a9b2-ad5c103ea138', 'status': 'Completed', 'startTimeUtc': '2021-06-14T18:02:40.22368Z', 'endTimeUtc': '2021-06-14T18:02:43.098834Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': '4c67cd90-bc1f-4e96-b252-04f3c5b3d88d'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.374b26ab-73e4-4b8c-a9b2-ad5c103ea138/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=QS8g7vuv%2FDuR6x9OMkC7aMECloMRf259gWVadu6unA0%3D&st=2021-06-14T17%3A54%3A36Z&se=2021-06-15T02%3A04%3A36Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.374b26ab-73e4-4b8c-a9b2-ad5c103ea138/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=aVpZFaK5UMwVdvkhlqQx2qLbNkpDYBUdoRTnmeANvmM%3D&st=2021-06-14T17%3A54%3A36Z&se=2021-06-15T02%3A04%3A36Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.374b26ab-73e4-4b8c-a9b2-ad5c103ea138/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=L%2B14ikAURPxRGqj6tYCt7hR%2BIqyHqNITqP4JQGrUYTo%3D&st=2021-06-14T17%3A54%3A36Z&se=2021-06-15T02%3A04%3A36Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments[experiment_name], run_id)\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401e1a2",
   "metadata": {},
   "source": [
    "### パイプラインをスケジューリングする\n",
    "\n",
    "糖尿病患者のクリニックが毎週新しいデータを収集し、データセットに追加しているとする。  \n",
    "パイプラインを毎週実行して、新しいデータでモデルを再学習することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fa610c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline scheduled.\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "# 毎週月曜0時(UTC時刻)に、パイプラインを実行する\n",
    "recurrence = ScheduleRecurrence(frequency=\"Week\", interval=1, week_days=[\"Monday\"], time_of_day=\"00:00\")\n",
    "weekly_schedule = Schedule.create(ws, name=\"weekly-diabetes-training\", \n",
    "                                  description=\"Based on time\",\n",
    "                                  pipeline_id=published_pipeline.id, \n",
    "                                  experiment_name='mslearn-diabetes-pipeline', \n",
    "                                  recurrence=recurrence)\n",
    "print('Pipeline scheduled.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f517822c",
   "metadata": {},
   "source": [
    "ワークスペースに定義されているスケジュールを取得するには、以下のようにする。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "55681213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Pipeline(Name: weekly-diabetes-training,\n",
       " Id: bc8e7161-8c3a-4ae8-8222-a8cccac95d14,\n",
       " Status: Active,\n",
       " Pipeline Id: 4c67cd90-bc1f-4e96-b252-04f3c5b3d88d,\n",
       " Pipeline Endpoint Id: None,\n",
       " Recurrence Details: Runs at 0:00 on Monday every Week)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedules = Schedule.list(ws)\n",
    "schedules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25b4d43",
   "metadata": {},
   "source": [
    "以下のようにして、最終実行履歴を確認することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2100ed5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'runId': 'd2a5da1b-7f9d-4adf-acac-2403dbae0272',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2021-06-14T18:06:28.973779Z',\n",
       " 'endTimeUtc': '2021-06-14T18:06:31.859857Z',\n",
       " 'properties': {'azureml.git.repository_uri': 'https://github.com/iguru0331/mslearn-dp100.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/iguru0331/mslearn-dp100.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': 'ed510154034e8c2bf830bb52bd28e078b6c98d13',\n",
       "  'mlflow.source.git.commit': 'ed510154034e8c2bf830bb52bd28e078b6c98d13',\n",
       "  'azureml.git.dirty': 'True',\n",
       "  'azureml.runsource': 'azureml.PipelineRun',\n",
       "  'runSource': 'Unavailable',\n",
       "  'runType': 'Schedule',\n",
       "  'azureml.parameters': '{}',\n",
       "  'azureml.pipelineid': '4c67cd90-bc1f-4e96-b252-04f3c5b3d88d'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'logFiles': {'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.d2a5da1b-7f9d-4adf-acac-2403dbae0272/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=z%2BqgTxldp799XDRtutVXCoVirklMxOybry8g8%2B0b6X0%3D&st=2021-06-14T17%3A57%3A19Z&se=2021-06-15T02%3A07%3A19Z&sp=r',\n",
       "  'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.d2a5da1b-7f9d-4adf-acac-2403dbae0272/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=pwMqNXmf8LhqPA6mFSHFwo7MbSulnBC7BVlDDDfhO40%3D&st=2021-06-14T17%3A57%3A19Z&se=2021-06-15T02%3A07%3A19Z&sp=r',\n",
       "  'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.d2a5da1b-7f9d-4adf-acac-2403dbae0272/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=5O%2BXG5zxoOIQ%2FHfLXgSLyIxyaB5J0s2S6yA4JD99h%2Bk%3D&st=2021-06-14T17%3A57%3A19Z&se=2021-06-15T02%3A07%3A19Z&sp=r'},\n",
       " 'submittedBy': 'Tatsuya Kato'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_experiment = ws.experiments.get('mslearn-diabetes-pipeline')\n",
    "latest_run = [0]\n",
    "\n",
    "latest_run.get_details()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f8df2",
   "metadata": {},
   "source": [
    "## 知識チェック\n",
    "\n",
    "1. 2 つのステップを含むパイプラインを作成しているとします。 ステップ 1 ではいくつかのデータが前処理され、  \n",
    "ステップ 2 では前処理されたデータを使用してモデルがトレーニングされます。  \n",
    "ステップ 1 からステップ 2 にデータを渡し、これらのステップの間に依存関係を作成するために使用するオブジェクトの種類を指定してください。\n",
    "\n",
    "    - データストア\n",
    "    - PipelineData\n",
    "    - データ参照\n",
    "\n",
    "\n",
    "2. 毎週実行するパイプラインを発行しました。 Schedule.create メソッドを使用してスケジュールを作成することを計画しているとします。  \n",
    "パイプライン実行の頻度を構成するために最初に作成する必要のあるオブジェクトの種類を指定してください。\n",
    "\n",
    "    - データストア\n",
    "    - PipelineParameter\n",
    "    - ScheduleRecurrence\n",
    "\n",
    "↓解答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8881e8a",
   "metadata": {},
   "source": [
    "1. PipelineData\n",
    "    - パイプライン内のステップ間でデータを渡すには、PipelineData オブジェクトを使用します。\n",
    "2. ScheduleRecurrence\n",
    "    - 定期的に実行されるスケジュールを作成するには、ScheduleRecurrence オブジェクトが必要です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
