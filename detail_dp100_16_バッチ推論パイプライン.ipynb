{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b31973e",
   "metadata": {},
   "source": [
    "# dp100_16 AzureMLを使用してバッチ推論パイプラインをデプロイする\n",
    "\n",
    "大量のデータを操作する実行期間の長いタスクが\"バッチ\"操作として実行される。  \n",
    "機械学習では\"バッチ推論\"を使用して、予測モデルが複数のケースに非同期に適用される。\n",
    "\n",
    "AzureMLでバッチ推論ソリューションを実装するには、入力データを読み取り、登録済みのモデルを読み込み、  \n",
    "ラベルを予測し、結果をその出力として書き込むためのステップを含むパイプラインを作成する。\n",
    "\n",
    "## バッチ推論パイプラインを作成する\n",
    "\n",
    "### 1.モデルを登録する\n",
    "\n",
    "バッチ推論パイプラインでトレーニング済みモデルを使用するには、それを自分のAzureMLワークスペースに登録する必要がある。  \n",
    "ローカルファイルからモデルを登録するには、**Model**オブジェクトの**register**メソッドを使用する。\n",
    "\n",
    "```\n",
    "from azureml.core import Model\n",
    "\n",
    "classification_model = Model.register(workspace=your_workspace,\n",
    "                                      model_name='classification_model',\n",
    "                                      model_path='model.pkl', # local path\n",
    "                                      description='A classification model')\n",
    "```\n",
    "\n",
    "また、モデルのトレーニングに使用される**Run**への参照がある場合は、**register_model**メソッドを使用できる。\n",
    "\n",
    "```\n",
    "run.register_model( model_name='classification_model',\n",
    "                    model_path='outputs/model.pkl', # run outputs path\n",
    "                    description='A classification model')\n",
    "```\n",
    "\n",
    "### 2.スコアリングスクリプトを作成する\n",
    "\n",
    "バッチ推論サービスには、モデルを読み込んでからそれを使用して新しい値を予測するスコアリングスクリプトが必要。  \n",
    "次の2つの関数が含まれている必要がある。\n",
    "\n",
    "- **init()** : パイプラインが初期化されると呼び出される\n",
    "- **run(mini_batch)** : 処理するデータのバッチ毎に呼び出される\n",
    "\n",
    "通常は、**init**関数を使用してモデルレジストリからモデルを読み込む。  \n",
    "また、**run**関数を使用してデータの各パッチから予測を生成して結果を返す。\n",
    "\n",
    "```\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    model_path = Model.get_model_path('classification_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "def run(mini_batch):\n",
    "    # 各バッチ毎に実行される\n",
    "    resultList = []\n",
    "\n",
    "    # バッチ内の各ファイルを処理する\n",
    "    for f in mini_batch:\n",
    "        # カンマで区切られたデータを配列に読み込む\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # モデル入力用の2次元配列に整形\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        # 予測値を結果に加える\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList\n",
    "```\n",
    "\n",
    "### 3.ParallelRunStepを使用してパイプラインを作成する\n",
    "\n",
    "AzureMLには、並列バッチ推論を実行するための一種のパイプラインステップが特に用意されている。  \n",
    "**ParallelRunStep**クラスを使用すると、**File**データセットからファイルのバッチを読み取り、  \n",
    "処理出力を**PipelineData**参照に書き込むことができる。  \n",
    "さらに、そのステップの**output_action**設定を\"append_row\"に設定することもできる。  \n",
    "これにより、並列に実行されているステップのすべてのインスタンスで、  \n",
    "それぞれの結果が確実に*parallel_run_step.txt*という名前の1つの出力ファイルと照合される。  \n",
    "次のコードスニペットは、**ParallelRunStep**を使用してパイプラインを作成する例を示している。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "# Get the batch dataset for input\n",
    "batch_data_set = ws.datasets['batch-data']\n",
    "\n",
    "# Set the output location\n",
    "default_ds = ws.get_default_datastore()\n",
    "output_dir = PipelineData(name='inferences',\n",
    "                          datastore=default_ds,\n",
    "                          output_path_on_compute='results')\n",
    "\n",
    "# Define the parallel run step step configuration\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory='batch_scripts',\n",
    "    entry_script=\"batch_scoring_script.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=aml_cluster,\n",
    "    node_count=4)\n",
    "\n",
    "# Create the parallel run step\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('batch_data')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa39c9bd",
   "metadata": {},
   "source": [
    "### 4.パイプラインを実行してステップの出力を取得する\n",
    "\n",
    "パイプラインが定義されたら、それを実行して完了するまで待つ。  \n",
    "さらに以下のコード例のように、ステップの出力から**parallel_run_step.txt**ファイルを取得して結果を表示できる。\n",
    "\n",
    "```\n",
    "from azureml.core import Experiment\n",
    "\n",
    "# パイプラインを実験として実行\n",
    "pipeline_run = Experiment(ws, 'batch_prediction_pipeline').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)\n",
    "\n",
    "# 最初の(そして唯一の)ステップからの出力を取得\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='results')\n",
    "\n",
    "# parallel_run_step.txtファイルの検索\n",
    "for root, dirs, files in os.walk('results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# 結果の出力\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "print(df)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef57673d",
   "metadata": {},
   "source": [
    "## バッチ推論パイプラインを発行する\n",
    "\n",
    "バッチ推論パイプラインはRESTサービスとして発行することができる。\n",
    "\n",
    "```\n",
    "published_pipeline = pipeline_run.publish_pipeline(name='Batch_Prediction_Pipeline',\n",
    "                                                   description='Batch pipeline',\n",
    "                                                   version='1.0')\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "```\n",
    "\n",
    "発行されたら、サービスエンドポイントを使用してバッチ推論ジョブを開始できる。\n",
    "\n",
    "```\n",
    "import requests\n",
    "\n",
    "response = requests.post(rest_endpoint,\n",
    "                         headers=auth_header,\n",
    "                         json={\"ExperimentName\": \"Batch_Prediction\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "```\n",
    "\n",
    "また、発行されたパイプラインが自動的に実行されるようにスケジュールすることもできる。\n",
    "\n",
    "```\n",
    "from azureml.pipeline.core import ScheduleRecurrence, Schedule\n",
    "\n",
    "weekly = ScheduleRecurrence(frequency='Week', interval=1)\n",
    "pipeline_schedule = Schedule.create(ws, name='Weekly Predictions',\n",
    "                                        description='batch inferencing',\n",
    "                                        pipeline_id=published_pipeline.id,\n",
    "                                        experiment_name='Batch_Prediction',\n",
    "                                        recurrence=weekly)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20541ddf",
   "metadata": {},
   "source": [
    "## 演習 バッチ推論パイプラインを作成する\n",
    "\n",
    "### ワークスペースの接続"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38f74214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready to use Azure ML 1.28.0 to work with 20210613\n"
     ]
    }
   ],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf372578",
   "metadata": {},
   "source": [
    "### モデルの訓練と登録"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf6d5657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting experiment: mslearn-train-diabetes\n",
      "Loading Data...\n",
      "Training a decision tree model\n",
      "Accuracy: 0.8903333333333333\n",
      "AUC: 0.8780859744265883\n",
      "Model trained and registered.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.core import Model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Create an Azure ML experiment in your workspace\n",
    "experiment = Experiment(workspace=ws, name='mslearn-train-diabetes')\n",
    "run = experiment.start_logging()\n",
    "print(\"Starting experiment:\", experiment.name)\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = pd.read_csv('data/diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a decision tree model\n",
    "print('Training a decision tree model')\n",
    "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the trained model\n",
    "model_file = 'diabetes_model.pkl'\n",
    "joblib.dump(value=model, filename=model_file)\n",
    "run.upload_file(name = 'outputs/' + model_file, path_or_stream = './' + model_file)\n",
    "\n",
    "# Complete the run\n",
    "run.complete()\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Inline Training'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "print('Model trained and registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f716c4d2",
   "metadata": {},
   "source": [
    "### バッチデータの生成とアップロード\n",
    "\n",
    "演習用に、すでにあるデータからランダムサンプリングし、そのデータをAzureMLワークスペースのデータストアにアップロードしてデータセットを登録する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63b75afd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml_globaldatasets - Default = False\n",
      "workspaceblobstore - Default = True\n",
      "workspacefilestore - Default = False\n",
      "Folder created!\n",
      "Saving files...\n",
      "files saved!\n",
      "Uploading files to datastore...\n",
      "Uploading an estimated of 100 files\n",
      "Uploading batch-data/1.csv\n",
      "Uploaded batch-data/1.csv, 1 files out of an estimated total of 100\n",
      "Uploading batch-data/10.csv\n",
      "Uploaded batch-data/10.csv, 2 files out of an estimated total of 100\n",
      "Uploading batch-data/100.csv\n",
      "Uploaded batch-data/100.csv, 3 files out of an estimated total of 100\n",
      "Uploading batch-data/11.csv\n",
      "Uploaded batch-data/11.csv, 4 files out of an estimated total of 100\n",
      "Uploading batch-data/12.csv\n",
      "Uploaded batch-data/12.csv, 5 files out of an estimated total of 100\n",
      "Uploading batch-data/13.csv\n",
      "Uploaded batch-data/13.csv, 6 files out of an estimated total of 100\n",
      "Uploading batch-data/14.csv\n",
      "Uploaded batch-data/14.csv, 7 files out of an estimated total of 100\n",
      "Uploading batch-data/15.csv\n",
      "Uploaded batch-data/15.csv, 8 files out of an estimated total of 100\n",
      "Uploading batch-data/16.csv\n",
      "Uploaded batch-data/16.csv, 9 files out of an estimated total of 100\n",
      "Uploading batch-data/17.csv\n",
      "Uploaded batch-data/17.csv, 10 files out of an estimated total of 100\n",
      "Uploading batch-data/18.csv\n",
      "Uploaded batch-data/18.csv, 11 files out of an estimated total of 100\n",
      "Uploading batch-data/19.csv\n",
      "Uploaded batch-data/19.csv, 12 files out of an estimated total of 100\n",
      "Uploading batch-data/2.csv\n",
      "Uploaded batch-data/2.csv, 13 files out of an estimated total of 100\n",
      "Uploading batch-data/20.csv\n",
      "Uploaded batch-data/20.csv, 14 files out of an estimated total of 100\n",
      "Uploading batch-data/21.csv\n",
      "Uploaded batch-data/21.csv, 15 files out of an estimated total of 100\n",
      "Uploading batch-data/22.csv\n",
      "Uploaded batch-data/22.csv, 16 files out of an estimated total of 100\n",
      "Uploading batch-data/23.csv\n",
      "Uploaded batch-data/23.csv, 17 files out of an estimated total of 100\n",
      "Uploading batch-data/24.csv\n",
      "Uploaded batch-data/24.csv, 18 files out of an estimated total of 100\n",
      "Uploading batch-data/25.csv\n",
      "Uploaded batch-data/25.csv, 19 files out of an estimated total of 100\n",
      "Uploading batch-data/26.csv\n",
      "Uploaded batch-data/26.csv, 20 files out of an estimated total of 100\n",
      "Uploading batch-data/27.csv\n",
      "Uploaded batch-data/27.csv, 21 files out of an estimated total of 100\n",
      "Uploading batch-data/28.csv\n",
      "Uploaded batch-data/28.csv, 22 files out of an estimated total of 100\n",
      "Uploading batch-data/29.csv\n",
      "Uploaded batch-data/29.csv, 23 files out of an estimated total of 100\n",
      "Uploading batch-data/3.csv\n",
      "Uploaded batch-data/3.csv, 24 files out of an estimated total of 100\n",
      "Uploading batch-data/30.csv\n",
      "Uploaded batch-data/30.csv, 25 files out of an estimated total of 100\n",
      "Uploading batch-data/31.csv\n",
      "Uploaded batch-data/31.csv, 26 files out of an estimated total of 100\n",
      "Uploading batch-data/32.csv\n",
      "Uploaded batch-data/32.csv, 27 files out of an estimated total of 100\n",
      "Uploading batch-data/33.csv\n",
      "Uploaded batch-data/33.csv, 28 files out of an estimated total of 100\n",
      "Uploading batch-data/34.csv\n",
      "Uploaded batch-data/34.csv, 29 files out of an estimated total of 100\n",
      "Uploading batch-data/35.csv\n",
      "Uploaded batch-data/35.csv, 30 files out of an estimated total of 100\n",
      "Uploading batch-data/36.csv\n",
      "Uploaded batch-data/36.csv, 31 files out of an estimated total of 100\n",
      "Uploading batch-data/37.csv\n",
      "Uploaded batch-data/37.csv, 32 files out of an estimated total of 100\n",
      "Uploading batch-data/38.csv\n",
      "Uploaded batch-data/38.csv, 33 files out of an estimated total of 100\n",
      "Uploading batch-data/39.csv\n",
      "Uploaded batch-data/39.csv, 34 files out of an estimated total of 100\n",
      "Uploading batch-data/4.csv\n",
      "Uploaded batch-data/4.csv, 35 files out of an estimated total of 100\n",
      "Uploading batch-data/40.csv\n",
      "Uploaded batch-data/40.csv, 36 files out of an estimated total of 100\n",
      "Uploading batch-data/41.csv\n",
      "Uploaded batch-data/41.csv, 37 files out of an estimated total of 100\n",
      "Uploading batch-data/42.csv\n",
      "Uploaded batch-data/42.csv, 38 files out of an estimated total of 100\n",
      "Uploading batch-data/43.csv\n",
      "Uploaded batch-data/43.csv, 39 files out of an estimated total of 100\n",
      "Uploading batch-data/44.csv\n",
      "Uploaded batch-data/44.csv, 40 files out of an estimated total of 100\n",
      "Uploading batch-data/45.csv\n",
      "Uploaded batch-data/45.csv, 41 files out of an estimated total of 100\n",
      "Uploading batch-data/46.csv\n",
      "Uploaded batch-data/46.csv, 42 files out of an estimated total of 100\n",
      "Uploading batch-data/47.csv\n",
      "Uploaded batch-data/47.csv, 43 files out of an estimated total of 100\n",
      "Uploading batch-data/48.csv\n",
      "Uploaded batch-data/48.csv, 44 files out of an estimated total of 100\n",
      "Uploading batch-data/49.csv\n",
      "Uploaded batch-data/49.csv, 45 files out of an estimated total of 100\n",
      "Uploading batch-data/5.csv\n",
      "Uploaded batch-data/5.csv, 46 files out of an estimated total of 100\n",
      "Uploading batch-data/50.csv\n",
      "Uploaded batch-data/50.csv, 47 files out of an estimated total of 100\n",
      "Uploading batch-data/51.csv\n",
      "Uploaded batch-data/51.csv, 48 files out of an estimated total of 100\n",
      "Uploading batch-data/52.csv\n",
      "Uploaded batch-data/52.csv, 49 files out of an estimated total of 100\n",
      "Uploading batch-data/53.csv\n",
      "Uploaded batch-data/53.csv, 50 files out of an estimated total of 100\n",
      "Uploading batch-data/54.csv\n",
      "Uploaded batch-data/54.csv, 51 files out of an estimated total of 100\n",
      "Uploading batch-data/55.csv\n",
      "Uploaded batch-data/55.csv, 52 files out of an estimated total of 100\n",
      "Uploading batch-data/56.csv\n",
      "Uploaded batch-data/56.csv, 53 files out of an estimated total of 100\n",
      "Uploading batch-data/57.csv\n",
      "Uploaded batch-data/57.csv, 54 files out of an estimated total of 100\n",
      "Uploading batch-data/58.csv\n",
      "Uploaded batch-data/58.csv, 55 files out of an estimated total of 100\n",
      "Uploading batch-data/59.csv\n",
      "Uploaded batch-data/59.csv, 56 files out of an estimated total of 100\n",
      "Uploading batch-data/6.csv\n",
      "Uploaded batch-data/6.csv, 57 files out of an estimated total of 100\n",
      "Uploading batch-data/60.csv\n",
      "Uploaded batch-data/60.csv, 58 files out of an estimated total of 100\n",
      "Uploading batch-data/61.csv\n",
      "Uploaded batch-data/61.csv, 59 files out of an estimated total of 100\n",
      "Uploading batch-data/62.csv\n",
      "Uploaded batch-data/62.csv, 60 files out of an estimated total of 100\n",
      "Uploading batch-data/63.csv\n",
      "Uploaded batch-data/63.csv, 61 files out of an estimated total of 100\n",
      "Uploading batch-data/64.csv\n",
      "Uploaded batch-data/64.csv, 62 files out of an estimated total of 100\n",
      "Uploading batch-data/65.csv\n",
      "Uploaded batch-data/65.csv, 63 files out of an estimated total of 100\n",
      "Uploading batch-data/66.csv\n",
      "Uploaded batch-data/66.csv, 64 files out of an estimated total of 100\n",
      "Uploading batch-data/67.csv\n",
      "Uploaded batch-data/67.csv, 65 files out of an estimated total of 100\n",
      "Uploading batch-data/68.csv\n",
      "Uploaded batch-data/68.csv, 66 files out of an estimated total of 100\n",
      "Uploading batch-data/69.csv\n",
      "Uploaded batch-data/69.csv, 67 files out of an estimated total of 100\n",
      "Uploading batch-data/7.csv\n",
      "Uploaded batch-data/7.csv, 68 files out of an estimated total of 100\n",
      "Uploading batch-data/70.csv\n",
      "Uploaded batch-data/70.csv, 69 files out of an estimated total of 100\n",
      "Uploading batch-data/71.csv\n",
      "Uploaded batch-data/71.csv, 70 files out of an estimated total of 100\n",
      "Uploading batch-data/72.csv\n",
      "Uploaded batch-data/72.csv, 71 files out of an estimated total of 100\n",
      "Uploading batch-data/73.csv\n",
      "Uploaded batch-data/73.csv, 72 files out of an estimated total of 100\n",
      "Uploading batch-data/74.csv\n",
      "Uploaded batch-data/74.csv, 73 files out of an estimated total of 100\n",
      "Uploading batch-data/75.csv\n",
      "Uploaded batch-data/75.csv, 74 files out of an estimated total of 100\n",
      "Uploading batch-data/76.csv\n",
      "Uploaded batch-data/76.csv, 75 files out of an estimated total of 100\n",
      "Uploading batch-data/77.csv\n",
      "Uploaded batch-data/77.csv, 76 files out of an estimated total of 100\n",
      "Uploading batch-data/78.csv\n",
      "Uploaded batch-data/78.csv, 77 files out of an estimated total of 100\n",
      "Uploading batch-data/79.csv\n",
      "Uploaded batch-data/79.csv, 78 files out of an estimated total of 100\n",
      "Uploading batch-data/8.csv\n",
      "Uploaded batch-data/8.csv, 79 files out of an estimated total of 100\n",
      "Uploading batch-data/80.csv\n",
      "Uploaded batch-data/80.csv, 80 files out of an estimated total of 100\n",
      "Uploading batch-data/81.csv\n",
      "Uploaded batch-data/81.csv, 81 files out of an estimated total of 100\n",
      "Uploading batch-data/82.csv\n",
      "Uploaded batch-data/82.csv, 82 files out of an estimated total of 100\n",
      "Uploading batch-data/83.csv\n",
      "Uploaded batch-data/83.csv, 83 files out of an estimated total of 100\n",
      "Uploading batch-data/84.csv\n",
      "Uploaded batch-data/84.csv, 84 files out of an estimated total of 100\n",
      "Uploading batch-data/85.csv\n",
      "Uploaded batch-data/85.csv, 85 files out of an estimated total of 100\n",
      "Uploading batch-data/86.csv\n",
      "Uploaded batch-data/86.csv, 86 files out of an estimated total of 100\n",
      "Uploading batch-data/87.csv\n",
      "Uploaded batch-data/87.csv, 87 files out of an estimated total of 100\n",
      "Uploading batch-data/88.csv\n",
      "Uploaded batch-data/88.csv, 88 files out of an estimated total of 100\n",
      "Uploading batch-data/89.csv\n",
      "Uploaded batch-data/89.csv, 89 files out of an estimated total of 100\n",
      "Uploading batch-data/9.csv\n",
      "Uploaded batch-data/9.csv, 90 files out of an estimated total of 100\n",
      "Uploading batch-data/90.csv\n",
      "Uploaded batch-data/90.csv, 91 files out of an estimated total of 100\n",
      "Uploading batch-data/91.csv\n",
      "Uploaded batch-data/91.csv, 92 files out of an estimated total of 100\n",
      "Uploading batch-data/92.csv\n",
      "Uploaded batch-data/92.csv, 93 files out of an estimated total of 100\n",
      "Uploading batch-data/93.csv\n",
      "Uploaded batch-data/93.csv, 94 files out of an estimated total of 100\n",
      "Uploading batch-data/94.csv\n",
      "Uploaded batch-data/94.csv, 95 files out of an estimated total of 100\n",
      "Uploading batch-data/95.csv\n",
      "Uploaded batch-data/95.csv, 96 files out of an estimated total of 100\n",
      "Uploading batch-data/96.csv\n",
      "Uploaded batch-data/96.csv, 97 files out of an estimated total of 100\n",
      "Uploading batch-data/97.csv\n",
      "Uploaded batch-data/97.csv, 98 files out of an estimated total of 100\n",
      "Uploading batch-data/99.csv\n",
      "Uploaded batch-data/99.csv, 99 files out of an estimated total of 100\n",
      "Uploading batch-data/98.csv\n",
      "Uploaded batch-data/98.csv, 100 files out of an estimated total of 100\n",
      "Uploaded 100 files\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore, Dataset\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set default data store\n",
    "ws.set_default_datastore('workspaceblobstore')\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "# Enumerate all datastores, indicating which is the default\n",
    "for ds_name in ws.datastores:\n",
    "    print(ds_name, \"- Default =\", ds_name == default_ds.name)\n",
    "\n",
    "# Load the diabetes data\n",
    "diabetes = pd.read_csv('data/diabetes2.csv')\n",
    "# Get a 100-item sample of the feature columns (not the diabetic label)\n",
    "sample = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].sample(n=100).values\n",
    "\n",
    "# Create a folder\n",
    "batch_folder = './batch-data'\n",
    "os.makedirs(batch_folder, exist_ok=True)\n",
    "print(\"Folder created!\")\n",
    "\n",
    "# Save each sample as a separate file\n",
    "print(\"Saving files...\")\n",
    "for i in range(100):\n",
    "    fname = str(i+1) + '.csv'\n",
    "    sample[i].tofile(os.path.join(batch_folder, fname), sep=\",\")\n",
    "print(\"files saved!\")\n",
    "\n",
    "# Upload the files to the default datastore\n",
    "print(\"Uploading files to datastore...\")\n",
    "default_ds = ws.get_default_datastore()\n",
    "default_ds.upload(src_dir=\"batch-data\", target_path=\"batch-data\", overwrite=True, show_progress=True)\n",
    "\n",
    "# Register a dataset for the input data\n",
    "batch_data_set = Dataset.File.from_files(path=(default_ds, 'batch-data/'), validate=False)\n",
    "try:\n",
    "    batch_data_set = batch_data_set.register(workspace=ws, \n",
    "                                             name='batch-data',\n",
    "                                             description='batch data',\n",
    "                                             create_new_version=True)\n",
    "except Exception as ex:\n",
    "    print(ex)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b99323",
   "metadata": {},
   "source": [
    "### コンピューティングの作成\n",
    "\n",
    "パイプラインにはコンピューティングコンテキストが必要なので、コンピューティングクラスタを指定する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd3e2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing cluster, use it.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"msl-20210613b\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    inference_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        inference_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        inference_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ad62d0",
   "metadata": {},
   "source": [
    "### バッチ推論パイプラインの作成\n",
    "\n",
    "パイプラインにはバッチ推論を実行するためのPythonコードが必要なので、パイプラインで使用するすべてのファイルを保管するフォルダを作成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e4b8e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_pipeline\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Create a folder for the experiment files\n",
    "experiment_folder = 'batch_pipeline'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(experiment_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00899684",
   "metadata": {},
   "source": [
    "実際の作業を行うPythonスクリプトを作成し、pipelineフォルダに保存する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48b9a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing batch_pipeline/batch_diabetes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $experiment_folder/batch_diabetes.py\n",
    "import os\n",
    "import numpy as np\n",
    "from azureml.core import Model\n",
    "import joblib\n",
    "\n",
    "\n",
    "def init():\n",
    "    # Runs when the pipeline step is initialized\n",
    "    global model\n",
    "\n",
    "    # load the model\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "\n",
    "def run(mini_batch):\n",
    "    # This runs for each batch\n",
    "    resultList = []\n",
    "\n",
    "    # process each file in the batch\n",
    "    for f in mini_batch:\n",
    "        # Read the comma-delimited data into an array\n",
    "        data = np.genfromtxt(f, delimiter=',')\n",
    "        # Reshape into a 2-dimensional array for prediction (model expects multiple items)\n",
    "        prediction = model.predict(data.reshape(1, -1))\n",
    "        # Append prediction to results\n",
    "        resultList.append(\"{}: {}\".format(os.path.basename(f), prediction[0]))\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60739766",
   "metadata": {},
   "source": [
    "次に、スクリプトが必要となる依存関係を含む実行コンテキストを定義する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2299e3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.runconfig import DEFAULT_CPU_IMAGE\n",
    "from azureml.core.runconfig import CondaDependencies\n",
    "\n",
    "# モデルに必要な依存関係の追加\n",
    "# scikit-learnモデルにはscikit-learnが必要\n",
    "# 並列パイプラインのステップには、azureml-coreとazureml-dataprep[fuse]が必要\n",
    "cd = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n",
    "                              pip_packages=['azureml-defaults','azureml-core','azureml-dataprep[fuse]'])\n",
    "\n",
    "batch_env = Environment(name='batch_environment')\n",
    "batch_env.python.conda_dependencies = cd\n",
    "batch_env.docker.base_image = DEFAULT_CPU_IMAGE\n",
    "print('Configuration ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d77494",
   "metadata": {},
   "source": [
    "バッチ予測スクリプトを実行し、入力データから予測値を生成し、その結果をテキストファイルとして出力フォルダに保存するパイプラインを使用することになる。  \n",
    "このためにはParallelRunStepを使用する。これにより、バッチデータを並行して処理し、  \n",
    "結果を*parallel_run_step.txt*という単一の出力ファイルにまとめることができる。\n",
    "\n",
    "> 注:\"enabled\"は非推奨であるという渓谷が表示されることがあるが、無視して問題ない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b5dc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps defined\n"
     ]
    }
   ],
   "source": [
    "from azureml.pipeline.steps import ParallelRunConfig, ParallelRunStep\n",
    "from azureml.pipeline.core import PipelineData\n",
    "from azureml.core.runconfig import DockerConfiguration\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "output_dir = PipelineData(name='inferences', \n",
    "                          datastore=default_ds, \n",
    "                          output_path_on_compute='diabetes/results')\n",
    "\n",
    "parallel_run_config = ParallelRunConfig(\n",
    "    source_directory=experiment_folder,\n",
    "    entry_script=\"batch_diabetes.py\",\n",
    "    mini_batch_size=\"5\",\n",
    "    error_threshold=10,\n",
    "    output_action=\"append_row\",\n",
    "    environment=batch_env,\n",
    "    compute_target=inference_cluster,\n",
    "    node_count=2)\n",
    "\n",
    "parallelrun_step = ParallelRunStep(\n",
    "    name='batch-score-diabetes',\n",
    "    parallel_run_config=parallel_run_config,\n",
    "    inputs=[batch_data_set.as_named_input('diabetes_batch')],\n",
    "    output=output_dir,\n",
    "    arguments=[],\n",
    "    allow_reuse=True\n",
    ")\n",
    "\n",
    "print('Steps defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015d5b46",
   "metadata": {},
   "source": [
    "あとは、このステップをパイプラインに入れて実行するのみ　※時間がかかる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ffcdac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batch-score-diabetes [156ead4b][e6f294ef-33b2-4307-8139-34be78d6b6fc], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun f2ae0c56-645d-4323-a5e6-eea5d180d89f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f2ae0c56-645d-4323-a5e6-eea5d180d89f?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "PipelineRunId: f2ae0c56-645d-4323-a5e6-eea5d180d89f\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/f2ae0c56-645d-4323-a5e6-eea5d180d89f?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: cd739555-37f2-4496-a40d-2cb55edb7c5c\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/cd739555-37f2-4496-a40d-2cb55edb7c5c?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "StepRun( batch-score-diabetes ) Status: NotStarted\n",
      "StepRun( batch-score-diabetes ) Status: Queued\n",
      "StepRun( batch-score-diabetes ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/20_image_build_log.txt\n",
      "=============================================\n",
      "2021/06/15 08:01:53 Downloading source code...\n",
      "2021/06/15 08:01:54 Finished downloading source code\n",
      "2021/06/15 08:01:54 Creating Docker network: acb_default_network, driver: 'bridge'\n",
      "2021/06/15 08:01:55 Successfully set up Docker network: acb_default_network\n",
      "2021/06/15 08:01:55 Setting up Docker configuration...\n",
      "2021/06/15 08:01:56 Successfully set up Docker configuration\n",
      "2021/06/15 08:01:56 Logging in to registry: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "2021/06/15 08:01:57 Successfully logged into 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "2021/06/15 08:01:57 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/06/15 08:01:57 Scanning for dependencies...\n",
      "2021/06/15 08:01:57 Successfully scanned dependencies\n",
      "2021/06/15 08:01:57 Launching container with name: acb_step_0\n",
      "Sending build context to Docker daemon  66.56kB\n",
      "\n",
      "Step 1/18 : FROM mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1@sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1@sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232: Pulling from azureml/openmpi3.1.2-ubuntu18.04\n",
      "d519e2592276: Pulling fs layer\n",
      "d22d2dfcfa9c: Pulling fs layer\n",
      "b3afe92c540b: Pulling fs layer\n",
      "b45c209a4d67: Pulling fs layer\n",
      "3f5a608df989: Pulling fs layer\n",
      "11df60c3c446: Pulling fs layer\n",
      "3306300f7441: Pulling fs layer\n",
      "d5f61fd90197: Pulling fs layer\n",
      "3c91cee49561: Pulling fs layer\n",
      "3166a3588baf: Pulling fs layer\n",
      "386667a0fc79: Pulling fs layer\n",
      "3f5a608df989: Waiting\n",
      "11df60c3c446: Waiting\n",
      "3306300f7441: Waiting\n",
      "d5f61fd90197: Waiting\n",
      "3c91cee49561: Waiting\n",
      "3166a3588baf: Waiting\n",
      "386667a0fc79: Waiting\n",
      "b45c209a4d67: Waiting\n",
      "b3afe92c540b: Verifying Checksum\n",
      "b3afe92c540b: Download complete\n",
      "d22d2dfcfa9c: Verifying Checksum\n",
      "d22d2dfcfa9c: Download complete\n",
      "d519e2592276: Verifying Checksum\n",
      "d519e2592276: Download complete\n",
      "11df60c3c446: Verifying Checksum\n",
      "11df60c3c446: Download complete\n",
      "3f5a608df989: Verifying Checksum\n",
      "3f5a608df989: Download complete\n",
      "b45c209a4d67: Verifying Checksum\n",
      "b45c209a4d67: Download complete\n",
      "d5f61fd90197: Verifying Checksum\n",
      "d5f61fd90197: Download complete\n",
      "3c91cee49561: Verifying Checksum\n",
      "3c91cee49561: Download complete\n",
      "3166a3588baf: Verifying Checksum\n",
      "3166a3588baf: Download complete\n",
      "386667a0fc79: Verifying Checksum\n",
      "386667a0fc79: Download complete\n",
      "d519e2592276: Pull complete\n",
      "d22d2dfcfa9c: Pull complete\n",
      "3306300f7441: Verifying Checksum\n",
      "3306300f7441: Download complete\n",
      "b3afe92c540b: Pull complete\n",
      "b45c209a4d67: Pull complete\n",
      "3f5a608df989: Pull complete\n",
      "11df60c3c446: Pull complete\n",
      "3306300f7441: Pull complete\n",
      "d5f61fd90197: Pull complete\n",
      "3c91cee49561: Pull complete\n",
      "3166a3588baf: Pull complete\n",
      "386667a0fc79: Pull complete\n",
      "Digest: sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "Status: Downloaded newer image for mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1@sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      " ---> 821000375236\n",
      "Step 2/18 : USER root\n",
      " ---> Running in 2d83f8398b45\n",
      "Removing intermediate container 2d83f8398b45\n",
      " ---> 07d046377d05\n",
      "Step 3/18 : RUN mkdir -p $HOME/.cache\n",
      " ---> Running in fc7f22fcebbf\n",
      "Removing intermediate container fc7f22fcebbf\n",
      " ---> d96d05206376\n",
      "Step 4/18 : WORKDIR /\n",
      " ---> Running in 8d1580e672a6\n",
      "Removing intermediate container 8d1580e672a6\n",
      " ---> 8091c314dff8\n",
      "Step 5/18 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n",
      " ---> f3e88f2d0543\n",
      "Step 6/18 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n",
      " ---> Running in 642327b80852\n",
      "Removing intermediate container 642327b80852\n",
      " ---> bc096c7f4d86\n",
      "Step 7/18 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n",
      " ---> fe98a4944499\n",
      "Step 8/18 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n",
      " ---> Running in 957cb0844cab\n",
      "Collecting package metadata (repodata.json): ...working... \n",
      "done\n",
      "Solving environment: ...working... \n",
      "done\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  |            |   0% \n",
      "mkl-2019.4           | 204.1 MB  | 5          |   5% \n",
      "mkl-2019.4           | 204.1 MB  | #          |  11% \n",
      "mkl-2019.4           | 204.1 MB  | #5         |  16% \n",
      "mkl-2019.4           | 204.1 MB  | ##         |  21% \n",
      "mkl-2019.4           | 204.1 MB  | ##6        |  26% \n",
      "mkl-2019.4           | 204.1 MB  | ###1       |  31% \n",
      "mkl-2019.4           | 204.1 MB  | ###6       |  36% \n",
      "mkl-2019.4           | 204.1 MB  | ####       |  41% \n",
      "mkl-2019.4           | 204.1 MB  | ####5      |  46% \n",
      "mkl-2019.4           | 204.1 MB  | #####      |  50% \n",
      "mkl-2019.4           | 204.1 MB  | #####4     |  55% \n",
      "mkl-2019.4           | 204.1 MB  | #####9     |  59% \n",
      "mkl-2019.4           | 204.1 MB  | ######4    |  64% \n",
      "mkl-2019.4           | 204.1 MB  | ######8    |  69% \n",
      "mkl-2019.4           | 204.1 MB  | #######2   |  73% \n",
      "mkl-2019.4           | 204.1 MB  | #######8   |  78% \n",
      "mkl-2019.4           | 204.1 MB  | ########3  |  83% \n",
      "mkl-2019.4           | 204.1 MB  | ########8  |  88% \n",
      "mkl-2019.4           | 204.1 MB  | #########3 |  94% \n",
      "mkl-2019.4           | 204.1 MB  | #########8 |  99% \n",
      "\n",
      "mkl-2019.4           | 204.1 MB  | ########## | 100% \n",
      "\n",
      "pip-20.2.4           | 2.0 MB    |            |   0% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "pip-20.2.4           | 2.0 MB    | ########## | 100% \n",
      "\n",
      "sqlite-3.23.1        | 1.5 MB    |            |   0% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "sqlite-3.23.1        | 1.5 MB    | ########## | 100% \n",
      "\n",
      "libedit-3.1          | 171 KB    |            |   0% \n",
      "libedit-3.1          | 171 KB    | ########## | 100% \n",
      "\n",
      "ca-certificates-2020 | 128 KB    |            |   0% \n",
      "ca-certificates-2020 | 128 KB    | ########## | 100% \n",
      "\n",
      "openssl-1.0.2u       | 3.1 MB    |            |   0% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "openssl-1.0.2u       | 3.1 MB    | ########## | 100% \n",
      "\n",
      "python-3.6.2         | 27.0 MB   |            |   0% \n",
      "python-3.6.2         | 27.0 MB   | #4         |  15% \n",
      "python-3.6.2         | 27.0 MB   | #####      |  50% \n",
      "python-3.6.2         | 27.0 MB   | #######3   |  73% \n",
      "python-3.6.2         | 27.0 MB   | ########9  |  89% \n",
      "python-3.6.2         | 27.0 MB   | ########## | 100% \n",
      "\n",
      "numpy-1.19.1         | 20 KB     |            |   0% \n",
      "numpy-1.19.1         | 20 KB     | ########## | 100% \n",
      "\n",
      "libffi-3.2.1         | 52 KB     |            |   0% \n",
      "libffi-3.2.1         | 52 KB     | ########## | 100% \n",
      "\n",
      "zlib-1.2.11          | 120 KB    |            |   0% \n",
      "zlib-1.2.11          | 120 KB    | ########## | 100% \n",
      "\n",
      "mkl-service-2.3.0    | 208 KB    |            |   0% \n",
      "mkl-service-2.3.0    | 208 KB    | ########## | 100% \n",
      "\n",
      "tk-8.6.10            | 3.2 MB    |            |   0% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "tk-8.6.10            | 3.2 MB    | ########## | 100% \n",
      "\n",
      "threadpoolctl-2.1.0  | 16 KB     |            |   0% \n",
      "threadpoolctl-2.1.0  | 16 KB     | ########## | 100% \n",
      "\n",
      "mkl_fft-1.2.0        | 164 KB    |            |   0% \n",
      "mkl_fft-1.2.0        | 164 KB    | ########## | 100% \n",
      "\n",
      "six-1.15.0           | 13 KB     |            |   0% \n",
      "six-1.15.0           | 13 KB     | ########## | 100% \n",
      "\n",
      "readline-7.0         | 387 KB    |            |   0% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "readline-7.0         | 387 KB    | ########## | 100% \n",
      "\n",
      "scikit-learn-0.23.2  | 6.9 MB    |            |   0% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "scikit-learn-0.23.2  | 6.9 MB    | ########## | 100% \n",
      "\n",
      "scipy-1.5.2          | 18.5 MB   |            |   0% \n",
      "scipy-1.5.2          | 18.5 MB   | ###7       |  38% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "scipy-1.5.2          | 18.5 MB   | ########## | 100% \n",
      "\n",
      "setuptools-50.3.0    | 891 KB    |            |   0% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "setuptools-50.3.0    | 891 KB    | ########## | 100% \n",
      "\n",
      "certifi-2020.6.20    | 160 KB    |            |   0% \n",
      "certifi-2020.6.20    | 160 KB    | ########## | 100% \n",
      "\n",
      "intel-openmp-2020.2  | 947 KB    |            |   0% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "intel-openmp-2020.2  | 947 KB    | ########## | 100% \n",
      "\n",
      "ncurses-6.0          | 907 KB    |            |   0% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "ncurses-6.0          | 907 KB    | ########## | 100% \n",
      "\n",
      "libgcc-ng-9.1.0      | 8.1 MB    |            |   0% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########9  |  90% \n",
      "libgcc-ng-9.1.0      | 8.1 MB    | ########## | 100% \n",
      "\n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    |            |   0% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "libstdcxx-ng-9.1.0   | 4.0 MB    | ########## | 100% \n",
      "\n",
      "blas-1.0             | 6 KB      |            |   0% \n",
      "blas-1.0             | 6 KB      | ########## | 100% \n",
      "\n",
      "mkl_random-1.1.0     | 369 KB    |            |   0% \n",
      "mkl_random-1.1.0     | 369 KB    | ########## | 100% \n",
      "\n",
      "joblib-0.17.0        | 205 KB    |            |   0% \n",
      "joblib-0.17.0        | 205 KB    | ########## | 100% \n",
      "\n",
      "numpy-base-1.19.1    | 5.2 MB    |            |   0% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "numpy-base-1.19.1    | 5.2 MB    | ########## | 100% \n",
      "\n",
      "libgfortran-ng-7.3.0 | 1.3 MB    |            |   0% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "libgfortran-ng-7.3.0 | 1.3 MB    | ########## | 100% \n",
      "\n",
      "xz-5.2.5             | 438 KB    |            |   0% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "xz-5.2.5             | 438 KB    | ########## | 100% \n",
      "\n",
      "wheel-0.35.1         | 36 KB     |            |   0% \n",
      "wheel-0.35.1         | 36 KB     | ########## | 100% \n",
      "Preparing transaction: ...working... done\n",
      "Verifying transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "Installing pip dependencies: ...working... \n",
      "Ran pip subprocess with arguments:\n",
      "['/azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.g3jmb9rl.requirements.txt']\n",
      "Pip subprocess output:\n",
      "Collecting azureml-defaults~=1.28.0\n",
      "  Downloading azureml_defaults-1.28.0-py3-none-any.whl (3.1 kB)\n",
      "Collecting azureml-core~=1.28.0\n",
      "  Downloading azureml_core-1.28.0.post1-py3-none-any.whl (2.2 MB)\n",
      "Collecting azureml-dataprep[fuse]\n",
      "  Downloading azureml_dataprep-2.18.0-py3-none-any.whl (39.4 MB)\n",
      "Collecting azureml-model-management-sdk==1.0.1b6.post1\n",
      "  Downloading azureml_model_management_sdk-1.0.1b6.post1-py2.py3-none-any.whl (130 kB)\n",
      "Collecting configparser==3.7.4\n",
      "  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\n",
      "Collecting azureml-dataset-runtime[fuse]~=1.28.0\n",
      "  Downloading azureml_dataset_runtime-1.28.0-py3-none-any.whl (3.5 kB)\n",
      "Collecting applicationinsights>=0.11.7\n",
      "  Downloading applicationinsights-0.11.10-py2.py3-none-any.whl (55 kB)\n",
      "Collecting werkzeug<=1.0.1,>=0.16.1\n",
      "  Downloading Werkzeug-1.0.1-py2.py3-none-any.whl (298 kB)\n",
      "Collecting gunicorn==20.1.0\n",
      "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
      "Collecting flask==1.0.3\n",
      "  Downloading Flask-1.0.3-py2.py3-none-any.whl (92 kB)\n",
      "Collecting json-logging-py==0.2\n",
      "  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n",
      "Collecting msrest<1.0.0,>=0.5.1\n",
      "  Downloading msrest-0.6.21-py2.py3-none-any.whl (85 kB)\n",
      "Collecting azure-mgmt-storage<16.0.0,>=1.5.0\n",
      "  Downloading azure_mgmt_storage-11.2.0-py2.py3-none-any.whl (547 kB)\n",
      "Collecting pytz\n",
      "  Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting azure-mgmt-keyvault<7.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_keyvault-2.2.0-py2.py3-none-any.whl (89 kB)\n",
      "Collecting pyopenssl<21.0.0\n",
      "  Downloading pyOpenSSL-20.0.1-py2.py3-none-any.whl (54 kB)\n",
      "Collecting jmespath<1.0.0\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting azure-mgmt-resource<15.0.0,>=1.2.1\n",
      "  Downloading azure_mgmt_resource-13.0.0-py2.py3-none-any.whl (1.3 MB)\n",
      "Collecting python-dateutil<3.0.0,>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting ndg-httpsclient\n",
      "  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\n",
      "Collecting ruamel.yaml<0.17.5,>=0.15.35\n",
      "  Downloading ruamel.yaml-0.17.4-py3-none-any.whl (101 kB)\n",
      "Collecting SecretStorage<4.0.0\n",
      "  Downloading SecretStorage-3.3.1-py3-none-any.whl (15 kB)\n",
      "Collecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<4.0.0\n",
      "  Downloading cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2 MB)\n",
      "Collecting PyJWT<3.0.0\n",
      "  Downloading PyJWT-2.1.0-py3-none-any.whl (16 kB)\n",
      "Collecting contextlib2<1.0.0\n",
      "  Downloading contextlib2-0.6.0.post1-py2.py3-none-any.whl (9.8 kB)\n",
      "Collecting jsonpickle<3.0.0\n",
      "  Downloading jsonpickle-2.0.0-py2.py3-none-any.whl (37 kB)\n",
      "Collecting backports.tempfile\n",
      "  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Collecting pathspec<1.0.0\n",
      "  Downloading pathspec-0.8.1-py2.py3-none-any.whl (28 kB)\n",
      "Collecting azure-mgmt-authorization<1.0.0,>=0.40.0\n",
      "  Downloading azure_mgmt_authorization-0.61.0-py2.py3-none-any.whl (94 kB)\n",
      "Collecting azure-graphrbac<1.0.0,>=0.40.0\n",
      "  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n",
      "Collecting urllib3>=1.23\n",
      "  Downloading urllib3-1.26.5-py2.py3-none-any.whl (138 kB)\n",
      "Collecting requests<3.0.0,>=2.19.1\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting azure-common<2.0.0,>=1.1.12\n",
      "  Downloading azure_common-1.1.27-py2.py3-none-any.whl (12 kB)\n",
      "Collecting msrestazure>=0.4.33\n",
      "  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n",
      "Collecting docker<5.0.0\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Collecting adal>=1.2.0\n",
      "  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n",
      "Collecting azure-mgmt-containerregistry>=2.0.0\n",
      "  Downloading azure_mgmt_containerregistry-8.0.0-py2.py3-none-any.whl (663 kB)\n",
      "Collecting cloudpickle<2.0.0,>=1.1.0\n",
      "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
      "Collecting dotnetcore2<3.0.0,>=2.1.14\n",
      "  Downloading dotnetcore2-2.1.21-py3-none-manylinux1_x86_64.whl (28.7 MB)\n",
      "Collecting azure-identity<1.5.0,>=1.2.0\n",
      "  Downloading azure_identity-1.4.1-py2.py3-none-any.whl (86 kB)\n",
      "Collecting azureml-dataprep-native<37.0.0,>=36.0.0\n",
      "  Downloading azureml_dataprep_native-36.0.0-cp36-cp36m-manylinux1_x86_64.whl (1.3 MB)\n",
      "Collecting azureml-dataprep-rslex<1.17.0a,>=1.16.0dev0\n",
      "  Downloading azureml_dataprep_rslex-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (83.9 MB)\n",
      "Collecting fusepy<4.0.0,>=3.0.1; extra == \"fuse\"\n",
      "  Downloading fusepy-3.0.1.tar.gz (11 kB)\n",
      "Collecting liac-arff>=2.1.1\n",
      "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.g3jmb9rl.requirements.txt (line 1)) (1.15.0)\n",
      "Collecting dill>=0.2.7.1\n",
      "  Downloading dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting pandas>=0.20.2\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.0 in /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/lib/python3.6/site-packages (from azureml-model-management-sdk==1.0.1b6.post1->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.g3jmb9rl.requirements.txt (line 1)) (1.19.1)\n",
      "Collecting pyarrow<4.0.0,>=0.17.0\n",
      "  Downloading pyarrow-3.0.0-cp36-cp36m-manylinux2014_x86_64.whl (20.7 MB)\n",
      "Requirement already satisfied, skipping upgrade: setuptools>=3.0 in /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/lib/python3.6/site-packages (from gunicorn==20.1.0->azureml-defaults~=1.28.0->-r /azureml-environment-setup/condaenv.g3jmb9rl.requirements.txt (line 1)) (50.3.0.post20201006)\n",
      "Collecting Jinja2>=2.10\n",
      "  Downloading Jinja2-3.0.1-py3-none-any.whl (133 kB)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting click>=5.1\n",
      "  Downloading click-8.0.1-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/lib/python3.6/site-packages (from msrest<1.0.0,>=0.5.1->azureml-core~=1.28.0->-r /azureml-environment-setup/condaenv.g3jmb9rl.requirements.txt (line 2)) (2020.6.20)\n",
      "Collecting requests-oauthlib>=0.5.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting isodate>=0.6.0\n",
      "  Downloading isodate-0.6.0-py2.py3-none-any.whl (45 kB)\n",
      "Collecting pyasn1>=0.1.1\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.10\"\n",
      "  Downloading ruamel.yaml.clib-0.2.2-cp36-cp36m-manylinux1_x86_64.whl (549 kB)\n",
      "Collecting jeepney>=0.6\n",
      "  Downloading jeepney-0.6.0-py3-none-any.whl (45 kB)\n",
      "Collecting cffi>=1.12\n",
      "  Downloading cffi-1.14.5-cp36-cp36m-manylinux1_x86_64.whl (401 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-4.5.0-py3-none-any.whl (17 kB)\n",
      "Collecting backports.weakref\n",
      "  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting websocket-client>=0.32.0\n",
      "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
      "Collecting azure-mgmt-core<2.0.0,>=1.2.0\n",
      "  Downloading azure_mgmt_core-1.2.2-py2.py3-none-any.whl (21 kB)\n",
      "Collecting distro>=1.2.0\n",
      "  Downloading distro-1.5.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting msal-extensions~=0.2.2\n",
      "  Downloading msal_extensions-0.2.2-py2.py3-none-any.whl (15 kB)\n",
      "Collecting msal<2.0.0,>=1.3.0\n",
      "  Downloading msal-1.12.0-py2.py3-none-any.whl (66 kB)\n",
      "Collecting azure-core<2.0.0,>=1.0.0\n",
      "  Downloading azure_core-1.15.0-py2.py3-none-any.whl (138 kB)\n",
      "Collecting MarkupSafe>=2.0\n",
      "  Downloading MarkupSafe-2.0.1-cp36-cp36m-manylinux2010_x86_64.whl (30 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pycparser\n",
      "  Downloading pycparser-2.20-py2.py3-none-any.whl (112 kB)\n",
      "Collecting typing-extensions>=3.6.4; python_version < \"3.8\"\n",
      "  Downloading typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.4.1-py3-none-any.whl (5.2 kB)\n",
      "Collecting portalocker~=1.0; platform_system != \"Windows\"\n",
      "  Downloading portalocker-1.7.1-py2.py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: json-logging-py, fusepy, liac-arff\n",
      "  Building wheel for json-logging-py (setup.py): started\n",
      "  Building wheel for json-logging-py (setup.py): finished with status 'done'\n",
      "  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=3622eaa34f23da27bdbd3090900ec4bf6bf79ef59876cf999907ec85e9d2de3f\n",
      "  Stored in directory: /root/.cache/pip/wheels/e2/1d/52/535a274b9c2ce7d4064838f2bdb62013801281ef7d7f21e2ee\n",
      "  Building wheel for fusepy (setup.py): started\n",
      "  Building wheel for fusepy (setup.py): finished with status 'done'\n",
      "  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10504 sha256=4e026ed78045fd325e1cf06231eafd029213979665d1792fba0630708d977dd0\n",
      "  Stored in directory: /root/.cache/pip/wheels/21/5c/83/1dd7e8a232d12227e5410120f4374b33adeb4037473105b079\n",
      "  Building wheel for liac-arff (setup.py): started\n",
      "  Building wheel for liac-arff (setup.py): finished with status 'done'\n",
      "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11730 sha256=d83a6fef204762d9a2e12d5059c590f0ee557f70843f01a920cf6267fe2761a7\n",
      "  Stored in directory: /root/.cache/pip/wheels/53/ba/da/8562a6a6dbb428fd1ecc21053106df3948645cd991958f669b\n",
      "Successfully built json-logging-py fusepy liac-arff\n",
      "Installing collected packages: liac-arff, dill, urllib3, chardet, idna, requests, pytz, python-dateutil, pandas, pycparser, cffi, cryptography, PyJWT, adal, azureml-model-management-sdk, oauthlib, requests-oauthlib, isodate, msrest, azure-common, msrestazure, azure-mgmt-storage, azure-mgmt-keyvault, pyopenssl, jmespath, azure-mgmt-resource, pyasn1, ndg-httpsclient, ruamel.yaml.clib, ruamel.yaml, jeepney, SecretStorage, contextlib2, typing-extensions, zipp, importlib-metadata, jsonpickle, backports.weakref, backports.tempfile, pathspec, azure-mgmt-authorization, azure-graphrbac, websocket-client, docker, azure-core, azure-mgmt-core, azure-mgmt-containerregistry, azureml-core, configparser, pyarrow, cloudpickle, distro, dotnetcore2, portalocker, msal, msal-extensions, azure-identity, azureml-dataprep-native, azureml-dataprep-rslex, fusepy, azureml-dataprep, azureml-dataset-runtime, applicationinsights, werkzeug, gunicorn, MarkupSafe, Jinja2, itsdangerous, click, flask, json-logging-py, azureml-defaults\n",
      "Successfully installed Jinja2-3.0.1 MarkupSafe-2.0.1 PyJWT-2.1.0 SecretStorage-3.3.1 adal-1.2.7 applicationinsights-0.11.10 azure-common-1.1.27 azure-core-1.15.0 azure-graphrbac-0.61.1 azure-identity-1.4.1 azure-mgmt-authorization-0.61.0 azure-mgmt-containerregistry-8.0.0 azure-mgmt-core-1.2.2 azure-mgmt-keyvault-2.2.0 azure-mgmt-resource-13.0.0 azure-mgmt-storage-11.2.0 azureml-core-1.28.0.post1 azureml-dataprep-2.18.0 azureml-dataprep-native-36.0.0 azureml-dataprep-rslex-1.16.0 azureml-dataset-runtime-1.28.0 azureml-defaults-1.28.0 azureml-model-management-sdk-1.0.1b6.post1 backports.tempfile-1.0 backports.weakref-1.0.post1 cffi-1.14.5 chardet-4.0.0 click-8.0.1 cloudpickle-1.6.0 configparser-3.7.4 contextlib2-0.6.0.post1 cryptography-3.4.7 dill-0.3.4 distro-1.5.0 docker-4.4.4 dotnetcore2-2.1.21 flask-1.0.3 fusepy-3.0.1 gunicorn-20.1.0 idna-2.10 importlib-metadata-4.5.0 isodate-0.6.0 itsdangerous-2.0.1 jeepney-0.6.0 jmespath-0.10.0 json-logging-py-0.2 jsonpickle-2.0.0 liac-arff-2.5.0 msal-1.12.0 msal-extensions-0.2.2 msrest-0.6.21 msrestazure-0.6.4 ndg-httpsclient-0.5.1 oauthlib-3.1.1 pandas-1.1.5 pathspec-0.8.1 portalocker-1.7.1 pyarrow-3.0.0 pyasn1-0.4.8 pycparser-2.20 pyopenssl-20.0.1 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 requests-oauthlib-1.3.0 ruamel.yaml-0.17.4 ruamel.yaml.clib-0.2.2 typing-extensions-3.10.0.0 urllib3-1.26.5 websocket-client-1.1.0 werkzeug-1.0.1 zipp-3.4.1\n",
      "\n",
      "done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n",
      "\u001b[91m\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.9.2\n",
      "  latest version: 4.10.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\u001b[0mWARNING: /root/.conda/pkgs does not exist\n",
      "Removing intermediate container 957cb0844cab\n",
      " ---> 3cef2b002ba7\n",
      "Step 9/18 : ENV PATH /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/bin:$PATH\n",
      " ---> Running in 4d60bd453ae6\n",
      "Removing intermediate container 4d60bd453ae6\n",
      " ---> 9b2d31f5f420\n",
      "Step 10/18 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n",
      " ---> 103a165c228f\n",
      "Step 11/18 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n",
      " ---> 280063041b36\n",
      "Step 12/18 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34\n",
      " ---> Running in 249e9db4bf87\n",
      "Report materialized dependencies for the environment\n",
      "Reading environment context\n",
      "Exporting conda environment\n",
      "Sending request with materialized conda environment details\n",
      "Successfully sent materialized environment details\n",
      "Removing intermediate container 249e9db4bf87\n",
      " ---> 83bf5cfec021\n",
      "Step 13/18 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34\n",
      " ---> Running in b44110ccc3b1\n",
      "Removing intermediate container b44110ccc3b1\n",
      " ---> af7d46619885\n",
      "Step 14/18 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_9227c6a4a5c53cc7836db22683f3eb34/lib:$LD_LIBRARY_PATH\n",
      " ---> Running in 8ed49136c4d2\n",
      "Removing intermediate container 8ed49136c4d2\n",
      " ---> f59f2d55a54a\n",
      "Step 15/18 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n",
      " ---> 5f728351e62b\n",
      "Step 16/18 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n",
      " ---> Running in 5fd4c3c75d12\n",
      "Removing intermediate container 5fd4c3c75d12\n",
      " ---> f3860cdd715d\n",
      "Step 17/18 : ENV AZUREML_ENVIRONMENT_IMAGE True\n",
      " ---> Running in 354be89db447\n",
      "Removing intermediate container 354be89db447\n",
      " ---> 339bde4c798b\n",
      "Step 18/18 : CMD [\"bash\"]\n",
      " ---> Running in fcae3649d3d1\n",
      "Removing intermediate container fcae3649d3d1\n",
      " ---> 1dd5b0b0a7a8\n",
      "Successfully built 1dd5b0b0a7a8\n",
      "Successfully tagged 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d:latest\n",
      "Successfully tagged 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d:1\n",
      "2021/06/15 08:05:55 Successfully executed container: acb_step_0\n",
      "2021/06/15 08:05:55 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/06/15 08:05:55 Pushing image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d:1, attempt 1\n",
      "The push refers to repository [322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d]\n",
      "c69acd8784f8: Preparing\n",
      "30f9174d4254: Preparing\n",
      "dbbb0181e4d7: Preparing\n",
      "6a823bdc1649: Preparing\n",
      "b62651620a56: Preparing\n",
      "054c95c3ca45: Preparing\n",
      "aeee97c66e67: Preparing\n",
      "1d5d6e82b9b6: Preparing\n",
      "c2ad7eb58454: Preparing\n",
      "5a817c02ccf1: Preparing\n",
      "08d6fac9c4d0: Preparing\n",
      "de5226ffdd67: Preparing\n",
      "8d9f57db5cd6: Preparing\n",
      "09de504e442b: Preparing\n",
      "f86a0c2bc4c2: Preparing\n",
      "cb3dceea19cb: Preparing\n",
      "f5257ad8a814: Preparing\n",
      "9f10818f1f96: Preparing\n",
      "27502392e386: Preparing\n",
      "c95d2191d777: Preparing\n",
      "054c95c3ca45: Waiting\n",
      "aeee97c66e67: Waiting\n",
      "1d5d6e82b9b6: Waiting\n",
      "c2ad7eb58454: Waiting\n",
      "5a817c02ccf1: Waiting\n",
      "08d6fac9c4d0: Waiting\n",
      "de5226ffdd67: Waiting\n",
      "8d9f57db5cd6: Waiting\n",
      "09de504e442b: Waiting\n",
      "f86a0c2bc4c2: Waiting\n",
      "cb3dceea19cb: Waiting\n",
      "f5257ad8a814: Waiting\n",
      "9f10818f1f96: Waiting\n",
      "27502392e386: Waiting\n",
      "c95d2191d777: Waiting\n",
      "6a823bdc1649: Pushed\n",
      "dbbb0181e4d7: Pushed\n",
      "c69acd8784f8: Pushed\n",
      "30f9174d4254: Pushed\n",
      "054c95c3ca45: Pushed\n",
      "1d5d6e82b9b6: Pushed\n",
      "aeee97c66e67: Pushed\n",
      "c2ad7eb58454: Pushed\n",
      "5a817c02ccf1: Pushed\n",
      "08d6fac9c4d0: Pushed\n",
      "de5226ffdd67: Pushed\n",
      "8d9f57db5cd6: Pushed\n",
      "f86a0c2bc4c2: Pushed\n",
      "cb3dceea19cb: Pushed\n",
      "9f10818f1f96: Pushed\n",
      "27502392e386: Pushed\n",
      "09de504e442b: Pushed\n",
      "c95d2191d777: Pushed\n",
      "f5257ad8a814: Pushed\n",
      "b62651620a56: Pushed\n",
      "1: digest: sha256:9555a0fed751593b6b856173529b748ae8eb5e394bbffec2b3ef11faa5ffac9d size: 4513\n",
      "2021/06/15 08:08:18 Successfully pushed image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d:1\n",
      "2021/06/15 08:08:18 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n",
      "2021/06/15 08:08:18 Pushing image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d:latest, attempt 1\n",
      "The push refers to repository [322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d]\n",
      "c69acd8784f8: Preparing\n",
      "30f9174d4254: Preparing\n",
      "dbbb0181e4d7: Preparing\n",
      "6a823bdc1649: Preparing\n",
      "b62651620a56: Preparing\n",
      "054c95c3ca45: Preparing\n",
      "aeee97c66e67: Preparing\n",
      "1d5d6e82b9b6: Preparing\n",
      "c2ad7eb58454: Preparing\n",
      "5a817c02ccf1: Preparing\n",
      "08d6fac9c4d0: Preparing\n",
      "de5226ffdd67: Preparing\n",
      "8d9f57db5cd6: Preparing\n",
      "09de504e442b: Preparing\n",
      "f86a0c2bc4c2: Preparing\n",
      "cb3dceea19cb: Preparing\n",
      "f5257ad8a814: Preparing\n",
      "9f10818f1f96: Preparing\n",
      "27502392e386: Preparing\n",
      "c95d2191d777: Preparing\n",
      "aeee97c66e67: Waiting\n",
      "09de504e442b: Waiting\n",
      "1d5d6e82b9b6: Waiting\n",
      "f86a0c2bc4c2: Waiting\n",
      "cb3dceea19cb: Waiting\n",
      "c2ad7eb58454: Waiting\n",
      "5a817c02ccf1: Waiting\n",
      "08d6fac9c4d0: Waiting\n",
      "f5257ad8a814: Waiting\n",
      "de5226ffdd67: Waiting\n",
      "8d9f57db5cd6: Waiting\n",
      "9f10818f1f96: Waiting\n",
      "27502392e386: Waiting\n",
      "c95d2191d777: Waiting\n",
      "b62651620a56: Layer already exists\n",
      "c69acd8784f8: Layer already exists\n",
      "30f9174d4254: Layer already exists\n",
      "dbbb0181e4d7: Layer already exists\n",
      "6a823bdc1649: Layer already exists\n",
      "054c95c3ca45: Layer already exists\n",
      "c2ad7eb58454: Layer already exists\n",
      "aeee97c66e67: Layer already exists\n",
      "1d5d6e82b9b6: Layer already exists\n",
      "08d6fac9c4d0: Layer already exists\n",
      "5a817c02ccf1: Layer already exists\n",
      "09de504e442b: Layer already exists\n",
      "8d9f57db5cd6: Layer already exists\n",
      "f86a0c2bc4c2: Layer already exists\n",
      "de5226ffdd67: Layer already exists\n",
      "cb3dceea19cb: Layer already exists\n",
      "f5257ad8a814: Layer already exists\n",
      "9f10818f1f96: Layer already exists\n",
      "c95d2191d777: Layer already exists\n",
      "27502392e386: Layer already exists\n",
      "latest: digest: sha256:9555a0fed751593b6b856173529b748ae8eb5e394bbffec2b3ef11faa5ffac9d size: 4513\n",
      "2021/06/15 08:08:19 Successfully pushed image: 322f90ddb50346f18d4568f1641a9197.azurecr.io/azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d:latest\n",
      "2021/06/15 08:08:19 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 238.514410)\n",
      "2021/06/15 08:08:19 Populating digests for step ID: acb_step_0...\n",
      "2021/06/15 08:08:22 Successfully populated digests for step ID: acb_step_0\n",
      "2021/06/15 08:08:22 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 142.846759)\n",
      "2021/06/15 08:08:22 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.391799)\n",
      "2021/06/15 08:08:22 The following dependencies were found:\n",
      "2021/06/15 08:08:22 \n",
      "- image:\n",
      "    registry: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "    repository: azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d\n",
      "    tag: latest\n",
      "    digest: sha256:9555a0fed751593b6b856173529b748ae8eb5e394bbffec2b3ef11faa5ffac9d\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210301.v1\n",
      "    digest: sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "  git: {}\n",
      "- image:\n",
      "    registry: 322f90ddb50346f18d4568f1641a9197.azurecr.io\n",
      "    repository: azureml/azureml_4d0c5f845cfbe250128f4d0459276e9d\n",
      "    tag: \"1\"\n",
      "    digest: sha256:9555a0fed751593b6b856173529b748ae8eb5e394bbffec2b3ef11faa5ffac9d\n",
      "  runtime-dependency:\n",
      "    registry: mcr.microsoft.com\n",
      "    repository: azureml/openmpi3.1.2-ubuntu18.04\n",
      "    tag: 20210301.v1\n",
      "    digest: sha256:9c4f76b334a5add8bd2862ff33289658d267ba298f2d2424fa1a28a4e4cc2232\n",
      "  git: {}\n",
      "\n",
      "\n",
      "Run ID: cc4 was successful after 6m31s\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-15T09:38:08Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore\n",
      "2021-06-15T09:38:09Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-15T09:38:10Z Starting output-watcher...\n",
      "2021-06-15T09:38:10Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_fe4afc798de401edfb76dc27a38b1703\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "9e11d437728f: Pulling fs layer\n",
      "3506c910620f: Pulling fs layer\n",
      "afe6352c52c2: Pulling fs layer\n",
      "45d886309004: Pulling fs layer\n",
      "2ce19e789040: Pulling fs layer\n",
      "f2a2950e1ed4: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "45d886309004: Waiting\n",
      "2ce19e789040: Waiting\n",
      "f2a2950e1ed4: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "9e11d437728f: Waiting\n",
      "3506c910620f: Waiting\n",
      "afe6352c52c2: Waiting\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt\n",
      "========================================================================================================================\n",
      "2021-06-15T09:38:08Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore\n",
      "2021-06-15T09:38:09Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-15T09:38:09Z Starting output-watcher...\n",
      "2021-06-15T09:38:09Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-06-15T09:38:10Z Executing 'Copy ACR Details file' on 10.0.0.7\n",
      "2021-06-15T09:38:10Z Executing 'Copy ACR Details file' on 10.0.0.6\n",
      "2021-06-15T09:38:10Z Copy ACR Details file succeeded on 10.0.0.6. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "2021-06-15T09:38:10Z Copy ACR Details file succeeded on 10.0.0.7. Output: \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_fe4afc798de401edfb76dc27a38b1703\n",
      "92473f7ef455: Pulling fs layer\n",
      "fb52bde70123: Pulling fs layer\n",
      "64788f86be3f: Pulling fs layer\n",
      "33f6d5f2e001: Pulling fs layer\n",
      "eeb715f1b6ae: Pulling fs layer\n",
      "fe519cf36537: Pulling fs layer\n",
      "58ff99196c15: Pulling fs layer\n",
      "9b13f06a8eff: Pulling fs layer\n",
      "2d4e93adbf58: Pulling fs layer\n",
      "6ee7c3767844: Pulling fs layer\n",
      "62cfc3ccb8ab: Pulling fs layer\n",
      "4a7af9d757ee: Pulling fs layer\n",
      "9e11d437728f: Pulling fs layer\n",
      "3506c910620f: Pulling fs layer\n",
      "afe6352c52c2: Pulling fs layer\n",
      "45d886309004: Pulling fs layer\n",
      "2ce19e789040: Pulling fs layer\n",
      "f2a2950e1ed4: Pulling fs layer\n",
      "33f6d5f2e001: Waiting\n",
      "eeb715f1b6ae: Waiting\n",
      "fe519cf36537: Waiting\n",
      "58ff99196c15: Waiting\n",
      "9b13f06a8eff: Waiting\n",
      "2d4e93adbf58: Waiting\n",
      "6ee7c3767844: Waiting\n",
      "62cfc3ccb8ab: Waiting\n",
      "4a7af9d757ee: Waiting\n",
      "9e11d437728f: Waiting\n",
      "3506c910620f: Waiting\n",
      "afe6352c52c2: Waiting\n",
      "45d886309004: Waiting\n",
      "2ce19e789040: Waiting\n",
      "f2a2950e1ed4: Waiting\n",
      "64788f86be3f: Verifying Checksum\n",
      "64788f86be3f: Download complete\n",
      "fb52bde70123: Verifying Checksum\n",
      "fb52bde70123: Download complete\n",
      "33f6d5f2e001: Verifying Checksum\n",
      "33f6d5f2e001: Download complete\n",
      "fe519cf36537: Verifying Checksum\n",
      "fe519cf36537: Download complete\n",
      "92473f7ef455: Verifying Checksum\n",
      "92473f7ef455: Download complete\n",
      "58ff99196c15: Verifying Checksum\n",
      "58ff99196c15: Download complete\n",
      "eeb715f1b6ae: Verifying Checksum\n",
      "eeb715f1b6ae: Download complete\n",
      "9b13f06a8eff: Verifying Checksum\n",
      "9b13f06a8eff: Download complete\n",
      "6ee7c3767844: Verifying Checksum\n",
      "6ee7c3767844: Download complete\n",
      "4a7af9d757ee: Verifying Checksum\n",
      "4a7af9d757ee: Download complete\n",
      "62cfc3ccb8ab: Verifying Checksum\n",
      "62cfc3ccb8ab: Download complete\n",
      "9e11d437728f: Verifying Checksum\n",
      "9e11d437728f: Download complete\n",
      "afe6352c52c2: Verifying Checksum\n",
      "afe6352c52c2: Download complete\n",
      "45d886309004: Verifying Checksum\n",
      "45d886309004: Download complete\n",
      "2ce19e789040: Verifying Checksum\n",
      "2ce19e789040: Download complete\n",
      "f2a2950e1ed4: Verifying Checksum\n",
      "f2a2950e1ed4: Download complete\n",
      "2d4e93adbf58: Verifying Checksum\n",
      "2d4e93adbf58: Download complete\n",
      "3506c910620f: Verifying Checksum\n",
      "3506c910620f: Download complete\n",
      "92473f7ef455: Pull complete\n",
      "fb52bde70123: Pull complete\n",
      "64788f86be3f: Pull complete\n",
      "33f6d5f2e001: Pull complete\n",
      "eeb715f1b6ae: Pull complete\n",
      "fe519cf36537: Pull complete\n",
      "58ff99196c15: Pull complete\n",
      "9b13f06a8eff: Pull complete\n",
      "2d4e93adbf58: Pull complete\n",
      "6ee7c3767844: Pull complete\n",
      "62cfc3ccb8ab: Pull complete\n",
      "4a7af9d757ee: Pull complete\n",
      "9e11d437728f: Pull complete\n",
      "3506c910620f: Pull complete\n",
      "afe6352c52c2: Pull complete\n",
      "45d886309004: Pull complete\n",
      "2ce19e789040: Pull complete\n",
      "f2a2950e1ed4: Pull complete\n",
      "Digest: sha256:5224cd9c4e07c9304c90193ab084da3cf8643e81065eef4d81c2c4029c58248c\n",
      "Status: Downloaded newer image for viennaglobal.azurecr.io/azureml/azureml_fe4afc798de401edfb76dc27a38b1703:latest\n",
      "viennaglobal.azurecr.io/azureml/azureml_fe4afc798de401edfb76dc27a38b1703:latest\n",
      "2021-06-15T09:38:42Z The vmsize standard_ds11_v2 is not a GPU VM, skipping get GPU count by running nvidia-smi command.\n",
      "2021-06-15T09:38:42Z Check if container cd739555-37f2-4496-a40d-2cb55edb7c5c_DataSidecar already exist exited with 0, \n",
      "\n",
      "41defc6ef85f26bf033f22dd70ac8a76f04c6f2fe63a9057739c958ad4aa3bcc\n",
      "2021-06-15T09:38:45Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
      "2021-06-15T09:38:45Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-affecd50a957fbf0b412b5b35cc8d834-3ef10c439f81cf62-01 -sshRequired=false] \n",
      "2021/06/15 09:38:46 Starting App Insight Logger for task:  containerSetup\n",
      "2021/06/15 09:38:46 Version: 3.0.01615.0003 Branch: .SourceBranch Commit: 41d0573\n",
      "2021/06/15 09:38:46 Entered ContainerSetupTask - Preparing infiniband\n",
      "2021/06/15 09:38:46 Starting infiniband setup\n",
      "2021/06/15 09:38:46 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/06/15 09:38:46 Returning Python Version as 3.7\n",
      "2021/06/15 09:38:46 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/15 09:38:46 VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021-06-15T09:38:46Z VMSize: standard_ds11_v2, Host: runtime-gen1-ubuntu18, Container: ubuntu-16.04\n",
      "2021/06/15 09:38:46 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/06/15 09:38:46 Not setting up Infiniband in Container\n",
      "2021/06/15 09:38:46 Not setting up Infiniband in Container\n",
      "2021-06-15T09:38:46Z Not setting up Infiniband in Container\n",
      "2021/06/15 09:38:46 Python Version found is Python 3.7.9\n",
      "\n",
      "2021/06/15 09:38:46 Returning Python Version as 3.7\n",
      "2021/06/15 09:38:46 sshd inside container not required for job, skipping setup.\n",
      "2021/06/15 09:38:46 All App Insights Logs was send successfully\n",
      "2021/06/15 09:38:46 App Insight Client has already been closed\n",
      "2021/06/15 09:38:46 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "2021-06-15T09:38:46Z Starting docker container succeeded.\n",
      "\n",
      "Streaming azureml-logs/65_job_prep-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-15T09:38:46.983360] Entering job preparation.\n",
      "[2021-06-15T09:38:47.699720] Starting job preparation.\n",
      "[2021-06-15T09:38:47.699761] Extracting the control code.\n",
      "[2021-06-15T09:38:47.717475] fetching and extracting the control code on master node.\n",
      "[2021-06-15T09:38:47.717504] Starting extract_project.\n",
      "[2021-06-15T09:38:47.717643] Starting to extract zip file.\n",
      "[2021-06-15T09:38:48.441544] Finished extracting zip file.\n",
      "[2021-06-15T09:38:48.703502] Using urllib.request Python 3.0 or later\n",
      "[2021-06-15T09:38:48.703632] Start fetching snapshots.\n",
      "[2021-06-15T09:38:48.703673] Start fetching snapshot.\n",
      "[2021-06-15T09:38:48.703689] Retrieving project from snapshot: 8b547af3-86c2-4323-abd6-54ce172e870c\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 40\n",
      "[2021-06-15T09:38:48.971465] Finished fetching snapshot.\n",
      "[2021-06-15T09:38:48.971508] Start fetching snapshot.\n",
      "[2021-06-15T09:38:48.971526] Retrieving project from snapshot: dd02c867-f96e-4d59-bcfe-0fea31777ee1\n",
      "[2021-06-15T09:38:59.512006] Finished fetching snapshot.\n",
      "[2021-06-15T09:38:59.512041] Finished fetching snapshots.\n",
      "[2021-06-15T09:38:59.512056] Finished extract_project.\n",
      "[2021-06-15T09:38:59.532967] Finished fetching and extracting the control code.\n",
      "[2021-06-15T09:38:59.540785] Start run_history_prep.\n",
      "[2021-06-15T09:38:59.636177] Job preparation is complete.\n",
      "[2021-06-15T09:38:59.636739] Entering Data Context Managers in Sidecar\n",
      "[2021-06-15T09:38:59.637864] Running Sidecar prep cmd...\n",
      "[2021-06-15T09:39:00.079001] INFO azureml.sidecar.sidecar: Received task: enter_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c\n",
      "[2021-06-15T09:39:00.080056] INFO azureml.sidecar.sidecar: Invoking \"enter_contexts\" task with Context Managers: {\"context_managers\": [\"Dataset:context_managers.Datasets\", \"DataStoreCopy:context_managers.DataStores\"]}\n",
      "Enter __enter__ of DatasetContextManager\n",
      "SDK version: azureml-core==1.28.0 azureml-dataprep==2.16.0. Session id: cf5b6fa6-360c-4b61-a4bc-a53c0632f980. Run id: cd739555-37f2-4496-a40d-2cb55edb7c5c.\n",
      "Processing 'diabetes_batch'.\n",
      "Processing dataset FileDataset\n",
      "{\n",
      "  \"source\": [\n",
      "    \"('workspaceblobstore', 'batch-data/')\"\n",
      "  ],\n",
      "  \"definition\": [\n",
      "    \"GetDatastoreFiles\"\n",
      "  ],\n",
      "  \"registration\": {\n",
      "    \"id\": \"ebe2d2aa-3e14-415e-aa26-7c3646186817\",\n",
      "    \"name\": \"batch-data\",\n",
      "    \"version\": 1,\n",
      "    \"description\": \"batch data\",\n",
      "    \"workspace\": \"Workspace.create(name='20210613', subscription_id='153404fd-72ab-4092-b50e-de490c5509fc', resource_group='20210613')\"\n",
      "  }\n",
      "}\n",
      "Mounting diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/wd/diabetes_batch_ebe2d2aa-3e14-415e-aa26-7c3646186817.\n",
      "Mounted diabetes_batch to /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/wd/diabetes_batch_ebe2d2aa-3e14-415e-aa26-7c3646186817 as folder.\n",
      "Exit __enter__ of DatasetContextManager\n",
      "Set Dataset diabetes_batch's target path to /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/wd/diabetes_batch_ebe2d2aa-3e14-415e-aa26-7c3646186817\n",
      "Acquired lockfile /tmp/cd739555-37f2-4496-a40d-2cb55edb7c5c-datastore.lock to downloading input data references\n",
      "[2021-06-15T09:39:13.334472] INFO azureml.sidecar.task.enter_contexts: Entered Context Managers\n",
      "[2021-06-15T09:39:14.050185] Ran Sidecar prep cmd.\n",
      "[2021-06-15T09:39:14.050284] Running Context Managers in Sidecar complete.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/06/15 09:40:03 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/06/15 09:40:03 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/info\n",
      "2021/06/15 09:40:03 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
      "[2021-06-15T09:40:04.431061] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', '--input_fds_0', 'diabetes_batch'])\n",
      "Script type = None\n",
      "[2021-06-15T09:40:05.838106] Entering Run History Context Manager.\n",
      "[2021-06-15T09:40:06.765668] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c\n",
      "[2021-06-15T09:40:06.765941] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', '--input_fds_0', 'diabetes_batch']\n",
      "[2021-06-15T09:40:06.766036] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', '--input_fds_0', 'diabetes_batch']\n",
      "\n",
      "2021/06/15 09:40:08 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt\n",
      "===============================================================================================================\n",
      "[2021-06-15T09:42:07.224709] Entering job release\n",
      "[2021-06-15T09:42:09.140693] Starting job release\n",
      "[2021-06-15T09:42:09.141301] Logging experiment finalizing status in history service.[2021-06-15T09:42:09.141481] job release stage : upload_datastore starting...\n",
      "\n",
      "[2021-06-15T09:42:09.142448] job release stage : start importing azureml.history._tracking in run_history_release.Starting the daemon thread to refresh tokens in background for process with pid = 280\n",
      "\n",
      "[2021-06-15T09:42:09.143167] job release stage : execute_job_release starting...\n",
      "[2021-06-15T09:42:09.143600] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-06-15T09:42:09.143805] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-06-15T09:42:09.235049] Entering context manager injector.\n",
      "[2021-06-15T09:42:09.290938] job release stage : upload_datastore completed...\n",
      "[2021-06-15T09:42:09.292721] job release stage : execute_job_release completed...\n",
      "[2021-06-15T09:42:09.310435] job release stage : send_run_telemetry starting...\n",
      "[2021-06-15T09:42:09.556267] get vm size and vm region successfully.\n",
      "[2021-06-15T09:42:09.571625] get compute meta data successfully.\n",
      "[2021-06-15T09:42:09.700575] post artifact meta request successfully.\n",
      "[2021-06-15T09:42:09.725817] upload compute record artifact successfully.\n",
      "[2021-06-15T09:42:09.725916] job release stage : send_run_telemetry completed...\n",
      "[2021-06-15T09:42:09.726496] Running in AzureML-Sidecar, starting to exit user context managers...\n",
      "[2021-06-15T09:42:09.726601] Running Sidecar release cmd...\n",
      "[2021-06-15T09:42:09.748709] INFO azureml.sidecar.sidecar: Received task: exit_contexts. Running on Linux at /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c\n",
      "Enter __exit__ of DatasetContextManager\n",
      "Unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/wd/diabetes_batch_ebe2d2aa-3e14-415e-aa26-7c3646186817.\n",
      "Finishing unmounting /mnt/hostfs/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/wd/diabetes_batch_ebe2d2aa-3e14-415e-aa26-7c3646186817.\n",
      "Exit __exit__ of DatasetContextManager\n",
      "[2021-06-15T09:42:09.848982] Removing absolute paths from host...\n",
      "[2021-06-15T09:42:09.856217] INFO azureml.sidecar.task.exit_contexts: Exited Context Managers\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/06/15 09:40:03 Starting App Insight Logger for task:  runTaskLet\n",
      "2021/06/15 09:40:03 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/info\n",
      "2021/06/15 09:40:03 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
      "[2021-06-15T09:40:04.431061] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'Dataset:context_managers.Datasets', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', '--input_fds_0', 'diabetes_batch'])\n",
      "Script type = None\n",
      "[2021-06-15T09:40:05.838106] Entering Run History Context Manager.\n",
      "[2021-06-15T09:40:06.765668] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c\n",
      "[2021-06-15T09:40:06.765941] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', '--input_fds_0', 'diabetes_batch']\n",
      "[2021-06-15T09:40:06.766036] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/20210613/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/mounts/workspaceblobstore/azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', '--input_fds_0', 'diabetes_batch']\n",
      "\n",
      "2021/06/15 09:40:08 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 1\n",
      "FilteredData: 0.\n",
      "\n",
      "\n",
      "[2021-06-15T09:42:03.994414] The experiment completed successfully. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.21326541900634766 seconds\n",
      "[2021-06-15T09:42:04.383898] Finished context manager injector.\n",
      "2021/06/15 09:42:05 Attempt 1 of http call to http://10.0.0.6:16384/sendlogstoartifacts/status\n",
      "2021/06/15 09:42:05 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
      "Stopped: false\n",
      "OriginalData: 2\n",
      "FilteredData: 0.\n",
      "2021/06/15 09:42:05 Process Exiting with Code:  0\n",
      "2021/06/15 09:42:06 All App Insights Logs was send successfully\n",
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Finished\n",
      "{'runId': 'cd739555-37f2-4496-a40d-2cb55edb7c5c', 'target': 'msl-20210613b', 'status': 'Completed', 'startTimeUtc': '2021-06-15T09:38:21.875069Z', 'endTimeUtc': '2021-06-15T09:42:22.372807Z', 'properties': {'ContentSnapshotId': '8b547af3-86c2-4323-abd6-54ce172e870c', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'e6f294ef-33b2-4307-8139-34be78d6b6fc', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '156ead4b', 'azureml.pipelinerunid': 'f2ae0c56-645d-4323-a5e6-eea5d180d89f', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [{'dataset': {'id': 'ebe2d2aa-3e14-415e-aa26-7c3646186817'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'diabetes_batch', 'mechanism': 'Mount'}}], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'msl-20210613b', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', 'pathOnCompute': 'diabetes/results', 'overwrite': False}}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': 'ebe2d2aa-3e14-415e-aa26-7c3646186817', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2021-06-15T08:01:48Z_42816eaf', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.28.0', 'azureml-core~=1.28.0', 'azureml-dataprep[fuse]']}, 'scikit-learn', 'pip'], 'name': 'azureml_9227c6a4a5c53cc7836db22683f3eb34'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=oBDrnQ8kH9RdHCIr9oURgifG4gAvisgvBy4a6%2FdcMf4%3D&st=2021-06-15T09%3A31%3A58Z&se=2021-06-15T17%3A41%3A58Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/55_azureml-execution-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt?sv=2019-02-02&sr=b&sig=uW7qg56gQQkPSOvaTZuygqKASLeP%2Bfk7BtXanpIEsaE%3D&st=2021-06-15T09%3A31%3A59Z&se=2021-06-15T17%3A41%3A59Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/55_azureml-execution-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt?sv=2019-02-02&sr=b&sig=bsw1xJyn8GQ8Zl%2Bv9Jr9LAN1qJO9VemJYXWQOAVBi0g%3D&st=2021-06-15T09%3A32%3A01Z&se=2021-06-15T17%3A42%3A01Z&sp=r', 'azureml-logs/65_job_prep-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/65_job_prep-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt?sv=2019-02-02&sr=b&sig=mP5pV%2BOx7ePTpNwYW8tKaoiq38qVTMe02Vv9%2FsBhOpo%3D&st=2021-06-15T09%3A32%3A02Z&se=2021-06-15T17%3A42%3A02Z&sp=r', 'azureml-logs/65_job_prep-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/65_job_prep-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt?sv=2019-02-02&sr=b&sig=4hN1KAy%2Fb1SqfUFt8gDjNivfoqPUTJi6EgFEQSCZHfg%3D&st=2021-06-15T09%3A32%3A04Z&se=2021-06-15T17%3A42%3A04Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=e5%2BbHAL%2Fe6GcweD7kCvxaKu%2BckNuE4PJsNhfXro4PEI%3D&st=2021-06-15T09%3A32%3A05Z&se=2021-06-15T17%3A42%3A05Z&sp=r', 'azureml-logs/process_info.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Z3awL0FCnJxhj8k3KZSJHgiEHzLvhqcXhCpB9GQGgxk%3D&st=2021-06-15T09%3A32%3A08Z&se=2021-06-15T17%3A42%3A08Z&sp=r', 'azureml-logs/process_status.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=t37lgOPfIN8Pc75TTNJ3Rm9Q3jq6%2FB3PYiYQyKNApq8%3D&st=2021-06-15T09%3A32%3A09Z&se=2021-06-15T17%3A42%3A09Z&sp=r', 'logs/azureml/102_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/102_azureml.log?sv=2019-02-02&sr=b&sig=Z%2F3Zx8h2o4ARZNvMDQmKA%2FAC6ZGjtfLKmW9Haynmwuk%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/91_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/91_azureml.log?sv=2019-02-02&sr=b&sig=Pr13i9bmGW2OVeA9Ta4mctE0%2BFIX2Wogqk%2Bx2XDo3e8%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=p38vOE%2BQkHtxKAltyWRb4l8xMBxyf1SKjU%2BlSXVdzFE%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=K5EOuDx%2FJ5N4FWbGZT7stJCz6olK5KRZTANaICVkm6k%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rCbRCQb70YqfA6slJGT4Pb6sy5w%2BDOKohiVvO9BvVg4%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=LE1CwplKC2Ia0nK3cdUtRIZ9EuyHHPJbE2ZXpZIxSqI%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=JO12XaxBfwMcZPOPMH1f2f%2BEstyox92wVRnUOhwN78w%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/all.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/all.log?sv=2019-02-02&sr=b&sig=6AVSPKWaVNuRCfjeLn2ktRkKGn5FW%2BaYHHCU8YsJpwA%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.enter_contexts.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=gmgL0MtkP%2BbpYocHQeMU5p%2BVGIVnJcw%2BKdeJDeFf0lA%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.exit_contexts.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=EKbf65hPH%2B0OtgbwVofxt00FS6IDMKLFgQBT4GOu3Tc%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/all.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/all.log?sv=2019-02-02&sr=b&sig=%2B7F3QiaEfi1pqLoLkQvUPrdY%2FBXTNRUnoUn3N2GUjJc%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/task.enter_contexts.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=u1oFCqg4eJw9XxACj0DDfbyjcO1B15PVg0ttnD8n4Kg%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=feauPhNJiFq%2FUH8QQs5EaZ1s3EmxWjfxYibh79NOwok%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=j%2Bz3jf5bACS5mtTg3pP9xCCLlfhexCr4FeRpch5yzLU%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': 'f2ae0c56-645d-4323-a5e6-eea5d180d89f', 'status': 'Completed', 'startTimeUtc': '2021-06-15T08:00:38.032248Z', 'endTimeUtc': '2021-06-15T09:42:24.664723Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.f2ae0c56-645d-4323-a5e6-eea5d180d89f/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=xeB4p9nK216MyCkPUlmFgllRZsc%2F24cEtw8EUxe%2FJ5c%3D&st=2021-06-15T09%3A32%3A26Z&se=2021-06-15T17%3A42%3A26Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.f2ae0c56-645d-4323-a5e6-eea5d180d89f/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=YKs4UCXg0M0pmt1ZIEtPH6tjNZh13bt7OjV6%2BgH%2FAxQ%3D&st=2021-06-15T09%3A32%3A26Z&se=2021-06-15T17%3A42%3A26Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.f2ae0c56-645d-4323-a5e6-eea5d180d89f/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ezArn9MxJHT9USUFTJTp9BM1NWO6jez8V6DhqlBKAlY%3D&st=2021-06-15T09%3A32%3A26Z&se=2021-06-15T17%3A42%3A26Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline\n",
    "\n",
    "pipeline = Pipeline(workspace=ws, steps=[parallelrun_step])\n",
    "pipeline_run = Experiment(ws, 'mslearn-diabetes-batch').submit(pipeline)\n",
    "pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e1bc5",
   "metadata": {},
   "source": [
    "パイプラインの実行が終了すると、結果として得られた予測値はパイプラインの最初の(そして唯一の)ステップに関連する実験の出力に保存される。  \n",
    "それは以下のようにして取り出すことができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32bfffcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>66.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      File  Prediction\n",
       "0   13.csv           1\n",
       "1   14.csv           0\n",
       "2   15.csv           1\n",
       "3   16.csv           0\n",
       "4   17.csv           0\n",
       "5   27.csv           0\n",
       "6   28.csv           0\n",
       "7   29.csv           1\n",
       "8    3.csv           1\n",
       "9   30.csv           0\n",
       "10  63.csv           1\n",
       "11  64.csv           0\n",
       "12  65.csv           0\n",
       "13  66.csv           0\n",
       "14  67.csv           0\n",
       "15  36.csv           1\n",
       "16  37.csv           1\n",
       "17  38.csv           1\n",
       "18  39.csv           1\n",
       "19   4.csv           0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# 前回の実行結果が残っている場合は、ローカルの結果フォルダを削除\n",
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# 最初のステップのRunを取得し、その出力をダウンロード\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# フォルダ階層をたどって結果ファイルを探す\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# 出y録フォーマットのクリーンナップ\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# 結果の出力(先頭20件)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386b4106",
   "metadata": {},
   "source": [
    "### パイプラインの公開とRESTインターフェイスの使用\n",
    "\n",
    "バッチ推論パイプラインが完成したので、これを公開してRESTエンドポイントを用いてアプリケーションから実行することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a1aff0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Id</th><th>Status</th><th>Endpoint</th></tr><tr><td>diabetes-batch-pipeline</td><td><a href=\"https://ml.azure.com/pipelines/891d6831-3cc8-4273-9820-cacc27b2dbf5?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613\" target=\"_blank\" rel=\"noopener\">891d6831-3cc8-4273-9820-cacc27b2dbf5</a></td><td>Active</td><td><a href=\"https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/PipelineRuns/PipelineSubmit/891d6831-3cc8-4273-9820-cacc27b2dbf5\" target=\"_blank\" rel=\"noopener\">REST Endpoint</a></td></tr></table>"
      ],
      "text/plain": [
       "Pipeline(Name: diabetes-batch-pipeline,\n",
       "Id: 891d6831-3cc8-4273-9820-cacc27b2dbf5,\n",
       "Status: Active,\n",
       "Endpoint: https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/PipelineRuns/PipelineSubmit/891d6831-3cc8-4273-9820-cacc27b2dbf5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name='diabetes-batch-pipeline', description='Batch scoring of diabetes data', version='1.0')\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860c7808",
   "metadata": {},
   "source": [
    "> 注 : 公開されたパイプラインにはエンドポイントがあり、Azureポータルで確認できる。  \n",
    "エンドポイントは、公開されたパイプラインオブジェクトのプロパティからも確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd4b3d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://westus2.api.azureml.ms/pipelines/v1.0/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourceGroups/20210613/providers/Microsoft.MachineLearningServices/workspaces/20210613/PipelineRuns/PipelineSubmit/891d6831-3cc8-4273-9820-cacc27b2dbf5\n"
     ]
    }
   ],
   "source": [
    "rest_endpoint = published_pipeline.endpoint\n",
    "print(rest_endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed41efc",
   "metadata": {},
   "source": [
    "エンドポイントを利用するには、クライアントからHTTPでRESTコールをする必要がある。  \n",
    "このリクエストは認証が必要なのでauthorizationヘッダが必要で、これをテストするためにAzureワークスペースへの現在の接続からの認証ヘッダーを使用する。\n",
    "\n",
    "> 注 : 実際のアプリケーションでは、認証されるためのサービスプリンシパルが必要になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc7ea427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication header ready.\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()\n",
    "print('Authentication header ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e433712a",
   "metadata": {},
   "source": [
    "これで、RESTインターフェイスを呼び出す準備ができた。  \n",
    "バッチ推論パイプラインは非同期的に実行されるので、識別子が返ってくる。  \n",
    "この識別子を用いて、パイプラインの実験が実行されているかどうかを追跡することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6655e296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'5d5d8353-1e0b-4d24-a838-4ab544c0b170'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": \"mslearn-diabetes-batch\"})\n",
    "run_id = response.json()[\"Id\"]\n",
    "run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92efb52",
   "metadata": {},
   "source": [
    "RunIDがあるので、**RunDetails**ウィジェットを使って実験が実行されている様子を見ることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e437e159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PipelineRunId: 5d5d8353-1e0b-4d24-a838-4ab544c0b170\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/5d5d8353-1e0b-4d24-a838-4ab544c0b170?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "PipelineRun Status: NotStarted\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: bc6d3475-e8af-4aa7-864f-d20f4f2343c7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/bc6d3475-e8af-4aa7-864f-d20f4f2343c7?wsid=/subscriptions/153404fd-72ab-4092-b50e-de490c5509fc/resourcegroups/20210613/workspaces/20210613&tid=5456e8d8-0223-4619-ba5b-e313627da53d\n",
      "\n",
      "StepRun(batch-score-diabetes) Execution Summary\n",
      "================================================\n",
      "StepRun( batch-score-diabetes ) Status: Finished\n",
      "{'runId': 'bc6d3475-e8af-4aa7-864f-d20f4f2343c7', 'target': 'msl-20210613b', 'status': 'Completed', 'startTimeUtc': '2021-06-15T09:42:38.585768Z', 'endTimeUtc': '2021-06-15T09:42:38.713083Z', 'properties': {'azureml.reusedrunid': 'cd739555-37f2-4496-a40d-2cb55edb7c5c', 'azureml.reusednodeid': '156ead4b', 'azureml.reusedpipeline': 'f2ae0c56-645d-4323-a5e6-eea5d180d89f', 'azureml.reusedpipelinerunid': 'f2ae0c56-645d-4323-a5e6-eea5d180d89f', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '156ead4b', 'ContentSnapshotId': '8b547af3-86c2-4323-abd6-54ce172e870c', 'StepType': 'PythonScriptStep', 'ComputeTargetType': 'AmlCompute', 'azureml.moduleid': 'e6f294ef-33b2-4307-8139-34be78d6b6fc', 'azureml.pipelinerunid': '5d5d8353-1e0b-4d24-a838-4ab544c0b170', 'azureml.pipelineid': '891d6831-3cc8-4273-9820-cacc27b2dbf5', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json', 'azureml.parallelrunstep': 'true'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'driver/amlbi_main.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--client_sdk_version', '1.28.0', '--scoring_module_name', 'batch_diabetes.py', '--mini_batch_size', '5', '--error_threshold', '10', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--output', '$AZUREML_DATAREFERENCE_inferences', '--input_fds_0', 'diabetes_batch'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'msl-20210613b', 'dataReferences': {'inferences': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/cd739555-37f2-4496-a40d-2cb55edb7c5c/inferences', 'pathOnCompute': 'diabetes/results', 'overwrite': False}}, 'data': {'diabetes_batch': {'dataLocation': {'dataset': {'id': 'ebe2d2aa-3e14-415e-aa26-7c3646186817', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Mount', 'environmentVariableName': 'diabetes_batch', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'datacaches': [], 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 2, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'batch_environment', 'version': 'Autosave_2021-06-15T08:01:48Z_42816eaf', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.28.0', 'azureml-core~=1.28.0', 'azureml-dataprep[fuse]']}, 'scikit-learn', 'pip'], 'name': 'azureml_9227c6a4a5c53cc7836db22683f3eb34'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi3.1.2-ubuntu18.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': True, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/20_image_build_log.txt?sv=2019-02-02&sr=b&sig=oBDrnQ8kH9RdHCIr9oURgifG4gAvisgvBy4a6%2FdcMf4%3D&st=2021-06-15T09%3A31%3A58Z&se=2021-06-15T17%3A41%3A58Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/55_azureml-execution-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt?sv=2019-02-02&sr=b&sig=uW7qg56gQQkPSOvaTZuygqKASLeP%2Bfk7BtXanpIEsaE%3D&st=2021-06-15T09%3A31%3A59Z&se=2021-06-15T17%3A41%3A59Z&sp=r', 'azureml-logs/55_azureml-execution-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/55_azureml-execution-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt?sv=2019-02-02&sr=b&sig=bsw1xJyn8GQ8Zl%2Bv9Jr9LAN1qJO9VemJYXWQOAVBi0g%3D&st=2021-06-15T09%3A32%3A01Z&se=2021-06-15T17%3A42%3A01Z&sp=r', 'azureml-logs/65_job_prep-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/65_job_prep-tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d.txt?sv=2019-02-02&sr=b&sig=mP5pV%2BOx7ePTpNwYW8tKaoiq38qVTMe02Vv9%2FsBhOpo%3D&st=2021-06-15T09%3A32%3A02Z&se=2021-06-15T17%3A42%3A02Z&sp=r', 'azureml-logs/65_job_prep-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/65_job_prep-tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d.txt?sv=2019-02-02&sr=b&sig=4hN1KAy%2Fb1SqfUFt8gDjNivfoqPUTJi6EgFEQSCZHfg%3D&st=2021-06-15T09%3A32%3A04Z&se=2021-06-15T17%3A42%3A04Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=e5%2BbHAL%2Fe6GcweD7kCvxaKu%2BckNuE4PJsNhfXro4PEI%3D&st=2021-06-15T09%3A32%3A05Z&se=2021-06-15T17%3A42%3A05Z&sp=r', 'azureml-logs/process_info.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=Z3awL0FCnJxhj8k3KZSJHgiEHzLvhqcXhCpB9GQGgxk%3D&st=2021-06-15T09%3A32%3A08Z&se=2021-06-15T17%3A42%3A08Z&sp=r', 'azureml-logs/process_status.json': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=t37lgOPfIN8Pc75TTNJ3Rm9Q3jq6%2FB3PYiYQyKNApq8%3D&st=2021-06-15T09%3A32%3A09Z&se=2021-06-15T17%3A42%3A09Z&sp=r', 'logs/azureml/102_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/102_azureml.log?sv=2019-02-02&sr=b&sig=Z%2F3Zx8h2o4ARZNvMDQmKA%2FAC6ZGjtfLKmW9Haynmwuk%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/91_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/91_azureml.log?sv=2019-02-02&sr=b&sig=Pr13i9bmGW2OVeA9Ta4mctE0%2BFIX2Wogqk%2Bx2XDo3e8%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=p38vOE%2BQkHtxKAltyWRb4l8xMBxyf1SKjU%2BlSXVdzFE%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=K5EOuDx%2FJ5N4FWbGZT7stJCz6olK5KRZTANaICVkm6k%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=rCbRCQb70YqfA6slJGT4Pb6sy5w%2BDOKohiVvO9BvVg4%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=LE1CwplKC2Ia0nK3cdUtRIZ9EuyHHPJbE2ZXpZIxSqI%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=JO12XaxBfwMcZPOPMH1f2f%2BEstyox92wVRnUOhwN78w%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/all.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/all.log?sv=2019-02-02&sr=b&sig=6AVSPKWaVNuRCfjeLn2ktRkKGn5FW%2BaYHHCU8YsJpwA%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.enter_contexts.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=gmgL0MtkP%2BbpYocHQeMU5p%2BVGIVnJcw%2BKdeJDeFf0lA%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.exit_contexts.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_59c2fa8eae6ecbdead82aae6c967a6023ed1c3c0d84863ea37256d72cac57216_d/task.exit_contexts.log?sv=2019-02-02&sr=b&sig=EKbf65hPH%2B0OtgbwVofxt00FS6IDMKLFgQBT4GOu3Tc%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/all.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/all.log?sv=2019-02-02&sr=b&sig=%2B7F3QiaEfi1pqLoLkQvUPrdY%2FBXTNRUnoUn3N2GUjJc%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/task.enter_contexts.log': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/sidecar/tvmps_9d2cb1bdbf30e6d5ece2de3fe4fe80efc129d185680c4b967fdd5f9798adff8e_d/task.enter_contexts.log?sv=2019-02-02&sr=b&sig=u1oFCqg4eJw9XxACj0DDfbyjcO1B15PVg0ttnD8n4Kg%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=feauPhNJiFq%2FUH8QQs5EaZ1s3EmxWjfxYibh79NOwok%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.cd739555-37f2-4496-a40d-2cb55edb7c5c/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=j%2Bz3jf5bACS5mtTg3pP9xCCLlfhexCr4FeRpch5yzLU%3D&st=2021-06-15T09%3A32%3A10Z&se=2021-06-15T17%3A42%3A10Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n",
      "\n",
      "\n",
      "PipelineRun Execution Summary\n",
      "==============================\n",
      "PipelineRun Status: Finished\n",
      "{'runId': '5d5d8353-1e0b-4d24-a838-4ab544c0b170', 'status': 'Completed', 'startTimeUtc': '2021-06-15T09:42:33.423385Z', 'endTimeUtc': '2021-06-15T09:42:39.353915Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'Unavailable', 'runType': 'HTTP', 'azureml.parameters': '{}', 'azureml.pipelineid': '891d6831-3cc8-4273-9820-cacc27b2dbf5'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.5d5d8353-1e0b-4d24-a838-4ab544c0b170/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=LrrIbfyhqbLOvCR9Lw0ejjgQ%2FMw2s%2FmlWdQ%2BiuoMEUE%3D&st=2021-06-15T09%3A32%3A41Z&se=2021-06-15T17%3A42%3A41Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.5d5d8353-1e0b-4d24-a838-4ab544c0b170/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=1DA6fy3azo5OZfgNB8ODwj6Er6qN1Ro%2Fn3SDbP72jUo%3D&st=2021-06-15T09%3A32%3A41Z&se=2021-06-15T17%3A42%3A41Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://202106138491592323.blob.core.windows.net/azureml/ExperimentRun/dcid.5d5d8353-1e0b-4d24-a838-4ab544c0b170/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=hwylneF%2B6W3M3bY5UpSa05vLb6cHIgXSDF7kdkT2Q2o%3D&st=2021-06-15T09%3A32%3A41Z&se=2021-06-15T17%3A42%3A41Z&sp=r'}, 'submittedBy': 'Tatsuya Kato'}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Finished'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.pipeline.core.run import PipelineRun\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "published_pipeline_run = PipelineRun(ws.experiments['mslearn-diabetes-batch'], run_id)\n",
    "\n",
    "# Block until the run completes\n",
    "published_pipeline_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a8f5e",
   "metadata": {},
   "source": [
    "パイプラインの実行が完了するのを待ってから、以下のセルを実行して結果を確認する。  \n",
    "先程と同様に、結果は最初のパイプラインステップの出力にある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17e9c84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>27.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>28.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>30.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>63.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>64.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>65.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>66.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>67.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>37.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>39.csv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.csv</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      File  Prediction\n",
       "0   13.csv           1\n",
       "1   14.csv           0\n",
       "2   15.csv           1\n",
       "3   16.csv           0\n",
       "4   17.csv           0\n",
       "5   27.csv           0\n",
       "6   28.csv           0\n",
       "7   29.csv           1\n",
       "8    3.csv           1\n",
       "9   30.csv           0\n",
       "10  63.csv           1\n",
       "11  64.csv           0\n",
       "12  65.csv           0\n",
       "13  66.csv           0\n",
       "14  67.csv           0\n",
       "15  36.csv           1\n",
       "16  37.csv           1\n",
       "17  38.csv           1\n",
       "18  39.csv           1\n",
       "19   4.csv           0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "# 前回の実行結果が残っている場合、ローカルの結果フォルダを削除\n",
    "shutil.rmtree('diabetes-results', ignore_errors=True)\n",
    "\n",
    "# 最初のステップのRunを取得し、その出力をダウンロード\n",
    "prediction_run = next(pipeline_run.get_children())\n",
    "prediction_output = prediction_run.get_output_data('inferences')\n",
    "prediction_output.download(local_path='diabetes-results')\n",
    "\n",
    "# フォルダ階層をたどって結果ファイルを探す\n",
    "for root, dirs, files in os.walk('diabetes-results'):\n",
    "    for file in files:\n",
    "        if file.endswith('parallel_run_step.txt'):\n",
    "            result_file = os.path.join(root,file)\n",
    "\n",
    "# 出力形式をクリーンナップ\n",
    "df = pd.read_csv(result_file, delimiter=\":\", header=None)\n",
    "df.columns = [\"File\", \"Prediction\"]\n",
    "\n",
    "# 結果の出力\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c2a39",
   "metadata": {},
   "source": [
    "これで、バッチ処理するためのパイプラインが出来上がった。\n",
    "\n",
    "バッチ推論の詳細 : https://docs.microsoft.com/azure/machine-learning/how-to-run-batch-predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15efbdb6",
   "metadata": {},
   "source": [
    "## 知識チェック\n",
    "\n",
    "1. あなたは大量のデータ ファイルの新しい値を予測するために使用するバッチ推論パイプラインを作成中ですか?  \n",
    "あなたはパイプラインによってスコアリング スクリプトが複数のノード上で実行され、その結果が照合されるようにしたいと考えています。  \n",
    "パイプラインにはどのような種類のステップを含める必要がありますか?\n",
    "    - PythonScriptStep\n",
    "    - ParallelRunStep\n",
    "    - AdlaStep\n",
    "\n",
    "\n",
    "2. あなたは output_action=\"append_row\" プロパティを使用してバッチ推論パイプライン内のステップを構成しました。  \n",
    "どのファイルでバッチ推論の結果を探す必要がありますか?\n",
    "    - output.txt\n",
    "    - stdoutlogs.txt\n",
    "    - parallel_run_step.txt\n",
    "\n",
    "↓解答"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb299ba",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "1. ParallelRunStep\n",
    "    - ParallelRunStep ステップを使用して、スコアリング スクリプトを並列に実行する必要があります。\n",
    "2. parallel_run_step.txt\n",
    "    - append_row 出力アクションを使用すると、ParallelRunStep ステップからの結果が、  \n",
    "    parallel_run_step.txt という名前のファイル内で照合されます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
